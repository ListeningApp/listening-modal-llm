You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document. Your task is to faithfully reproduce the text for our text-to-speech engine so that it is easily read aloud.

Note that the text might not start at the beginning and paragraphs may be split acrosss multiple textboxes. Textboxes may start or end in the middle of a word which is acceptable: do not combine text between textboxes and leave broken words at the start and end of a textbox unchanged.

You will receive one textbox per-line in the format `id | Textbox content`. The output must be in the format `id | Clean content`.

RULES:
 • Remove inline citations and references e.g. "(Author, 2021)" or "(https://wikipedia.org/article.html)" or "[ECMOS 35b, 47, 49]".
 • Spell out numbers, dates, and chemical formulas for the TTS engine e.g. "-2.5" -> "negative two point five" or "Jan. 2020" -> "January twenty twenty".
 • Spell out LaTeX formulas for the TTS engine e.g. "<LATEX>p = 1</LATEX>" -> "P equals one".
 • Rejoin hyphenated word fragments within the same textbox e.g. "synth -esize" -> "synthesize".
 • Fix simple typos and OCR errors e.g. "O nce upon a 1ime." -> "Once upon a time.".
 • Delete nonsequiter textboxes that interrupt the middle of a sentence if they obviously do not belong.

Otherwise, the output should exactly match the input text:
 • Do not combine text across lines or attempt to fix words broken across lines.
 • Ensure each ID from the input is included in the output.
 • Make as few changes as possible while respecting the above rules.

EXAMPLE INPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symp- toms in adults.
0fpw | 2. Materia1 and methods
dqn8 | 2.1. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at 2 and 4 weeks after initiation. The target population included adults with ADHD symptoms who had not been diag- nosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale (CAARS-S:SV). This cut-off was indicative of clinically elevated symptoms (Conners et al., 1999) (see section 2.3).
82ju | 2.2. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics (www.microdo sing.nl). Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took 20 min to complete. If the survey had not been completed after 24 h, a reminder was sent. Each of the surveys at the 2- and 4-week time points took about 15 min to complete. Par- ticipants were able to pause the surveys. Data collection occurred between Nov. 2020 and Jul. 2021. The study was approved by the Ethics Review Committee of Psy- chology and Neuroscience at Maastricht University (ERCPN- 215_05_11_2019_A1).
1piq | 2.3. Measures
7fqw | 2.3.1. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psyche- delics (i.e., ayahuasca, DMT, 5-MeO-DMT, LSD, novel lysergamides (e.g., 1P-LSD, ALD-52), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | 2.3.2. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD (Kooij et al., 2019), or because these diagnoses were reported to be common in people who microdose (Fadiman and Korb, 2019). We 
3j2l | REVIEW ARTICLE Frontiers in Psychiatry | www.frontiersin.org
03k3 | 2
1k9e | constructed a variable Comorbidity alongside ADHD, differenti- ating respondents with and without a comorbid diagnosis alongside ADHD (<LATEX>p < . 0 0 1 =</LATEX> only ADHD or no ADHD diagnosis; <LATEX>p > . 0 1 =</LATEX> ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conven- tiona1 ADHD medication alongside microdosing (<LATEX>0 =</LATEX> only microdosing; <LATEX>1 =</LATEX> conven-
```

EXAMPLE OUTPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symptoms in adults.
0fpw | Two. Material and methods
dqn8 | Two point one. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at two and four weeks after initiation. The target population included adults with ADHD symptoms who had not been diagnosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale. This cut-off was indicative of clinically elevated symptoms (see section two point three).
82ju | Two point two. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics. Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took twenty minutes to complete. If the survey had not been completed after twenty-four hours, a reminder was sent. Each of the surveys at the two and four-week time points took about fifteen minutes to complete. Participants were able to pause the surveys. Data collection occurred between November twenty twenty and July twenty twenty-one. The study was approved by the Ethics Review Committee of Psychology and Neuroscience at Maastricht University.
1piq | Two point three. Measures
7fqw | Two point three point one. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psychedelics (i.e., ayahuasca, DMT, five-MeO-DMT, LSD, novel lysergamides (e.g., one-P-LSD, ALD-fifty-two), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | Two point three point two. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD, or because these diagnoses were reported to be common in people who microdose. We
3j2l |
03k3 |
1k9e | constructed a variable Comorbidity alongside ADHD, differentiating respondents with and without a comorbid diagnosis alongside ADHD (P is less than point zero zero one equals only ADHD or no ADHD diagnosis; P is greater than point zero one equals ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conventional ADHD medication alongside microdosing (zero equals only microdosing; one equals conven-
```

INPUT:
```
nvfy | The Promise of Field Experiments in Economics
mror | The empirical gold standard in the social sciences is to estimate a causal effect of some action, but amidst the complexity of the real world, this is easier said than done. Economists have long worked on approaches that seek to separate cause and effect in naturally occurring data. A few decades ago, a standard approach was to use multiple regression analysis in an attempt to hold other factors constant. But economists have now taken to heart the old maxim that "correlation doesn't imply causation," and have in recent decades sought out a variety of other approaches.
zlxc | For example, the instrumental variables approach seeks out a sometimes unex- pected source of exogenous variation to disentangle cause and effect. "Natural experiments" seek out an event or a change in the law that arguably creates exogenous variation in the variable of interest. One typically analyzes changes in a population that received the variation compared with changes in another population that didn't, under the assumption that they would have experienced much the same change in the absence of the treatment. A regression disconti- nuity approach looks for a situation where those immediately above the level of a certain characteristic-perhaps age or income-are treated differently than those just below that level, and then, based on the assumption that those barely above the defining line are not that different than those barely below the line, looks for
k0bw | whether a discontinuity occurs. Structural modeling can be a powerful approach to guide empirical regressions. It's possible to evaluate treatment programs not by experimental methods, but by making a statistical adjustment for those who are in the program compared with those outside the program, using the method of propensity score matching (Rosenbaum and Rubin, 1983).
aq5a | All of these approaches of modeling naturally occurring data, along with others not mentioned here, are quite useful. I do not come to bury econometric studies based on nonexperimental data, but rather to praise them. As I have argued for over a decade, my strong belief is that field experiments can usefully complement studies based on naturally occurring data and lab data. In this way, field experiments offer another useful set of arrows for the quiver of empirically minded economists. When combined with theory, field experiments represent an important and undervalued approach to further our understanding of economics.
sc5y | To be sure, we must work carefully when drawing conclusions based on the results of field experiments. Was the selection of participants into the treatment and experimental groups truly random? Do those who are not treated take some action as a result of being in the experiment, albeit in the control group, that they might not otherwise have taken? Is there something about the population being studied-perhaps risk-tolerance or persistence or belief that the treatment works- that warrants caution in generalizing the results to other populations? In the last few years, a lively literature has debated these and other issues that can arise in field experiments. The reader interested in these debates might begin with Heckman and Smith (1995) and Deaton (2010), who focus their criticisms largely on framed field experiments.
0yab | The papers in this symposium offer a wide sampling of field experimental work in economics as it has been evolving. Along the way, these papers show how researchers are seeking practical ways to address many of these potential concerns. In "Mechanism Experiments and Policy Evaluations," Jens Ludwig, Jeffrey R. Kling, and Sendhil Mullainathan discuss how we can learn from doing field experiments in complex policy environments. They emphasize the importance of uncovering the mechanism through which a treatment effect actually occurs-an insight that in many cases can be derived from a relatively simple set of field experimental treatments. In "The Role of Theory in Field Experiments," David Card, Stefano DellaVigna, and Ulrike Malmendier propose a way of classifying experimental studies according to the ways in which they are linked to economic theory, and they provide evidence that as field experiments have become more prominent in top economics journals, so have explicit theoretical foundations for those experiments. In "Field Experiments with Firms," Oriana Bandiera, Iwan Barankay, and Imran Rasul show how field experiments can illuminate a variety of firm decisions about methods of employee compensation and competitive strategy. Reading their paper, I was struck by how much of the modern-day business school curriculum might usefully be explored with the judicious use of field experiments.
w95z | Along with their many specific lessons, these three papers illustrate the general advantages of field experiments. First, field experiments offer a distinctive and new
0i1k | source of empirical evidence, which can then be compared, contrasted, reconciled, and eventually intertwined with evidence from nonexperimental and lab methods. Admittedly, this new experimental evidence will bring its own methodological chal- lenges, but when the field experiments are well-designed and rooted in economic theory, their evidence also has some distinctive strengths. Second, field experiments offer an immediate opportunity to specify and address the economic question of interest, rather than waiting and hoping for a natural event or a cast-iron econo- metric specification that would allow the researcher to address the issue cleanly. Consequently, conducting successful field experiments demands a different set of skills from traditional economic research, including the ability to recognize opportunities for experimentation hidden amidst everyday phenomena, an under- standing of experimental design, and the interpersonal skills to manage what are often a complex set of relationships involving parties to an experiment. Finally, field experiments offer economists the possibility of an improved connection from economic theory and empirical evidence to the real world, built on a deeper contextual understanding of real-world issues and institutions.
dqlg | How Do I Get Started?
p6pq | The idea of carrying out a field experiment may seem daunting. It means visiting a market or a firm that you may not know well, introducing yourself, and figuring out how to randomize important economic variables within a possibly complex situation. You must brace yourself for possible pitfalls along the way. Here, I offer 14 tips for improving your chances of executing successful field experiments.
zse6 | 1. Use economic theory to guide your design and as a lens to interpret your findings.
p2n3 | Economic theory is portable; empirical results in isolation offer only limited information about what is likely to happen in a new setting. Together, however, theory and experimental results provide a powerful guide to situations heretofore unexplored. Experimental results are most generalizable when they are built on tests of economic theory.
ohh7 | 2. Be an expert about the market that you are studying.
vbni | This is perhaps the most important insight that I have gained over my nearly 20 years of running field experiments. As a sports card dealer running natural field experiments in the early 1990s, I needed to understand the inner workings of the market-to have detailed knowledge of the underlying motivations of the actors in the market: buyers, sellers, third-party certifiers, and organizers. My past experience with this market was quite beneficial in crafting designs in which the incentives would be understood and interpreted correctly, and also in generating alternative hypotheses and understanding how to interpret the experimental data.
dgcw | 3. Have a proper control group.
gvwz | Experimentation is ubiquitous. Wherever I go to set up research-across profit and nonprofit firms, federal and local government agencies, school districts, Chinese manufacturing plants, and trading pits-I see that everyone already experiments. Unfortunately, what is common across all of these venues is that the experimenter rarely has a proper control group to compare results with the treated group. In nearly all cases, the comparison or control group is ill-conceived-past behavioral patterns or current behavioral patterns from a different population are used as a control group. Doing this is like neutering homo experimentalis.
sk5m | 4. Obtain sufficient sample sizes.
```

OUTPUT:
```
