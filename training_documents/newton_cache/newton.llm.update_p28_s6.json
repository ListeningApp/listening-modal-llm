{
  "id": "chatcmpl-A3UEKqYmpm7NrM5Wi43javt2orBFe",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "r5ct | negative \\left( \\frac { one } { two } minus \\rho \\right) \\sigma plus \\frac { \\alpha squared L subscript { H } } { six } \\| \\mathrm { s } subscript { k } superset { \\mathcal{I} } \\| \\leq zero \\Longrightarrow \\alpha \\leq \\sqrt { \\frac { three \\sigma \\left( one minus two \\rho \\right) } { L subscript { H } \\| \\mathrm { s } subscript { k } superset { \\mathcal{I} } \\| } } . Collecting the bounds on \\alpha , the largest step size that satisfies the line search condition can be lower bounded as\nt5nr | \\alpha subscript { k } \\geq \\min \\left\\{ one , \\sqrt { \\frac { three \\sigma \\left( one minus two \\rho \\right) } { L subscript { H } \\| \\mathrm { s } subscript { k } superset { \\mathcal{I} } \\| } } , \\frac { \\delta subscript { k } } { \\| \\mathrm { s } subscript { k } superset { \\mathcal{I} } \\| } \\right\\} . Now let \\mathrm { D } subscript { \\mathrm { t y p e } } equals \\mathrm { N P C } so that \\mathrm { p } subscript { k } superset { \\mathcal{I} } equals \\mathrm { r } subscript { k } superset { \\mathcal{I} } . Applying the negative curvature of \\mathrm { r } subscript { k } superset { \\mathcal{I} } , (twenty-one) and (thirty-seven)\nxiwq | f \\left( \\mathrm { x } subscript { k } \\left( \\alpha \\right) \\right) minus f \\left( \\mathrm { x } subscript { k } \\right) minus \\rho \\alpha \\langle \\mathrm { g } subscript { k } , \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\rangle \\leq \\alpha \\langle \\mathrm { g } subscript { k } superset { \\mathcal{I} } , \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\rangle plus \\frac { \\alpha squared } { two } \\langle \\mathrm { r } subscript { k } superset { \\mathcal{I} } , \\mathrm { H } subscript { k } superset { \\mathcal{I} } \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\rangle plus \\frac { \\alpha cubed L subscript { H } } { six } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| cubed minus \\rho \\alpha \\langle \\mathrm { g } subscript { k } , \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\rangle \\leq \\alpha \\left( one minus \\rho \\right) \\langle \\mathrm { g } subscript { k } superset { \\mathcal{I} } , \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\rangle plus \\frac { \\alpha cubed L subscript { H } } { six } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| cubed \\leq negative \\alpha \\left( one minus \\rho \\right) \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| squared plus \\frac { \\alpha cubed L subscript { H } } { six } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| cubed equals \\alpha \\left( negative \\left( one minus \\rho \\right) plus \\frac { \\alpha squared L subscript { H } } { six } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| \\right) \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| squared . This upper bound is nonpositive if\niivy | negative \\left( one minus \\rho \\right) plus \\frac { \\alpha squared L subscript { H } } { six } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| \\leq zero \\Longrightarrow \\alpha \\leq \\sqrt { \\frac { six \\left( one minus \\rho \\right) } { L subscript { H } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| } } . Therefore the largest step size that satisfies the line search condition, in the NPC case, is lower bounded as\nkn8m | \\alpha subscript { k } \\geq \\min \\left\\{ \\sqrt { \\frac { six \\left( one minus \\rho \\right) } { L subscript { H } \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| } } , \\frac { \\delta subscript { k } } { \\| \\mathrm { r } subscript { k } superset { \\mathcal{I} } \\| } \\right\\} . From Lemma C.4 we can see that, for a judicious choice of \\delta subscript { k } , the step size is inversely scaling with the step length, except for the \\alpha subscript { k } equals one in \\mathrm { D } subscript { \\mathrm { t y p e } } equals \\mathrm { S O I } case. This inverse scaling is key to obtaining an improved rate. We therefore deal with the \\alpha subscript { k } equals one case separately. Indeed, in Lemma C.5 we show that if \\alpha subscript { k } equals one with \\mathrm { D } subscript { \\mathrm { t y p e } } equals \\mathrm { S O L } the step length must be lower bounded by norm of the gradient of the next iterate (over the same inactive set). This lemma is similar to the result in Liu and Roosta, we include it for completeness.\nvqoi | Inexact Newton-type Methods for Optimization with Nonnegativity Constraints\nn3q9 | Lemma C.5. Suppose Algorithm two selects a Type two step at iteration k with Dtype equals S O L and @k equals one, that is, an update of the form\n8jez | with possible reordering. Under Assumptions three point one, three point five and three point seven, we have\nbhki | negative eight k plus one I k divided by E k; E k equals,\nq8rl | T I S K greater than or equal to co min S I k,\ngsah | where\nt5nl | zero L g plus zero two one two plus two L H O two two zero",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394552,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1573,
    "prompt_tokens": 3367,
    "total_tokens": 4940
  }
}