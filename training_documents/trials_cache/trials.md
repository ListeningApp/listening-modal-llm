## CLINICAL TRIALS SESSION THREE THE SIZE OF TRIALS

One Objectives

The aim of this session is to understand the importance of recruiting sufficient numbers into a trial and be able to calculate the required sample size when designing a trial.

By the end of this session students will be able to:

· Understand the importance of the size of a trial to provide reliable results

· Explain the key factors in determining the required size for a particular trial

· Discuss the importance of power for sample size calculations

· Calculate a sample size for a trial based on two percentages (or proportions) or means

· Adjust sample sizes to allow for factors such as losses to follow-up

· Discuss the problems of trials which are too small


## Two Introduction

In previous sessions the focus has been on the importance of randomisation, control groups and blinding (where appropriate) to avoid bias in the results from a clinical trial. A further key issue in the design of a clinical trial is ensuring there are sufficient numbers of patients.

The aim of a trial should be to provide reliable evidence of the effectiveness and safety of a treatment. To achieve this, enough patients are needed in our trial to give a good chance of detecting a clinically important treatment difference if such a difference exists, while being able to reasonably conclude that no such difference exists if our results do not show it.

Given the importance of sample size there are several approaches that can be taken to answer the question "How many patients do we need?". For example:

(One) Statistical/scientific approach. This approach is concerned with determining how many patients are needed to get firm evidence of a treatment difference if it exists, and to estimate any difference precisely (i.e. within a sufficiently small confidence interval).

(Two) Economic/pragmatic approach. In reality, other constraints will impact on the ability to recruit the numbers required from a purely statistical approach. For example, how many patients are available, and how much time, effort and cost is involved?

(Three) Ethical approach. In many clinical trials decisions need to be made as to how long it is ethical to continue a trial. The question that might be asked here is "How soon can we stop a trial to avoid some patients getting inferior treatment?". This will be dealt with in detail in session four: "Data Monitoring".

(Four) Credibility. If a trial is very small, its results may not be seen as providing believable evidence.


## Three point One

In determining the required size of a trial all of the above approaches are usually considered, but this session is mainly concerned with (One) the statistical approach. The compromises to be made between purely scientific objectives and practical constraints, and the implications of trials which are too small will also be considered.

In order to appreciate the impact of sample size for interpreting trial results consider the table below showing the results from two placebo-controlled trials assessing the impact of streptokinase for reducing mortality in patients who have experienced a myocardial infarction.

P is less than point zero zero zero one Risk ratio equals zero point seven seven with ninety-five percent confidence interval ranging from zero point seven zero to zero point eight four. The estimated treatment effect is very similar in the two trials. Further, the proportions of patients who die in the two trials are also very similar. However, while the ISIS-two trial provides very strong evidence of a treatment effect with P is less than point zero zero zero one and a tight confidence interval, the first Australian trial is unconvincing with P equals zero point three two and a wide confidence interval. Even though more than five hundred patients were recruited, the trial was too small in these circumstances.


## Three Key factors in determining the required sample size

The previous section indicated the impact the size of a trial can have on the interpretation of results. In particular, trials which are too small lead to results which are inconclusive. There are a number of key factors that determine the required size of a trial and in particular there are five key questions that need to be asked. In order to illustrate these factors, the UK PACE study in fitting a dual chamber versus single chamber pacemaker for patients with atrioventricular block is used.

Note that while questions (Two) and (Five) are more technical these are fairly standard whereas questions (Three) and (Four) are perhaps the most important and difficult to address. The answers to these two questions will have the most impact on the required size as will be shown later in the session.


## (One) What is the principal outcome measure of the trial?

In designing a trial, a suitable primary outcome measure is chosen to reflect the main purpose of conducting the trial. The sample size requirements need to be based on this outcome measure in order to reliably address the prime purpose of the trial.

For example, in the UK PACE trial the purpose was to assess whether dual chamber pacing could reduce mortality compared to the more usual single chamber by comparing mortality at four years.


## Three point Two

(Two) How will the data be analysed to detect a treatment difference?

Some thought should be given to the appropriate analysis for the outcome being measured. For example, is the outcome the occurrence of some event (e.g. death) or a continuous outcome (e.g. blood pressure). In addition, the level of statistical significance that will be accepted as indicating evidence of a treatment difference should also be considered. This is usually set at five percent i.e. if the final P-value is less than zero point zero five then this would be accepted as there being some evidence for a real treatment effect.

For example, the simplest analysis for the UK PACE trial is a comparison between the groups of the percentage of patients who die within four years of randomisation using a chi-squared test. A five percent significance level was used.

(Three) What results are expected in the control group?

Clearly the results that will be observed in the control arm will not be known. However, there may well be information from previous trials or observational studies as to what might be expected.

For example, in the UK PACE trial it was expected that twenty-four percent of patients would die by four years in the single chamber group.


## (Four) How small a treatment difference, if it exists, is important to detect?

This is perhaps the key decision that needs to be taken in determining sample size. If a very large treatment difference exists, then this can be detected with relatively few numbers. For example, in the UK PACE trial if the dual chamber pacing reduced mortality by three-quarters (i.e. from twenty-four percent to six percent) then relatively few patients are needed (in fact less than two hundred). Of course, such a difference is unlikely and, more importantly, a difference much smaller than this would be clinically very important to detect if it were true.

It could be argued that any difference would be important to detect but this is unrealistic as huge trials would be required (an example of this will be given later). What needs to be decided upon is the smallest clinically relevant difference that would be important to detect if it were true.

For example, in the UK PACE trial it was decided that a one quarter reduction (i.e. from twenty-four percent to eighteen percent) would be clinically important to detect.


## (Five) What degree of certainty is needed to be able to detect the treatment difference in (Four)?

In a clinical trial conclusions are based on observed treatment effects rather than the true, unknown effects. These observed effects could be larger (i.e., further away from the null hypothesis of no effect) but could also be smaller (i.e., closer to the null hypothesis of no effect) than the true effects. The trials need to give a good chance of providing evidence for a treatment difference even if the observed effects are smaller than the true effects. The chances of this can be improved by increasing the numbers in our trial.

For example, the investigators in the UK PACE trial wanted to be ninety percent sure of picking up a statistically significant result if a true difference of twenty-four percent versus eighteen percent existed.


## Three point three

In total, the UK PACE trial needed to recruit approximately two thousand patients to satisfy the above criteria as will be seen in later sections.


## Four Type One and type Two errors

Note the true population values in each treatment group are not known but in calculating the sample size some estimate of these values are needed based on the alternative hypothesis. In the following sections the observed and anticipated percentages will be distinguished using the following notation:

p one equals the observed percentage in those on standard treatment p two equals the observed percentage in those on "new" treatment i.e., p one minus p two is the observed treatment effect (observed absolute percentage reduction on "new" treatment)

Pi one equals percentage in those on standard treatment. Pi two equals anticipated percentage in those on "new" treatment.

i.e., Pi one minus Pi two is the true difference which has been decided it is important to detect.

Further notations are as follows:

Alpha equals significance level for detecting a difference (usually set at zero point zero five or five percent).

One minus beta equals degree of certainty that a true difference of Pi one minus Pi two would be detected i.e., the power (often aim for one minus beta equals zero point nine or ninety percent power).

Consider the table below. Ideally, the results of the trial should fall either:

(i) in the top left-hand cell of the table, i.e., if, in truth, no difference exists (the null hypothesis), then no evidence for a difference is observed in the trial, or

(ii) in the bottom right-hand cell of the table, i.e., if, in truth, a difference of Pi one minus Pi two does exist (the alternative hypothesis), then evidence for a difference is observed in the trial.

These are marked by X in the table.

(ii) a true Pi one minus Pi two difference


## Truth

No significant difference observed Significant difference observed

X Three point four

However, there are two particular types of errors that can be made in interpreting trial results. These are referred to as type One and type Two errors.

Type One error. A type One error is when a treatment difference is claimed based on a statistically significant observed result when in truth no such difference exists i.e., a false positive result.

Type Two error. A type Two error is when in truth there exists a difference of T1 minus T2 but the observed results fail to reach statistical significance, i.e., a false negative result.

Alternative ways of describing Alpha and Beta are as follows and are represented in the table below:

(ii) the alternative hypothesis being true

No significant difference observed

Significant difference observed Alpha

It needs to be decided in advance what levels will be set for Alpha and one minus beta and in the following sections the influences of the choice of these on the required sample size will be demonstrated.


## Five Comparing two percentages (or proportions) - power calculation

Five point one Sample size formula using five percent significance and ninety percent power

Up to now the key factors needed in calculating a sample size have been considered and the concept of power in this process has been introduced.

In the UK PACE example the intended power was set at ninety percent. This means that if the true underlying percentages are twenty-four percent and eighteen percent, there is a ten percent probability that the observed results will give p greater than zero point zero five. This will occur if the observed difference is less than the true difference to the extent that it is more compatible with the null hypothesis of no difference. Some risk of a false negative result has to be accepted (otherwise an infinitely large study is needed).

Note that some risk of a false positive result also has to be accepted: it is quite possible that p less than zero point zero five might be observed even if there is no true treatment difference.


## Three point five

Common choices for Alpha (significance level) and one minus beta (power) are zero point zero five and zero point nine zero respectively as already stated. Based on these choices, the equation to calculate the required sample size in each group for the comparison of two proportions is given below:

There are two key notes that you need to be aware of given below.

Note one: The above equation calculates the required number of patients required in each group. Therefore for a trial with two treatments (with equal numbers planned for each group), the required number of patients in total is double this amount.

Note two: Up to this point the outcomes have been considered as percentages. If proportions are preferred in the calculation of the sample size then the above equation must be adapted by substituting one in place of one hundred throughout.

By using the sample size formula above, the total sample size required for the UK PACE trial is one thousand nine hundred twenty-six (nine hundred sixty-three in each group). In practice the UK PACE trial aimed to recruit two thousand patients.

Note that the aim of a sample size calculation is to approximate the number of patients required rather than provide exact figures. There are several assumptions that need to be made including the anticipated true values which of course cannot be known.


## Five point two. More general formula for any combination of significance and power.

The formula given for the comparison for two proportions is based on a type one error of alpha equals zero point zero five (equating to a significance level of five percent) and a type two error of beta equals zero point one (equating to ninety percent power). However, a more general formula for different values of alpha and beta is needed.

A more general formula is as follows:

where F(alpha, beta) is a function of alpha and beta. The table below provides the value of F(alpha, beta) for different values of alpha and beta.


## Three point six

Note that the value of F(alpha, beta) can be calculated for any level of alpha and beta and this is given by the formula below (you will need to understand what Z one minus alpha over two and Z one minus beta represent: the z-distribution has a mean of zero with a standard deviation of one).

F(alpha, beta) equals (Z one minus alpha over two plus Z one minus beta) squared. For example, for alpha equals zero point zero five and beta equals zero point one: F(alpha, beta) equals (one point nine six plus one point two eight) squared equals ten point five. For example, for alpha equals zero point zero five and beta equals zero point two: F(alpha, beta) equals (one point nine six plus zero point eight four) squared equals seven point eight five. Six. Impact of choice of scientific criteria on sample size.

The key factors required in order to calculate the required sample size and needed for a trial comparing two percentages have been introduced. Assuming the primary outcome variable has been identified these are (one) the expected percentage or risk in the control arm, (two) the smallest clinically important difference that needs detecting, (three) the level of significance, and (four) the power to detect the difference specified in (two) if such a true difference exists.

While a set significance (usually five percent) and power (usually ninety percent or eighty percent) can be specified, perhaps the most important assumptions that need to be considered are for the unknown underlying risk in the control group and the smallest clinically important decision that needed to be detected.

Some flexibility is usually needed in assessing sample size requirements and it is a useful exercise to calculate the numbers needed for several different scenarios. In this section the impact of altering each of the four criteria given above on the sample size for comparing two percentages will be demonstrated using the UK PACE trial. Note that previous calculations showed one thousand nine hundred twenty-six patients were required based on the following criteria:

Expected mortality in the single chamber arm (pi one) equals twenty-four percent. Expected mortality in the dual chamber arm (pi two) equals eighteen percent (i.e. one quarter reduction) alpha equals zero point zero five, beta equals zero point one (power equals ninety percent) i.e.

F(alpha, beta) equals ten point five. (one) Impact of reducing the difference to detect.

Suppose one quarter reduction is considered unrealistically high and decide an absolute difference of three percent from twenty-four percent would be clinically important to detect (i.e. pi one minus pi two equals three percent). The total sample size required is eight thousand one hundred twenty-eight. Halving the absolute difference to detect for a given expected percentage outcome in the control arm resulted in more than quadrupling the sample size.

(two) Impact of overestimating the event rate in each group.

Suppose the true mortality is half that expected in both groups i.e. pi one equals twelve percent, pi two equals nine percent. Note that this is still a one quarter reduction in mortality. The total sample size required is four thousand three hundred seventy-six, more than double the initial estimate.

Note however that this assumes the relative effect remains the same i.e. a quarter reduction. For a given absolute difference to detect, the total number decreases as the event rate decreases (for event rates below fifty percent). For example, suppose it is required to detect a difference of twelve percent versus six percent, then the total sample size would be nine hundred forty-six, but this represents a halving in mortality.

(three) Impact of reducing the significance level (i.e. reducing risk of a type one error).

Suppose more stringent evidence for a treatment difference is required and the level of significance is set to be one percent i.e. require P less than point zero one to claim a treatment difference. F(alpha, beta) now becomes fourteen point nine, and the total sample size needs to be increased to two thousand seven hundred thirty-two.

(four) Impact of increasing the power (i.e. the risk of a type two error).

Suppose it is required for the study to give more chance of finding a treatment difference and ninety-five percent power is used. F(alpha, beta) now becomes thirteen point zero, and the total sample size needs to be increased to two thousand three hundred eighty-four.

In practice, these calculations are usually done using computer packages, such as Stata, R or Epi-Info. The number of patients which different packages arrive at may differ slightly from those above as slightly different approximations are used.

In deciding upon the required size of a trial, the numbers are often disappointingly large in respect of investigators' expectations and available patients. For example, reducing the absolute required difference to detect by half meant increasing the sample size more than fourfold.

Sample sizes entail some judgement, and some compromise between using stringent statistical criteria and what can practically be achieved is required. However, the choices to be made need to be realistic.


## Comparing two means

In some clinical trials, the primary endpoint is a continuous outcome, e.g. kidney functioning as measured by glomerular filtration rate or systolic blood pressure, rather than the occurrence of some binary event, e.g. mortality. The principles behind calculating the required sample size when the outcome is a comparison of two means are the same as when comparing two percentages.


## Seven point one. Sample size formula.

However, one additional factor that needs to be considered is the standard deviation of the outcome in each treatment group. In this section it is assumed that the standard deviation is the same for each treatment group although alternative formulae are available when this is clearly not the case. The standard deviation can be estimated from previous observational studies or in some cases a pilot study will be required. However, as when considering two percentages, it is advisable to calculate the required sample size for a number of different scenarios.

To distinguish between means and percentages, U one and U two will be used to refer to the anticipated means in the two treatment groups.

As for the comparison of percentages, there are certain assumptions and decisions that need to be made. These are as follows:

U one equals anticipated mean response on the standard treatment mu sub two equals anticipated mean response on the alternative treatment sigma equals standard deviation of response (assumed the same on both treatments)

alpha equals risk of a type I error (significance level)

beta equals risk of a type II error (one minus beta equals power). Once these values have been decided upon, the required number per group can be calculated as follows:

N equals F of alpha and beta times two sigma squared divided by mu sub one minus mu sub two squared in each group. Note that the actual values of mu sub one and mu sub two are less important than the treatment difference to be detected. Suppose eight is the anticipated treatment difference then the above formula can be written as:

N equals F of alpha and beta times two sigma squared divided by delta squared in each group. Seven point two example in kidney transplantation.

The REPAIR trial was designed to assess the impact of remote ischaemic preconditioning (RIPC) using repeated inflations of a blood pressure cuff on kidney function in patients undergoing kidney transplantation. The outcome of interest is a glomerular filtration rate at one year.

The assumptions are as follows:

Eight equals four point seven three milliliters per minute per one point seven three meters squared superiority with RIPC equals mu sub one minus mu sub two equivalent to a ten point nine six percent improvement. Sigma equals thirteen point nine milliliters per minute per one point seven three meters squared from a previous study.

Alpha equals zero point zero five. Beta equals zero point two, i.e., power equals zero point eight or eighty percent. The number required in each group is two hundred twenty-two times seven point eight five times two times thirteen point nine squared divided by four point seven three squared equals one hundred thirty-six. Two hundred seventy-two in total.

To allow for losses to follow-up, the trial requires approximately three hundred twenty patients.

It has been seen already when estimating the sample size for comparing percentages that as the absolute difference to detect decreases then the number required increases. In addition, as the significance level decreases or as the power increases this also leads to an increase in the numbers required (by increasing F of alpha and beta). The same principles apply when comparing means as can be seen from the sample size formula.

The impact of the standard deviation (sigma) also needs to be considered when comparing means. As the standard deviation increases so the number required in each group also increases. For example, suppose that the standard deviation was estimated to be fourteen point nine instead of thirteen point nine in the example given previously.

The number required in each group becomes two hundred twenty-two times seven point eight five times two times fourteen point nine squared divided by four point seven three squared equals one hundred fifty-six. Three hundred twelve in total.

Conversely, as the estimated standard deviation decreases so does the number of patients required. For example, suppose that the standard deviation was estimated to be twelve point nine percent.

The number required in each group would be two hundred twenty-two times seven point eight five times two times twelve point nine squared divided by four point seven three squared equals one hundred seventeen, i.e., two hundred thirty-four in total.


## Seven point three potential of adjustment in the analysis on the sample size for comparing two means.

It has already been stated that sample sizes are often disappointingly large even before making any adjustments. However, there is one scenario where it may be possible to reduce the required size if the primary outcome is a continuous measure which is also measured at baseline.

A detailed discussion is beyond the scope of this session and requires an understanding of an analysis technique called 'analysis of covariance' (ANCOVA). Basically, this method takes advantage of the fact that the outcome measure for individual patients is likely to be strongly correlated to the baseline value. For example, in the REPAIR trial, an estimate of the glomerular filtration rate of the transplanted kidney from the living donor is available and is expected to be correlated to the kidney function at one year following transplantation. This information was used in the analysis of the data.


## Eight Adjustments to sample size calculations

In the calculations so far it has been assumed that full information is available on everyone (i.e. no losses to follow-up) and also that every patient receives the treatment they are allocated. In reality this is rarely achieved and some adjustments to the sample size needs to be made to account for this.

In this section the implications of these two scenarios will briefly be considered including what adjustments can be made. Note that these adjustments make certain assumptions but provide useful guidance to the number required. In addition, the situation where more patients will be randomized to one group than the other will also be discussed.


## Eight point one Losses to follow-up

If patients are lost to follow-up for some endpoint then this reduces the effective sample size. For example, if two percent of patients in the United Kingdom PACE trial were expected to be lost to follow-up for mortality then the effective sample size of one thousand nine hundred twenty-six would be reduced by two percent (although in the United Kingdom, the Office of National Statistics can notify the trial when a patient dies).

Suppose the proportion expected to be lost to follow-up is 'Q' then, in order to adjust for this, the total sample size needs to be multiplied by one divided by (one minus Q). For example, the United Kingdom PACE trial would need to be increased to one thousand nine hundred twenty-six times (one divided by zero point nine eight) equals one thousand nine hundred sixty-six.


## Eight point two Patients who receive the alternative treatment

In many trials some patients will receive the alternative treatment. The impact of this is to make the groups more similar and therefore potentially reduce the observed treatment effect and therefore power is lost. In order to allow for this a correction formula is given below.

Let Q one equal proportion in group one getting the treatment for group two. Let Q two equal proportion in group two getting the treatment for group one.

Correction formula: multiply the required sample size by

(one minus Q one minus Q two) squared.

For example, suppose in the United Kingdom PACE trial:

One percent of patients randomized to the single chamber group received the dual chamber treatment. Two percent of patients randomized to the dual chamber group received the single chamber treatment.

The required size equals (one minus zero point zero one minus zero point zero two) squared times one thousand nine hundred twenty-six equals two thousand forty-eight

Alternatively the treatment effect to be detected might already account for the impact of patients receiving the alternative treatment.

Clearly, it is desirable to limit the number of patients who switch treatments and if the percentages become too large then interpretation becomes increasingly difficult. This is particularly important in non-inferiority trials where the aim is to show treatments are similar.


## Eight point three Patients who stop treatment

One simple adaptation to the formula introduced on the previous page relates to placebo controlled trials where a proportion, Q, on the active therapy stops taking their medication. For the purposes of the sample size adjustment, the proportion who stop their placebo medication is less important (as the randomized treatment contains no active ingredient expected to affect outcome).

The impact will be to make the active treatment group more similar to the placebo group. The correct formula used is to multiply the sample size by one divided by (one minus Q) squared.

As mentioned, certain assumptions are made (for example, that those stopping active therapy do so early in the trial) but the adjustments do provide useful guidance.


## Eight point four Other adjustments

A trial which randomizes patients to two treatment groups of equal size is usually the most efficient design in terms of total numbers required. However, it is sometimes the case that more patients are randomized to one group than the other.

Suppose patients are to be randomized to two groups in the ratio r:one. Then the total sample size required for equal numbers needs to be increased as follows:

Three point eleven

Multiply the sample size by

(r plus one) squared divided by four r. For example, in the United Kingdom PACE trial, suppose the investigators wanted to randomize patients in the ratio two to one to the dual chamber treatment. The total sample size would need to be increased as follows:

one thousand nine hundred twenty-six times (two plus one) squared divided by eight equals two thousand one hundred sixty-six. Since the required ratio is two to one, the number required in the dual chamber group would be (two thousand one hundred sixty-six times two divided by three) equals one thousand four hundred forty-four, and the number required in the single chamber group seven hundred twenty-two.


## Nine Trials which are too small and other issues

There are a number of important problems associated with trials which are too small. Such trials will be underpowered to detect realistic treatment differences, i.e. increasing the chance of a false negative result. In addition, the observed treatment effects could be far from the true values (whether the null hypothesis or some alternative hypothesis is true). These observed effects will also be measured imprecisely.

Unfortunately many trials are too small and as a result will be unable to reliably answer clinically meaningful questions. In addition they use valuable resources and it could be considered unethical to expose patients in a trial which has little chance of being able to address a clinically meaningful question.

In addition the results can be misleading and potentially lead to publication bias. Suppose a number of small trials are conducted addressing a similar question. It is likely that some small trials will produce results showing a large, statistically significant effect which might be a chance finding or at best an exaggeration of the truth. The trials showing a significant effect are more likely to be written up and accepted for publication.

Trials which are too small are a hindrance to medical progress but finding adequate numbers of patients is not easy. In addition investigators may be over-optimistic in the ability of a trial to recruit eligible patients and recruitment often takes longer than expected. Therefore a realistic appraisal of resources and potential patient accrual is needed.

However, there are a number of ways in which numbers can be potentially increased.

The trial may need to be conducted as a multi-centre collaboration. Patient accrual will be quicker and more eligible patients available.

Avoid being too restrictive in respect of the patient entry criteria. This will also have the advantage of making the results more broadly applicable.

Trials of more than two treatments require more patients so some thought is necessary as to any benefits of including more than two treatment groups. One possible approach would be through the use of a factorial design (see session eight).

In this session the main techniques have been covered to calculate sample size when comparing percentages and means for a clinical trial where each individual is randomized. Similar considerations are needed when estimating the required sample size for other measures of effects, e.g. rates which account for varying follow-up times, however a detailed discussion of these formulae is beyond the scope of this module but included in the articles in the references.

Three point twelve

In addition, other sample size considerations are required depending on the trial design, e.g. when the aim is to show one treatment is equivalent (or non-inferior) to another treatment or when groups (or clusters) are randomized rather than individuals. These will be discussed in more detail later in the module (sessions seven and eight).


## Ten Summary

In this session the importance of estimating the required number of patients needed to produce a clinically meaningful result has been discussed. Sample size formulae have been introduced for comparing percentages (or proportions) and means together with adjustments which can be made under different conditions. More complex formulae exist but give similar results.

Trials which are too small are highly unlikely to produce conclusive results particularly for realistic moderate effects. Such trials could be considered unethical by exposing patients to a trial which has little chance of being able to address a clinically meaningful question.

It is helpful to produce tabulations under different scenarios. Realistic evaluation is needed to as to whether a trial is feasible given the resources both in terms of costs and patient availability.

Three point one three