{
  "id": "chatcmpl-A3UFyb5nIIlZ7OLCIAFf8AhiPPavK",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "sod4 | f of x equals c x\n2x2r | for any real constant c. But are there any other solutions?\n4gct | Yes, if you use the axiom of choice! Treat the reals as a vector space over the rationals. Using the axiom of choice, pick a basis. To get f from the reals to the reals that's linear over the rational numbers, just let f send each basis element to whatever real number you want and extend it to a linear function defined on all of R. This gives a function f that obeys f of x plus y equals f of x plus f of y.\nuuio | However, no solutions of f of x plus y equals f of x plus f of y meet our other condition\ne34x | x less than y implies f of x greater than f of y for all x, y less than or equal to zero\n8w73 | except for the familiar ones f of x equals c x. For a proof see Wikipedia: they show all solutions except the familiar ones are so discontinuous their graphs are dense in the plane!\n6ndf | So, our conditions imply f of x equals c x for some c, and since f is decreasing we need c less than zero. So our formula I of p equals f of ln p says\nx2p2 | I of p equals c ln p\nyhgh | but this equals negative log of p if we take b equals exp of negative one over c. And this number b can be any number greater than one. QED.\njjti | Thus, if we want a more general concept of the information associated to a probability, we need to drop Condition one or two. For example, we could replace additivity by some other rule. People have tried this! Indeed, there is a world of generalized entropy concepts including Tsallis entropies, Renyi entropies and others.\nuw2x | WHAT IS PROBABILITY?\n1rbl | Since I've defined information in terms of probability, you may naturally wonder \"what is probability?\" I won't seriously try to answer this. This question has stirred up many debates over the centuries, and even today there's not a fully accepted answer. It deserves a whole book-and this is not that book. Luckily, we don't really need to know exactly what probability is to do calculations with it: we mainly need to set up some rules for working with it. This may seem like a cop-out. But it's a strange and wonderful feature of science that we can achieve great reliability in our results by sidestepping certain difficult questions, like someone who can make their way safely through a jungle by avoiding the quicksand and snakes.\nwr7g | One approach to probability goes like this. Suppose you repeat some experiment N times, doing your best to make the conditions the same each time. Suppose that M of these times some event E occurs. You may then say that the probability of event E happening under these conditions is M over N. This approach is called 'finite frequentism'. Unfortunately, this approach can lead you to say a coin has probability one of landing heads up if it does so the first time, or first three times, you flip it.\nbph4 | Another approach goes like this. You may say that some event E has probability p under some conditions if when you set up these conditions N times, and the event E happens M times, the fraction M over N approaches p in the limit N goes to infinity. This approach is called 'hypothetical frequentism', because in real experiments you can't take the limit N to infinity. But you can hope that when N becomes large enough, the fraction M over N usually becomes close to the limiting probability p-whatever that means.\ntzxi | Another approach, called 'Bayesianism', treats a probability of an event E under some specified conditions as a measure of your degree of belief that E will happen under these conditions. But what is 'degree of belief'? One answer involves bets. For example, perhaps to believe an event has probability one half means you're willing to take a bet where you win more when the event happens than you lose if it does not.\no4i7 | Bayesians tend to focus on the rules for updating your probabilities as you learn new things, the most famous being 'Bayes' rule'. Even if agents start by assigning different probabilities to an event, if they follow the same rules for changing these probabilities as they learn new things, under certain circumstances we can prove their probabilities will converge to the same value.\n2sts | For a passionate and intelligent discussion of these issues, I recommend E. T. Jaynes' book Probability Theory: the Logic of Science. Later we'll meet his 'principle of maximum entropy', another important approach to working with probabilities.\nzx3s | PROBABILITY MEASURES\n6c25 | A measure on a set X is a function that assigns to certain so-called measurable subsets S of X a number p of S in the interval from zero to one, obeying these rules:\n2ese | . The empty set and X are measurable and\nxvzx | m of the empty set equals zero\nt08l | . If S, T in X are measurable and S is a subset of T, then T minus S is measurable and\nk6vc | m of T equals m of S plus m of T minus S\nlnqw | . If a countable collection of disjoint subsets Si of X are measurable, then their union is measurable and\nkdr7 | m of the union of Si equals the sum of m of Si i equals one to infinity\nh1ds | We say m is a probability measure if m of X equals one.\nsgu6 | It is easier to do calculations with probabilities than say exactly what they mean! I will take a rough-and-ready approach to working with them, but first let's take a peek at how mathematicians do it. If you don't care, it's safe to move right on to the next tweet.\n47j0 | We start with any set. We call elements of X 'outcomes' and subsets of X 'events'. We can sometimes get into trouble trying to assign a probability to every subset of X. So, we'll only try to assign probabilities to events in some collection M with these properties:\n1c60 | · The empty set is in M and X is in M.\n0gex | . If S, T are in M and S is a subset of T then the set of elements of T that are not in S, called T minus S, is in M.\n8r7m | . If Si is in M for i equals one, two, and so on then the union Si is in M.\nqj19 | We call elements of M measurable subsets of X. A measure is then a function m from M to zero to one obeying these rules:\nl5ia | · m of the empty set equals zero\necp0 | · If S, T are in M and S is in M then m of T equals m of S plus m of T minus S.\ncujm | . If Si is in M then m of the union Si equals the sum of m of Si.\n25y0 | If M also obeys m of X equals one then we say M is a probability measure, and for any S in M we say m of S is the probability of the event S. But we will also be interested in other measures, like the measure on the real line called 'Lebesgue measure'. This is closely connected to the symbol d x that shows up in integrals, because for any measurable set S is a subset of the reals, its Lebesgue measure is",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394654,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1587,
    "prompt_tokens": 3324,
    "total_tokens": 4911
  }
}