You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document.

Your task is to label each textbox with exactly one of the following labels:
  title: the primary document title, no more than one per document
  heading: the name of the following chapter or section (should never start in the middle of the previous paragraph)
  subheading: a secondary heading, often following another heading (should never start in the middle of the previous paragraph)
  body: main paragraph content: may start or end in the middle of a word, use context to follow paragraphs that are split across textboxes (if a textbox contains both heading and body text, label it "body")
  math: textbox primarily containing math
  imageDescription: standalone callout that only describes an image, chart, table, or similar (typically begins with "Table...", "Figure...", "Fig. ...", "Above...", "Left...", etc.)
  authors: names of contributors to this document
  institutions: list of universities, business, and other institutions affiliated with this document
  publisher: info about the publisher, or provided by the publisher, including copyright info
  pagenum: the page number
  headerOrFooter: boilerplate text page number, or redundant headings at the top/bottom of the page
  toc: the table of contents
  references: bibliographic references and resources
  acknowledgements: thanks and credits to contributors
  appendix: index, appendix, or any other end matter not part of the main thread (including related headings)
  table: tabular data, label, title, or subheading for a grid or list of data
  datum: numeric data or data label from a chart or list
  advertisement: promotional ads and marketing
  layout: non-content related to the layout of the page, e.g. sidebar navigation
  callout: pull quote or long block text that stands apart from the main text
  footnote: footnotes and endnotes near the bottom of the page
  keywords: list of keywords or tags
  url: web address or email
  other: any other text that does not belong to the main thread

Each line of input is prefixed with a textbox ID in the format `id | Text content`. The output must be in the format `id | label`.

Note that body text may be split across multiple textboxes, and textboxes may start or end in the middle of a sentence or word. Because the text was extracted from a web page or document, paragraphs of body text may be interrupted by multiple textboxes of redundant headers, footnotes, page numbers, tables, images, etc. For example, a real heading will never interrupt the middle of a sentence. Use context clues like this to carefully label each textbox.

EXAMPLE INPUT:
1pjs | Neuroscience Applied 1 (2022) 101012
o2kr | Contents lists available at ScienceDirect
v6sk | Neuroscience Applied
1wj6 | journal homepage: www.journals.elsevier.com/neuroscience-applied
936l | Research Articles
06yq | Microdosing with psychedelics to self-medicate for ADHD symptoms in adults: A naturalistic study
dpv6 | ARTICLE INFO
8r5j | ABSTRACT
2taz | Keywords: ADHD Microdosing Psychedelics Self-medication Well-being Time perception
o3ya | ADHD in adulthood is often overlooked, which negatively affects the individual's well-being. First-line phar- macological interventions are effective in many ADHD patients, relieving symptoms rapidly. However, there seems to be a proportion of individuals who discontinue, or fail to respond to these treatments. For these in- dividuals, alternative treatment options should be explored.
r5il | 1. Introduction
5gui | Attention deficit hyperactivity disorder (ADHD) is one of the most common developmental disorders worldwide. Prevalence research indicates that 2.6% of the adult population has persistent ADHD. ADHD in adults is often overlooked because of the high comorbidity rate and lack of knowledge about how ADHD is expressed in adulthood (Kooij et al.,
9d4o | Fig. 1. Flowchart of included participants for each time point.
82qc | 2019). In addition, ADHD is associated with deficits in various domains of cogni- tive functioning. Twenty-five percent of ADHD cases suffered from ADHD symptoms purely because of de- ficiencies in temporal processing (Sonuga-Barke et al., 2010).
ls7d | First-line ADHD treatments in adults mainly include pharmacological interventions to enhance dopaminergic and noradrenergic neurotrans- mission with stimulants. Overall, they have been proven to work effectively in adults with ADHD, inducing fast symptom relief and thereby enhancing the person's quality of life. In the
5esx | Table 1 Demographic information from respondents at baseline and the two and four- week time points.
t8vv | longer term, approximately twenty percent of ADHD patients discontinue their prescribed medication after six to nine months, thirty percent after one year, and half of them after two years.
xrd1 | 2. Material and methods
5746 | 2.1. Study design and participants
7toz | The study employed a naturalistic design, assessing the experiences of participants at baseline,
j346 | Neuroscience Applied 1 (2022)
m5ka | E.C.H.M. Haijen et al.
kx2c | REVIEW
v8uq | before they start MD on their own initiative, and at two and four weeks after MD initiation. The target population included adults diagnosed with ADHD and individuals who experienced ADHD symptoms to the extent that these interfered with their daily lives and who had not been diag- nosed with ADHD before. To be included in the analyses, participants needed to score above a cut-off point on at least one of the subscales of the Conner's Adult ADHD Rating Scale (CAARS-S:SV).
2zmw | Fig. 2. Mean scores of the CAARS-S:SV DSM-IV total symptoms T-scores at baseline (0W) and two (2W) and four weeks (4W) after MD (A) of the whole sample, and (B) per conventional ADHD medication use. Error bars represent mean error.
sdk3 | <LATEX>\lim _ { x ightarrow \infty } rac { 6 x ^ { 2 } + 1 0 0 } { 7 x ^ { 2 } - 1 0 } =</LATEX>
x972 | 2.2. Study procedure
k221 | Mean performance measures of the CAARS-

EXAMPLE OUTPUT:
1pjs | headerOrFooter
o2kr | publisher
v6sk | publisher
1wj6 | publisher
936l | headerOrFooter
06yq | title
dpv6 | other
8r5j | heading
2taz | keywords
o3ya | body
r5il | heading
5gui | body
9d4o | imageDescription
82qc | body
ls7d | body
5esx | imageDescription
t8vv | body
xrd1 | heading
5746 | subheading
7toz | body
j346 | headerOrFooter
m5ka | authors
kx2c | headerOrFooter
v8uq | body
2zmw | imageDescription
sdk3 | math
x972 | heading
k221 | body




oczy | These three problems are elegantly circumvented if a convolutional network is replicated over the input field. First of all, as shown in Section III, convolutional NN's are very robust to shifts and scale variations of the input image, as well as to noise and extraneous marks in the input. These properties take care of the latter two problems mentioned in the previous paragraph. Second, convolutional networks provide a drastic saving in computational requirement when replicated over large input fields. A replicated convolutional network, also called an SDNN [27], is shown in Fig. 23. While scanning a recognizer can be prohibitively expen- sive in general, convolutional networks can be scanned or replicated very efficiently over large, variable-size input fields. Consider one instance of a convolutional net and its
2ttg | alter ego at a nearby location. Because of the convolutional nature of the network, units in the two instances that look at identical locations on the input have identical outputs, therefore their states do not need to be computed twice. Only a thin "slice" of new states that are not shared by the two network instances needs to be recomputed. When all the slices are put together, the result is simply a larger convolutional network whose structure is identical to the original network, except that the feature maps are larger in the horizontal dimension. In other words, replicating a convolutional network can be done simply by increasing the size of the fields over which the convolutions are performed and by replicating the output layer accordingly. The output layer effectively becomes a convolutional layer. An output whose receptive field is centered on an elementary object will produce the class of this object, while an in-between output may indicate no character or contain rubbish. The outputs can be interpreted as evidences for the presence of objects at all possible positions in the input field.
his3 | The SDNN architecture seems particularly attractive for recognizing cursive handwriting where no reliable segmen- tation heuristic exists. Although the idea of SDNN is quite old and very attractive in its simplicity, it has not generated wide interest until recently because, as stated above, it puts enormous demands on the recognizer [26], [27]. In speech recognition, where the recognizer is at least one order of magnitude smaller, replicated convolutional networks are easier to implement, for instance in Haffner's multistate TDNN model [78], [85].
m50z | A. Interpreting the Output of an SDNN with a GTN
me84 | The output of an SDNN is a sequence of vectors which encode the likelihoods, penalties, or scores of finding char- acter of a particular class label at the corresponding location in the input. A postprocessor is required to pull out the best possible label sequence from this vector sequence. An example of SDNN output is shown in Fig. 25. Very often, individual characters are spotted by several neighboring instances of the recognizer, a consequence of the robustness of the recognizer to horizontal translations. Also quite often, characters are erroneously detected by recognizer instances that see only a piece of a character. For example a recognizer instance that only sees the right third of a "4" might output the label 1. How can we eliminate those extraneous characters from the output sequence and pull out the best interpretation? This can be done using a new type of GT with two input graphs as shown in Fig. 24. The sequence of vectors produced by the SDNN is first coded into a linear graph with multiple arcs between pairs of successive nodes. Each arc between a particular pair of nodes contains the label of one of the possible categories, together with the penalty produced by the SDNN for that class label at that location. This graph is called the SDNN output graph. The second input graph to the transformer is a grammar transducer, more specifically a finite-state transducer [86], that encodes the relationship between input strings of class labels and corresponding output strings of recognized characters. The transducer is a weighted
o56m | Fig. 24. A GT pulls out the best interpretation from the output of the SDNN.
slz6 | Fig. 25. An example of multiple character recognition with SDNN. With SDNN, no explicit segmentation is performed.
90k5 | finite state machine (a graph) where each arc contains a pair of labels and possibly a penalty. Like a finite-state machine, a transducer is in a state and follows an arc to a new state when an observed input symbol matches the first symbol in the symbol pair attached to the arc. At this point the transducer emits the second symbol in the pair together with a penalty that combines the penalty of the input symbol and the penalty of the arc. A trans- ducer therefore transforms a weighted symbol sequence into another weighted symbol sequence. The GT shown in Fig. 24 performs a composition between the recognition graph and the grammar transducer. This operation takes every possible sequence corresponding to every possible path in the recognition graph and matches them with the paths in the grammar transducer. The composition produces the interpretation graph, which contains a path for each corresponding output label sequence. This composition operation may seem combinatorially intractable, but it turns out there exists an efficient algorithm for it described in more details in Section VIII.
9m8s | B. Experiments with SDNN
893y | In a series of experiments, LeNet-5 was trained with the goal of being replicated so as to recognize multiple charac- ters without segmentations. The data were generated from
favz | the previously described MNIST set as follows. Training images were composed of a central character, flanked by two side characters picked at random in the training set. The separation between the bounding boxes of the characters were chosen at random between -1 and 4 pixels. In other instances, no central character was present, in which case the desired output of the network was the blank space class. In addition, training images were degraded with 10% salt and pepper noise (random pixel inversions).
7szx | Figs. 25 and 26 show a few examples of successful recognitions of multiple characters by the LeNet-5 SDNN. Standard techniques based on HOS would fail miserably on many of those examples. As can be seen on these examples, the network exhibits striking invariance and noise resistance properties. While some authors have argued that invariance requires more sophisticated models than feedforward NN's [87], LeNet-5 exhibits these properties to a large extent.
hx9e | Similarly, it has been suggested that accurate recognition of multiple overlapping objects require explicit mechanisms that would solve the so-called feature binding problem [87]. As can be seen on Figs. 25 and 26, the network is able to tell the characters apart even when they are closely intertwined, a task that would be impossible to achieve with the more classical HOS technique. The SDNN is also able to correctly group disconnected pieces of ink that form characters. Good examples of that are shown in the upper half of Fig. 26. In the top left example, the 4 and the 0 are more connected to each other than they are connected with themselves, yet the system correctly identifies the 4 and the 0 as separate objects. The top right example is interesting for several reasons. First the system correctly identifies the three individual ones. Second, the left half and right half of disconnected 4 are correctly grouped, even though no geometrical information could decide to associate the left half to the vertical bar on its left or on its right. The right
ywn2 | half of the 4 does cause the appearance of an erroneous one on the SDNN output, but this one is removed by the character model transducer which prevents characters from appearing on contiguous outputs.
a63r | Another important advantage of SDNN is the ease with which they can be implemented on parallel hardware. Specialized analog/digital chips have been designed and used in character recognition, and in image preprocessing applications [88]. However the rapid progress of conven- tional processor technology with reduced-precision vector arithmetic instructions (such as Intel's MMX) make the success of specialized hardware hypothetical at best.3
dqvj | C. Global Training of SDNN
r17u | In the above experiments, the string images were artifi- cially generated from individual character. The advantage is that we know in advance the location and the label of the important character. With real training data, the correct sequence of labels for a string is generally available, but the precise locations of each corresponding character in the input image are unknown.
3c47 | In the experiments described in the previous section, the best interpretation was extracted from the SDNN output using a very simple GT. Global training of an SDNN can be performed by back propagating gradients through such GT's arranged in architectures similar to the ones described in Section VI.
g345 | This is somewhat equivalent to modeling the output of an SDNN with an HMM. Globally trained, variable- size TDNN/HMM hybrids have been used for speech recognition and online handwriting recognition [67], [77], [89], [90]. SDNN's have been used in combination with HMM's or other elastic matching methods for handwritten word recognition [91], [92].
svhz | Fig. 27 shows the GT architecture for training an SDNN/HMM hybrid with the discriminative forward criterion. The top part is comparable to the top part of Fig. 21. On the right side the composition of the recognition graph with the grammar gives the interpretation graph with all the possible legal interpretations. On the left side the composition is performed with a grammar that only contains paths with the desired sequence of labels. This has a somewhat similar function to the path selector used in the previous section. Like in Section VI-D, the loss function is the difference between the forward score obtained from the left half and the forward score obtained from the right half. To back propagate through the composition transformer, we need to keep a record of which arc in the recognition graph originated which arcs in the interpretation graph. The derivative with respect to an arc in the recognition graph is equal to the sum of the derivatives with respect to all the arcs in the interpretation graph that originated from it. Derivative can also be computed for the penalties on the grammar graph, allowing to learn them as well. As in the previous example, a discriminative criterion must
oaen | Fig. 27. A globally trainable SDNN/HMM hybrid system ex- pressed as a GTN.
5u67 | be used, because using a nondiscriminative criterion could result in a collapse effect if the network's output RBF are adaptive. The above training procedure can be equivalently formulated in term of HMM. Early experiments in zip code recognition [91], and more recent experiments in online handwriting recognition [38] have demonstrated the idea of globally trained SDNN/HMM hybrids. SDNN is an extremely promising and attractive technique for OCR, but so far it has not yielded better results than HOS. We hope that these results will improve as more experience is gained with these models.
dvms | D. Object Detection and Spotting with SDNN
qrd3 | An interesting application of SDNN's is object detection and spotting. The invariance properties of convolutional networks, combined with the efficiency with which they can be replicated over large fields, suggests that they can be used for "brute force" object spotting and detection in large images. The main idea is to train a single convolutional network to distinguish images of the object of interest from images present in the background. In utilization mode, the network is replicated so as to cover the entire image to be analyzed, thereby forming a 2-D SDNN. The output of the SDNN is a 2-D plane in which activated units indicate the presence of the object of interest in the corresponding receptive field. Since the sizes of the objects to be detected within the image are unknown, the image can be presented to the network at multiple resolutions, and the results at multiple resolutions combined. The idea has been applied to face location [93], address block location on envelopes [94], and hand tracking in video [95].
rxrg | To illustrate the method, we will consider the case of face detection in images as described in [93]. First,
tf43 | images containing faces at various scales are collected. Those images are filtered through a zero-mean Laplacian filter so as to remove variations in global illumination and low spatial frequency illumination gradients. Then, training samples of faces and nonfaces are manually extracted from those images. The face subimages are then size normalized so that the height of the entire face is approximately 20 pixels while keeping fairly large variations (within a factor of two). The scale of background subimages are picked at random. A single convolutional network is trained on those samples to classify face subimages from nonface subimages.
fcco | When a scene image is to be analyzed, it is first filtered through the Laplacian filter and subsampled at powers-of- two resolutions. The network is replicated over each of multiple resolution images. A simple voting technique is used to combine the results from multiple resolutions.
8uji | A 2-D version of the global training method described in the previous section can be used to alleviate the need to manually locate faces when building the training sample [93]. Each possible location is seen as an alternative inter- pretation, i.e., one of several parallel arcs in a simple graph that only contains a start node and an end node.
df3e | Other authors have used NN's or other classifiers such as SVM's for face detection with great success [96], [97]. Their systems are very similar to the one described above, including the idea of presenting the image to the network at multiple scales. But since those systems do not use convolutional networks, they cannot take advantage of the speedup described here, and they have to rely on other techniques, such as prefiltering and real-time tracking, to keep the computational requirement within reasonable limits. In addition, because those classifiers are much less invariant to scale variations than convolutional networks, it is necessary to multiply the number of scales at which the images are presented to the classifier.
53eu | VIII. GRAPH TRANSFORMER NETWORKS AND TRANSDUCERS
a5u1 | In Section IV, GTN's were introduced as a general- ization of multilayer, multimodule networks where the state information is represented as graphs instead of fixed- size vectors. This section reinterprets the GTN's in the framework of generalized transduction and proposes a powerful graph composition algorithm.
ry7u | A. Previous Work
5mda | Numerous authors in speech recognition have used gradient-based learning methods that integrate graph- based statistical models (notably HMM's) with acoustic recognition modules, mainly Gaussian mixture models, but also NN's [67], [78], [98], [99]. Similar ideas have been applied to handwriting recognition (see [38] for a review). However, there has been no proposal for a systematic approach to multilayer graph-based trainable systems. The idea of transforming graphs into other graphs has received considerable attention in computer science
i4li | through the concept of weighted finite-state transducers [86]. Transducers have been applied to speech recognition [100] and language translation [101], and proposals have been made for handwriting recognition [102]. This line of work has been mainly focused on efficient search algorithms [103] and on the algebraic aspects of combining transducers and graphs (called acceptors in this context), but very little effort has been devoted to building globally trainable systems out of transducers. What is proposed in the following sections is a systematic approach to automatic training in graph-manipulating systems. A different approach to graph-based trainable systems, called input-output HMM, was proposed in [104] and [105].
r8sm | B. Standard Transduction