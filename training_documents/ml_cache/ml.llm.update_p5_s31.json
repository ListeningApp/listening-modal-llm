{
  "id": "chatcmpl-A0ZVKBpxJu9jvSzVIgeB2mKkvDCu6",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "```\nhis3 | different keyword and searching across all databases. Although the use of ML in medical science can be dated back to the nineteen seventies, more rapid growth is evident in the past ten years. Moreover, publications based on 'multi-omics integration' and 'multi-omics and machine learning' have started to emerge in the last five years and have gained popularity in the precision and computational medicine domain. Although deep learning is widely popular in other related domains, the interest has been more limited for multi-omics analysis. This is because multi-omics studies are challenging to deploy as they require specialised high-throughput omic infrastructure. This fact is reinforced by the evidence that most of the current literature employs deep learning on large-scale multi-omics datasets from open sources for cancer prognosis and anti-cancer drug response.\nm50z | Three. Challenges in multi-omics analysis using machine learning\nme84 | The use of ML to analyse high-throughput generated multi-omic data poses key unique challenges. They can be summarised as follows.\no56m | Three point one. Heterogeneity, sparsity and outliers\nslz6 | Multi-omic data from different high-throughput sources are usually\n90k5 | heterogeneous. For example, transcriptomics and proteomics use different normalisation and scaling techniques before omics analysis. This leads to different dynamic ranges and data distribution. Also, some omics are more prone to generating sparse data than others. Therefore, imputation and outlier detection should be considered for each omic separately, before planning their integration.\n9m8s | Three point two. Class imbalance and overfitting\n893y | In disease classification, certain disease classes are rarer than others which can cause a class imbalance in the multi-omics dataset. For example, primary hypertension is the most common form of hypertension with ninety-five percent prevalence while endocrine hypertension occurs in only five percent. The ML model trained using an imbalanced dataset may be overfitted i.e. high accuracy for training data but underperformance for unseen test data. Therefore, to classify these two types of hypertension one of the following approaches can be used: one, collect more data if possible; or two, consider using weighted or normalised metrics to measure the ML performance; or three, consider over or undersampling the under or over-represented class respectively; or four, consider synthetic sample generation for the under-represented class. Similarly, techniques such as regularisation, bagging, hyperparameter tuning and cross-validation can be used to balance bias-variance trade-off. Any of the above approaches can be used, depending on data and problem, to overcome the class imbalance and overfitting problems.\nfavz | Three point three. More features than data.\n7szx | Most multi-omics datasets suffer from the classical 'curse of dimensionality' problem, i.e. having much fewer observation samples than\nhx9e | multi-omics features. The resulting high-dimensional space often contains correlated features which are redundant and can mislead the algorithm training. The dimensional space of the data can be reduced by employing dimensionality reduction techniques such as feature extraction and feature selection. Feature extraction refers here to techniques computing a subset of representative features which summarise the original dataset and its dimensions. These features are functions of the original ones, for instance, principal component analysis, linear discriminant analysis and multidimensional scaling. On the other hand, feature selection finds a subset of the original features that maximise the accuracy of a predictive model. It can be based on prior knowledge or based on a database such as a Biofilter. Formally, feature selection methods can be classed as filter, wrapper and embedded techniques. Xu and Sta≈Ñczyk provide an excellent resource for understanding and exploring the use of different dimensionality reduction techniques in the generic ML domain. Meng offers a review of these methods from the perspective of multi-omics data analysis.\nywn2 | Three point four. Computation and storage cost\na63r | The use of ML for multi-omics analysis comes with computational and data storage cost. Most ML algorithms require high computation power and large volumes of storage capacity to save the logs, results and analysis. In recent years, ML models can be deployed on dedicated graphics processing units and cloud computing platforms such as Amazon EC2, Microsoft Azure and Google Cloud Platform. The related costs should be considered well in advance before planning an ML-based multi-omics workflow.\ndqvj | Three point five. What algorithm works best for what conditions?\n```",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1724699842,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_df84d6bd70",
  "usage": {
    "completion_tokens": 915,
    "prompt_tokens": 3207,
    "total_tokens": 4122
  }
}