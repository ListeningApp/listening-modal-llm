{
  "id": "chatcmpl-A0YxUut2mvy4jZ24ftx9lxjCV2veH",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "```\nti7f | represented in a system and this is a controversial question. An analogy might be helpful here: say I set up a system to identify and track mutations in the melanocortin one receptor, a gene located on chromosome sixteen. Let's suppose that these mutations are entirely (rather than merely largely) responsible for the phenotypic trait of red hair. So a system which tracks these genetic mutations will, in effect, track people with red hair. It might be argued that such a system does not actually represent red-headedness or carry information about red-heads, since it simply tracks a property that correlates with or causes this observed trait, without recruiting the higher-level property in any of its internal transformations. On the other hand, since having red hair is (in the current thought experiment) nothing over and above having these genetic mutations, an alternative stance would be that by tracking the mutations the system de facto ends up representing information about red-headedness. Analogously, a Believer will want to claim that, from an internalist point of view, tracking statistical distributions turns out not merely to track a proxy for semantic properties but in fact succeeds in representing those properties as such, since distributional properties tacitly contain information about inferential and conceptual roles.\noksu | For philosophers, this kind of debate will call to mind protracted discussions about the possibility of a naturalised account of content. Contributors to this debate tend not to adopt an internalist approach to content, instead grounding meaning in the relationship between a sign and some worldly state of affairs, but still the question of how we settle exactly what distal property an internal state represents remains the same. Thus we might think that the same tools used in naturalised externalist frameworks will be available to the Believer here; for instance, spelling out representation in terms of asymmetric causal dependence (so that an internal state of an LLM could be held to represent inferential/conceptual relations not merely distributive properties since the distributional properties are caused by the inferential properties of a sign but not vice versa) or its proper function within a system. Of course, these questions remain vexed and I can't hope to settle them here. Yet I think it suffices for present purposes to note that if the demand for an externalist semantics is rejected, LLMs will at least be in the running as systems which directly target and represent semantic properties through targeting and representing distributional properties.\nwtow | Two point two. LLMs and Robots\no22k | An alternative response to the Sceptic's demand for better integration with the non-textual environment would be to accept that LLMs fail on external aspects at the moment, but hold that this is a contingent gap which will be filled by future iterations of artificial systems. This kind of move is of course familiar from the 'Robot Reply' Searle considers to his Chinese Room argument: according to this response, what is needed to get meaning into a Chinese Room is the addition of supplementary systems that integrate the Room into its non-linguistic environment. For instance, a perceptual system could be added, allowing the person in the room to connect incoming symbols with external objects. Artificial limbs or prostheses could be added, so that the person in the room could manipulate their environment as part of their response to incoming linguistic prompts, perhaps together with some form of locomotion, so that the system as a whole could explore its environment. In short, then, the Chinese Room could be embedded within a robot.\nnwfz | This philosophical call for embedding a linguistic system in a multimodal structure has been answered by some engineers, as Lake and Murphy note:\nnvfy | AI researchers are certainly working on various forms of multimodal learning. A recent flurry of work has focused on integrating vision and language, leading to creative combinations of computer vision and NLP models.\nmror | A recent multi-author paper pursues this idea, looking in detail at three such wider systems: PaLM-E, described as an \"embodied multimodal language model\"; a \"virtual rodent\" trained by reinforcement learning; and AdA, a large Transformer-based, RL-trained \"adaptive agent\". While it is early days for this research, some of the results have been impressive, with systems able to recognise and label complex situations that go beyond the specific examples contained in the system's training data. Furthermore, some of these models show \"emergent visual-language alignment\", where the decoder attends to the relevant part of an image when producing a word (e.g. analysing the umbrella part of an image when producing the word \"umbrella\" in a caption).\nzlxc | Although this is an extremely fast-moving area and the above projects are exciting, it is clear that the Robot Response cedes the current ground to the Sceptic: if we opt for an externalist view of semantic content and pair this with a requirement that an individual language\nk0bw | user must themselves realise the required word-world relations, then LLMs currently fall short. A different move, however, would be to argue that there is no need to embed an LLM within an artificial multi-modal system, for they already have access to a proxy which allows them to forge the necessary connections with the world: although an LLM lacks a direct ability to interact with the non-linguistic world, it does connect via humans.\naq5a | Language is a powerful interface, allowing GPT-four to perform tasks that require understanding the environment, the task, the actions, and the feedback, and adapting accordingly. While it cannot actually see or perform actions, it can do so via a surrogate (e.g., a human).\nsc5y | This brings us to the third response that Believers might make to the Sceptic's demand for appropriate word-world relations, which appeals to the role that humans play in the lifespan of LLMs.\n0yab | Two point three. Derived Intentionality\nw95z | Computers are built and used by people, thus a common response to Searle's challenge has been to appeal to the meaning that programmers or users assign to the symbols manipulated by artificial systems: when a calculator outputs the symbol \"four\" in response to the input \"two plus two\", this output means four because of the intentions of the person who designed or built the calculator and/or because of what the users of the calculator take the sign to mean. This is to appeal to what Searle termed 'derived intentionality': the symbols of an artificial system inherit meaning from their connection to human thinkers and their practices.\n0i1k | The appeal to derived intentionality takes on a special force, however, with respect to LLMs, for the signs manipulated by these systems just are the signs of ordinary natural languages that we, human speakers, manipulate in order to convey information to one another. These symbols are connected with human communicative systems both through the database of human-generated text that the system is exposed to during pre-training and through the interaction with speakers once the system is in use. Furthermore, these natural language signs are manipulated by LLMs in ways that look promising from the point of view of meaning. If we were faced with an artificial system which took English words as input but produced as output some kind of word salad - a rag-bag collection of English terms spewed out by a purely random mechanism, say - the idea that the signs produced in the output retained the meaning they would\n```",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1724697744,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_df84d6bd70",
  "usage": {
    "completion_tokens": 1513,
    "prompt_tokens": 3351,
    "total_tokens": 4864
  }
}