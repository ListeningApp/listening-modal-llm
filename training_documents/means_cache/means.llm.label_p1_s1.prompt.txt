You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document.

Your task is to label each textbox with exactly one of the following labels:
  title: the primary document title, no more than one per document
  heading: the name of the following chapter or section (should never start in the middle of the previous paragraph)
  subheading: a secondary heading, often following another heading (should never start in the middle of the previous paragraph)
  body: main paragraph content: may start or end in the middle of a word, use context to follow paragraphs that are split across textboxes (if a textbox contains both heading and body text, label it "body")
  math: textbox primarily containing math
  imageDescription: standalone callout that only describes an image, chart, table, or similar (typically begins with "Table...", "Figure...", "Fig. ...", "Above...", "Left...", etc.)
  authors: names of contributors to this document
  institutions: list of universities, business, and other institutions affiliated with this document
  publisher: info about the publisher, or provided by the publisher, including copyright info
  pagenum: the page number
  headerOrFooter: boilerplate text page number, or redundant headings at the top/bottom of the page
  toc: the table of contents
  references: bibliographic references and resources
  acknowledgements: thanks and credits to contributors
  appendix: index, appendix, or any other end matter not part of the main thread (including related headings)
  table: tabular data, label, title, or subheading for a grid or list of data
  datum: numeric data or data label from a chart or list
  advertisement: promotional ads and marketing
  layout: non-content related to the layout of the page, e.g. sidebar navigation
  callout: pull quote or long block text that stands apart from the main text
  footnote: footnotes and endnotes near the bottom of the page
  keywords: list of keywords or tags
  url: web address or email
  other: any other text that does not belong to the main thread

Each line of input is prefixed with a textbox ID in the format `id | Text content`. The output must be in the format `id | label`.

Note that body text may be split across multiple textboxes, and textboxes may start or end in the middle of a sentence or word. Because the text was extracted from a web page or document, paragraphs of body text may be interrupted by multiple textboxes of redundant headers, footnotes, page numbers, tables, images, etc. For example, a real heading will never interrupt the middle of a sentence. Use context clues like this to carefully label each textbox.

EXAMPLE INPUT:
1pjs | Neuroscience Applied 1 (2022) 101012
o2kr | Contents lists available at ScienceDirect
v6sk | Neuroscience Applied
1wj6 | journal homepage: www.journals.elsevier.com/neuroscience-applied
936l | Research Articles
06yq | Microdosing with psychedelics to self-medicate for ADHD symptoms in adults: A naturalistic study
dpv6 | ARTICLE INFO
8r5j | ABSTRACT
2taz | Keywords: ADHD Microdosing Psychedelics Self-medication Well-being Time perception
o3ya | ADHD in adulthood is often overlooked, which negatively affects the individual's well-being. First-line phar- macological interventions are effective in many ADHD patients, relieving symptoms rapidly. However, there seems to be a proportion of individuals who discontinue, or fail to respond to these treatments. For these in- dividuals, alternative treatment options should be explored.
r5il | 1. Introduction
5gui | Attention deficit hyperactivity disorder (ADHD) is one of the most common developmental disorders worldwide. Prevalence research indicates that 2.6% of the adult population has persistent ADHD. ADHD in adults is often overlooked because of the high comorbidity rate and lack of knowledge about how ADHD is expressed in adulthood (Kooij et al.,
9d4o | Fig. 1. Flowchart of included participants for each time point.
82qc | 2019). In addition, ADHD is associated with deficits in various domains of cogni- tive functioning. Twenty-five percent of ADHD cases suffered from ADHD symptoms purely because of de- ficiencies in temporal processing (Sonuga-Barke et al., 2010).
ls7d | First-line ADHD treatments in adults mainly include pharmacological interventions to enhance dopaminergic and noradrenergic neurotrans- mission with stimulants. Overall, they have been proven to work effectively in adults with ADHD, inducing fast symptom relief and thereby enhancing the person's quality of life. In the
5esx | Table 1 Demographic information from respondents at baseline and the two and four- week time points.
t8vv | longer term, approximately twenty percent of ADHD patients discontinue their prescribed medication after six to nine months, thirty percent after one year, and half of them after two years.
xrd1 | 2. Material and methods
5746 | 2.1. Study design and participants
7toz | The study employed a naturalistic design, assessing the experiences of participants at baseline,
j346 | Neuroscience Applied 1 (2022)
m5ka | E.C.H.M. Haijen et al.
kx2c | REVIEW
v8uq | before they start MD on their own initiative, and at two and four weeks after MD initiation. The target population included adults diagnosed with ADHD and individuals who experienced ADHD symptoms to the extent that these interfered with their daily lives and who had not been diag- nosed with ADHD before. To be included in the analyses, participants needed to score above a cut-off point on at least one of the subscales of the Conner's Adult ADHD Rating Scale (CAARS-S:SV).
2zmw | Fig. 2. Mean scores of the CAARS-S:SV DSM-IV total symptoms T-scores at baseline (0W) and two (2W) and four weeks (4W) after MD (A) of the whole sample, and (B) per conventional ADHD medication use. Error bars represent mean error.
sdk3 | <LATEX>\lim _ { x ightarrow \infty } rac { 6 x ^ { 2 } + 1 0 0 } { 7 x ^ { 2 } - 1 0 } =</LATEX>
x972 | 2.2. Study procedure
k221 | Mean performance measures of the CAARS-

EXAMPLE OUTPUT:
1pjs | headerOrFooter
o2kr | publisher
v6sk | publisher
1wj6 | publisher
936l | headerOrFooter
06yq | title
dpv6 | other
8r5j | heading
2taz | keywords
o3ya | body
r5il | heading
5gui | body
9d4o | imageDescription
82qc | body
ls7d | body
5esx | imageDescription
t8vv | body
xrd1 | heading
5746 | subheading
7toz | body
j346 | headerOrFooter
m5ka | authors
kx2c | headerOrFooter
v8uq | body
2zmw | imageDescription
sdk3 | math
x972 | heading
k221 | body




1pjs | 13 GLM 2: Comparing means adjusted for other predictors (analysis of covariance)
o2kr | 13.1 What will this chapter tell me?
v6sk | My road to rock stardom had taken a bit of a knock with my unexpected entry to an all-boys' grammar school (rock bands and grammar schools really didn't go together). I needed to be inspired and I turned to the masters: Iron Maiden. I first heard Iron Maiden at the age of 11 when a friend lent me Piece of Mind on a cassette and told me to listen to 'The Trooper'. It was, to put it mildly, an epiphany. I became their smallest (I was 11) biggest fan and obsessed about them in the unhealthiest of ways. I bombarded the man who ran their fan club (a guy called Keith) with letters, and, bless him, he replied to them all. Eventually my stalking paid off and Keith arranged for me to go backstage when they played what was then (and to me always will be) the Hammersmith Odeon in London on 5 November 1986 (Somewhere on Tour, in case you're interested). Not only was it the first time I had seen them live, but I got to meet them too. It is difficult to convey how exciting and anxiety-provoking that night was. It was all quite overwhelming. I was so utterly awe-struck that I managed to say precisely nothing to any of the band (but I do have some good photos where my speechlessness is tangible; see Figure 13.1). Soon to become a theme in my life, a social situation had provoked me to make an utter fool of myself.1 When it was over I was in no doubt that this was the best day of my life. In fact, I thought, I should just kill myself there and then because nothing would ever be as good.2 This may be true, but I have subsequently had other very nice experiences, so who is to say that they were not better? I could compare experiences to see which one is the best, but there is an important confound: my age. At the age of 13, meeting Iron Maiden was bowel-weakeningly exciting, but adulthood (sadly) dulls your capacity for this kind of unqualified excitement. To really see which experience was best, I would have to take account of the variance in enjoyment that is attributable to my age at the time. Doing so will give me a purer measure of how much variance in my enjoyment is attributable to the event itself.
1wj6 | 1 In my teens I met many bands I liked, and Iron Maiden were by far the nicest. 2 Apart from my wedding day, as it turned out.
936l | This chapter extends the previous one to look at situations in which you want to compare groups means, but also adjust those means for another variable (or variables) that you expect to affect the outcome. This involves a linear model in which an outcome is predicted from dummy variables representing group membership but one or more other predictors (usually continuous variables) are included. These additional predictors are sometimes labelled covariates, and this configuration of the linear model is sometimes known as analysis of covariance. Figure 13.1 Dave Murray (guitarist from Iron Maiden) and me backstage in
06yq | London in 1986 (my grimace reflects the utter terror I was feeling at meeting my hero)
dpv6 | IIII
8r5j | 13.2 What is ANCOVA?
2taz | In the previous chapter we saw how we can compare multiple group means with the linear model by using dummy variables to code group membership. In addition, in Chapter 9 we saw how the linear model can incorporate several continuous predictor variables. It should, therefore, be no surprise that the linear model to compare means can be extended to include one or more continuous variables that predict the outcome (or dependent variable). When the main focus of the model is to compare means (perhaps from different experimental groups) then these additional predictors in the model are sometimes referred to as covariates. Also, this form of the linear model is sometimes referred to as analysis of covariance (or ANCOVA for short).3
o3ya | 3 As we've discussed before, these labels for special cases of the linear model (such as one-way independent ANOVA in the previous chapter, and ANCOVA here) reflect historical divisions in methods (see Misconception Mutt 12.1). They are unhelpful because they create the impression that we're using distinct statistical models when we're not. I want you to focus on the general linear model that underpins these special cases, but I can't really avoid using the ANOVA/ANCOVA labels now and again so that when your supervisor tells you to do ANOVA/ANCOVA you can find the relevant part of the book!
r5il | In the previous chapter, we used an example about the effects of puppy therapy
5gui | on happiness. Let's think about things other than puppy therapy that might influence happiness. Well, the obvious one is how much you like dogs (a dog phobic is going to be about as happy after puppy therapy as I would be after tarantula therapy), but there are other things too such as individual differences in temperament. If these variables (the covariates) are measured, then it is possible to adjust for the influence they have on the outcome variable by including them in the linear model. From what we know of hierarchical regression (see Chapter 9) it should be clear that if we enter the covariate into the model first, and then enter the dummy variables representing the group means (e.g., the experimental manipulation), we can see what effect a predictor variable has, adjusting for the effect of the covariate. In essence, rather than predicting the outcome from group means, we predict it from group means that have been adjusted for the effect of covariate(s). There are two main reasons to include covariates in ANOVA:
82qc | . To reduce within-group error variance: When we predict an outcome from group means (e.g., when these represent the effect of an experiment), we compute an F-statistic by comparing the amount of variability in the outcome that the experiment can explain against the variability that it cannot explain. If we can attribute some of this 'unexplained' variance (SSR) to other measured variables (covariates), then we reduce the error variance, allowing us to assess more sensitively the difference between group means (SSM).
ls7d | . Elimination of confounds: In any experiment, there may be unmeasured variables that confound the results (i.e., variables other than the experimental manipulation that affect the outcome variable). If any variables are known to influence the outcome variable being measured, then including them as covariates can remove these variables as potential explanations for the effect of interest.
tzt3 | 13.3 ANCOVA and the general linear model
t8vv | The researchers who conducted the puppy therapy study in the previous chapter suddenly realized that a participant's love of dogs would affect whether puppy therapy would affect happiness. Therefore, they repeated the study on different participants, but included a self-report measure of love of puppies from 0 (I am a weird person who hates puppies, please be deeply suspicious of me) to 7 (puppies are the best thing ever, one day I might marry one). The data are in Table 13.1 and in the file Puppy Love.sav, which contains the variables Dose (1 = control, 2 = 15 minutes, 3 = 30 minutes), Happiness (the person's happiness
qvnu | The summary of the model resulting from the self-test (Output 13.1) shows us the goodness of fit of the model first when only the covariate is used in the model, and second when both the covariate and the dummy variables are used. The difference between the values of <LATEX>R ^ { 2 } \left( 0 . 2 8 8 - 0 . 0 6 1 = 0 . 2 2 7 \right)</LATEX> represents the individual contribution of puppy therapy to predicting happiness. Puppy therapy accounted for 22.7% of the variation in happiness, whereas love of puppies
kggw | accounted for only 6.1%. This additional information provides some insight into the substantive importance of puppy therapy. The next table is the ANOVA table, which is also divided into two sections. The top half represents the effect of the covariate alone, whereas the bottom half represents the whole model (i.e., covariate and puppy therapy included). Notice at the bottom of the ANOVA table (the bit for model 2) that the entire model (love of puppies and the dummy variables) accounts for 31.92 units of variance <LATEX>\left( \mathrm { S S } _ { \mathrm { M } } \right) ,</LATEX> there are 110.97 units in total <LATEX>\left( \mathrm { S S } _ { \mathrm { T } } \right)</LATEX> and the unexplained variance <LATEX>\left( \mathrm { S S } _ { \mathrm { R } } \right)</LATEX> is 79.05.
xrd1 | The interesting bit is the table of model coefficients (Output 13.2). The top half shows the effect when only the covariate is in the model, and the bottom half contains the whole model. The b-values for the dummy variables represent the difference between the means of the 15-minute group and the control group (Dummy 1) and the 30-minute group and the control group (Dummy <LATEX>\left. 2 \right) - \sec</LATEX> Section 12.2 for an explanation of why. The means of the 15-and 30-minute groups were 4.88 and 4.85 respectively, and the mean of the control group was 3.22. Therefore, the b-values for the two dummy variables should be roughly the same <LATEX>\left( 4 . 8 8 \quad - \quad 3 . 2 2 = 1 . 6 6 \right.</LATEX> for Dummy 1 and <LATEX>4 . 8 5 \quad - \quad 3 . 2 2 = 1 . 6 3</LATEX> for Dummy 2). The astute among you might notice that the <LATEX>b</LATEX> b-values in Output 13.2 are not only very different from each other (which shouldn't be the case because the 15-and 30-minute groups means are virtually the same), but also different from the values I've just calculated. Does this mean I've been lying to you for the past 50 pages about what the beta values represent? I'm evil, but I'm not that evil. The reason for this apparent anomaly is that with a covariate present, the b-values represent the differences between the means of each group and the control adjusted for the covariate(s). In this case, they represent the difference in the means of the puppy therapy groups adjusted for the love of puppies. Output 13.1
5746 | These adjusted means come directly from the model. If we replace the b-values in equation (13.1) with the values in Output 13.2, our model becomes: Happiness; = 1.789+ 2.225Long; + 1.786Short; + 0.416Puppy_love; (13.2) Remember that Long and Short are dummy variables such that Long takes the value of 1 only for the 30-minute group, and Short takes a value of 1 only for the 15-minute group; in all other situations they have a value of 0. To get the adjusted means, we use this equation, but rather than replacing the covariate with an individual's score, we replace it with the mean value of the covariate from Table 13.2 (2.73) because we're interested in the predicted value for each group at the mean level of the covariate. For the control group, the dummy variables are both coded as 0, so we replace Long and Short in the model with 0. The adjusted mean will, therefore, be 2.925: Happiness Control =1.789+(2.225×0)+(1.786×0)+(0.416×XPuppy_love) =1.789+(0.416×2.73) (13.3) =2.925
7toz | For the 15-minute group, the dummy variable Short is 1 and Long is 0, so the adjusted mean is 4.71:
j346 | <LATEX>\bar { \text { Happiness } } _ { 1 5 \text { mins } } = 1 . 7 8 9 + \left( 2 . 2 2 5 \times 0 \right) + \left( 1 . 7 8 6 \times 1 \right) + \left( 0 . 4 1 6 \times \bar { X } _ { \text { Puppy love } } \right)</LATEX> <LATEX>= 1 . 7 8 9 + 1 . 7 8 6 + \left( 0 . 4 1 6 \times 2 . 7 3 \right)</LATEX> (13.4)
v8uq | <LATEX>= 4 . 7 1</LATEX> For the 30-minute group, the dummy variable <LATEX>S h o r t \quad i s \quad 0</LATEX> and Long is 1, so the adjusted mean is 5.15:
x972 | <LATEX>\widetilde { \mathrm { H a p p i n e s } } _ { 3 0 \mathrm { m i n s } } = 1 . 7 8 9 + \left( 2 . 2 2 5 \times 1 \right) + \left( 1 . 7 8 6 \times 0 \right) + \left( 0 . 4 1 6 \times \bar { X } _ { \text { Puppy love } } \right)</LATEX> <LATEX>= 1 . 7 8 9 + 2 . 2 2 5 + \left( 0 . 4 1 6 \times 2 . 7 3 \right)</LATEX> <LATEX>= 5 . 1 5</LATEX> (13.5)
cwrw | We can now see that the <LATEX>b</LATEX> b-values for the two dummy variables represent the differences between these adjusted means <LATEX>\left( 4 . 7 1 \quad - \quad 2 . 9 3 = 1 . 7 8 \right.</LATEX> for Dummy 1 and <LATEX>5 . 1 5 \quad - \quad 2 . 9 3 = 2 . 2 2</LATEX> for Dummy 2). These adjusted means are the average amount of happiness for each group at the mean level of love of puppies. Some people think of this kind of model (i.e., ANCOVA) as 'controlling' for the covariate, because it compares the predicted group means at the average value of the covariate, so the groups are being compared at a level of the covariate that is the same for each group. However, as we shall see, the 'controlling for the covariate' analogy is not a good one.
4i0e | Output 13.2
h2l3 | 13.4 Assumptions and issues in ANCOVA