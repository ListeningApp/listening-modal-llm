{
  "id": "chatcmpl-A3U9mPNWGDGELApklOsdFRKcC18fo",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "dqlg | Two point three. Derived Intentionality\np6pq | Computers are built and used by people, thus a common response to Searle's challenge has been to appeal to the meaning that programmers or users assign to the symbols manipulated by artificial systems: when a calculator outputs the symbol \"four\" in response to the input \"two plus two\", this output means four because of the intentions of the person who designed or built the calculator and or because of what the users of the calculator take the sign to mean. This is to appeal to what Searle termed 'derived intentionality': the symbols of an artificial system inherit meaning from their connection to human thinkers and their practices.\nzse6 | The appeal to derived intentionality takes on a special force, however, with respect to LLMs, for the signs manipulated by these systems just are the signs of ordinary natural languages that we, human speakers, manipulate in order to convey information to one another. These symbols are connected with human communicative systems both through the database of human-generated text that the system is exposed to during pre-training and through the interaction with speakers once the system is in use. Furthermore, these natural language signs are manipulated by LLMs in ways that look promising from the point of view of meaning. If we were faced with an artificial system which took English words as input but produced as output some kind of word salad - a rag-bag collection of English terms spewed out by a purely random mechanism, say - the idea that the signs produced in the output retained the meaning they would\np2n3 | have in the mouths of ordinary English speakers would be on much shakier ground. Yet the outputs of LLMs respect syntactic rules (even though at no point is the system given any explicit syntactic training or instruction) and they make contextual sense. So, if we think the sentence \"Dogs bark\" means what it does when uttered by an English speaker because it combines words with a particular meaning in a particular well-formed syntactic structure, it seems a Believer might similarly hold that the sentence \"Dogs bark\" when produced by an LLM means what it does because it is the result of combining meaningful words in a particular well-formed syntactic string. LLM outputs are meaningful, according to this line of thought, because they stand on the shoulders of ordinary language users, re-using words and structures that have been antecedently made meaningful by us.\nohh7 | Searle himself, of course, thought that what mattered for understanding was, fundamentally, original intentionality and a Sceptic might object that the kind of derived aboutness discussed above is not really sufficient for meaning. Rather what is needed is the ability to invest signs with meaning de novo, an ability which Searle holds arises in biological brains and things which have the same causal powers as human brains. I'll return to the demand for original intentionality in section four, but in the next section I want to explore further the idea that derived intentionality might be sufficient to support genuine semantic attributions to LLMs (not least because the position of LLMs with regard to word-world connections may in fact mirror the position human interlocutors are often in).\nvbni | Three. Derived intentionality as sufficient for meaning?\ndgcw | Intention-based semantic theories hold that meaning is grounded in the intentional practices of agents, so that, for example, \"dog\" means what it does because English speakers intend \"dog\" to refer to dogs and an intentional practice has grown up of using this term in this way. There are, however, different ways to conceive of the relationship between meaning and intentions. Borg introduces a distinction that might be helpful here, between what she terms 'A-style' and 'B-style' versions of intention-based semantics. According to 'A-style' intention-based theories, speaker intentions play a preconditional role: in order for a sign to mean something there has to be a practice of using that sign with that meaning amongst intentional agents. A-style theories are thus likely to appeal to generalised, conventional intentions. On this kind of A-style account what matters for an expression coming to have a given meaning in a given community is that the expression be used by one speaker with the intention of conveying a certain meaning and that this use be picked up by the community, so that it becomes conventional to intend to convey that meaning by using that word. A-style approaches provide an answer to a constitutive question concerning the kind of thing linguistic meaning is, grounding it in the intentional practices of language users, but they need not demand that producers of token expressions have particular intentions in order for signs to be meaningful. According to A-style accounts, although intentional agents (with a practice of using certain signs to represent things) are needed to get a meaningful system off the ground in the first place, once the system is up and running, token signs from the system can be meaningful without any input from the intentions of the current speaker (under an A-style intention-based account, a speaker who says \"dog\" but intends to mean cat will fail, at least literally, to mean cat since the meaning of this sign is fixed by the conventional fact that speakers generally intend to convey the meaning dog by saying \"dog\").\ngvwz | B-style accounts, on the other hand, hold that a linguistic utterance is simply a good piece of evidence for determining the intentions of a speaker and that it is only once someone has grasped these speaker intentions that they can be credited with a grasp of semantic content. So, to discover the meaning of some sentence \"s\" as produced by U we need to look to what U\nsk5m | Thirteen\nqws8 | intends to convey, what thought she is trying to get across by uttering what she does. B-style accounts take the locus of linguistic meaning to be utterances; while A-style accounts focus on the type-level, taking semantic content to attach to sentence types. Prima facie, if semantic content is, first and foremost, a property of linguistic types then it seems that the door is open to token LLM outputs sharing in semantic properties in just the way that token human utterances do.\n877u | A-style accounts rely on a notion of semantic deference, according to which a speaker can produce a given linguistic token with a specific meaning not because she cognises that meaning herself (though she may do) but because her use is part of an established practice and she defers to that practice. Semantic deference is most often discussed as part of the kind of 'social externalism' defended by Burge, where a speaker defers to experts in her community for the meaning of technical terms. In Putnam's famous example (Meaning of Meaning), a speaker may be unable to distinguish elm trees from beech trees, and yet her utterance of the term \"elm\" still refers to elms (and not to beeches) because she defers to experts in the community who can tell these two kinds of tree apart. Social externalism allows a speaker to express a concept (and perhaps even be credited as possessing that concept) even if she has only a very partial grasp of what the concept involves. Hunter frames this idea as follows:\nrzhj | If the experts in S's community use a word, W, to express concept C, and S is minimally competent with W and defers to the experts in its use, then S has C too.\nbfax | The kind of deference envisaged here need not, it seems, be limited to technical terms and experts in particular fields. Instead, A-style accounts hold that it captures a much more general feature of linguistic meaning: words in general mean what they do because intentional agents kick-start a social activity, so that a token expression produced by a speaker now means what it does because there is a community practice of using that term with a certain meaning and the current speaker defers to this practice.\nf2y8 | This kind of A-style, deference model is embedded in many approaches to semantic theorising which fall under the broad heading of 'formal semantics'. So, for instance, take",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394270,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1657,
    "prompt_tokens": 3379,
    "total_tokens": 5036
  }
}