{
  "id": "chatcmpl-A3U7QXoDyv6MKzFeuAEM0TyLYDKcw",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "````\n5iea | One of the best networks we found for both online and offline character recognition is a five-layer convolutional network somewhat similar to LeNet-five, but with multiple input planes and different numbers of units on the last two layers-layer one: convolution with eight kernels of size three by three; layer two: two by two subsampling; layer three: convolution with twenty-five kernels of size five by five; layer four: convolution with eighty-four kernels of size four by four; layer five: two by one subsampling; classification layer: ninety-five RBF units (one per class in the full printable ASCII set). The distributed codes on the output are the same as for LeNet-five, except they are adaptive unlike with LeNet-five. When used in the HOS system, the input to above network consisted of an AMAP with five planes, twenty rows, and eighteen columns. It was determined that this resolution was sufficient for representing handwritten characters. In the SDNN version, the number of columns was varied according to the width\n62l5 | of the input word. Once the number of subsampling layers and the sizes of the kernels are chosen, the sizes of all the layers, including the input, are determined unambiguously. The only architectural parameters that remain to be selected are the number of feature maps in each layer and the information as to what feature map is connected to what other feature map. In our case, the subsampling rates were chosen as small as possible (two by two) and the kernels as small as possible in the first layer (three by three) to limit the total number of connections. Kernel sizes in the upper layers are chosen to be as small as possible while satisfying the size constraints mentioned above. Larger architectures did not necessarily perform better and required considerably more time to be trained. A very small architecture with half the input field also performed worse because of insufficient input resolution. Note that the input resolution is nonetheless much less than for OCR because the angle and curvature provide more information than would a single grey level at each pixel.\nshub | C. Network Training\nzjn5 | Training proceeded in two phases. First, we kept the centers of the RBF's fixed and trained the network weights so as to minimize the output distance of the RBF unit corresponding to the correct class. This is equivalent to minimizing the MSE between the previous layer and the center of the correct-class RBF. This bootstrap phase was performed on isolated characters. In the second phase, all the parameters, network weights, and RBF centers were trained globally to minimize a discriminative criterion at the word level.\nw8ia | With the HOS approach, the GTN was composed of four main GT's.\n4vej | One. The segmentation transformer performs the HOS and outputs the segmentation graph. An AMAP is then computed for each image attached to the arcs of this graph.\n8ut1 | Two. The character recognition transformer applies the convolutional network character recognizer to each candidate segment and outputs the recognition graph with penalties and classes on each arc.\n6o35 | Three. The composition transformer composes the recognition graph with a grammar graph representing a language model incorporating lexical constraints.\n8r63 | Four. The beam search transformer extracts a good interpretation from the interpretation graph. This task could have been achieved with the usual Viterbi Transformer. The beam search algorithm, however, implements pruning strategies which are appropriate for large interpretation graphs.\nqze0 | With the SDNN approach, the main GT's are the following.\no3m2 | One. The SDNN transformer replicates the convolutional network over a whole word image and outputs a recognition graph that is a linear graph with class\nkro9 | penalties for every window centered at regular intervals on the input image.\ni438 | Two. The character-level composition transformer composes the recognition graph with a left-to-right HMM for each character class.\nyr7b | Three. The word-level composition transformer composes the output of the previous transformer with a language model incorporating lexical constraints and outputs the interpretation graph.\n60hk | Four. The beam search transformer extracts a good interpretation from the interpretation graph.\n5djf | In this application, the language model simply constrains the final output graph to represent sequences of character labels from a given dictionary. Furthermore, the interpretation graph is not actually completely instantiated: the only nodes created are those that are needed by the beam search module. The interpretation graph is therefore represented procedurally rather than explicitly.\nhem5 | A crucial contribution of this research was the joint training of all GT modules within the network with respect to a single criterion, as explained in Sections Six and Seven. We used the discriminative forward loss function on the final output graph: minimize the forward penalty of the constrained interpretation (that is, along all the \"correct\" paths) while maximizing the forward penalty of the whole interpretation graph (that is, along all the paths).\nvfd9 | During global training, the loss function was optimized with the stochastic diagonal Levenberg-Marquardt procedure described in Appendix C, which uses second derivatives to compute optimal learning rates. This optimization operates on all the parameters in the system, most notably the network weights and the RBF centers.\njkgk | D. Experimental Results\n8nom | In the first set of experiments, we evaluated the generalization ability of the NN classifier coupled with the word normalization preprocessing and AMAP input representation. All results are in writer independent mode (different writers in training and testing). Initial training on isolated characters was performed on a database of\nvsjd | approximately one hundred thousand hand printed characters (ninety-five classes of upper case, lower case, digits, and punctuation). Tests on a database of isolated characters were performed separately on the four types of characters: upper case (two point nine nine percent error on nine thousand one hundred twenty-two patterns), lower case (four point one five percent error on eight thousand two hundred one patterns), digits (one point four percent error on two thousand nine hundred thirty-eight patterns), and punctuation (four point three percent error on eight hundred eighty-one patterns). Experiments were performed with the network architecture described above. To enhance the robustness of the recognizer to variations in position, size, orientation, and other distortions, additional training data was generated by applying local affine transformations to the original characters.\ntucm | The second and third set of experiments concerned the recognition of lower case words (writer independent). The tests were performed on a database of eight hundred eighty-one words. First we evaluated the improvements brought by the word normalization to the system. For the SDNN/HMM system we have to use word-level normalization since the network sees one whole word at a time. With the HOS system, and before doing any word-level training, we obtained with character-level normalization seven point three percent and three point five percent word and character errors (adding insertions, deletions and substitutions) when the search was constrained within a twenty-five thousand four hundred sixty-one-word dictionary. When using the word normalization preprocessing instead of a character level normalization, error rates dropped to four point six percent and two point zero percent for word and character errors respectively, that is, a relative drop of thirty-seven percent and forty-three percent in word and character error respectively. This suggests that normalizing the word in its entirety is better than first segmenting it and then normalizing and processing each of the segments.\nprly | In the third set of experiments, we measured the improvements obtained with the joint training of the NN and the postprocessor with the word-level criterion, in comparison to training based only on the errors performed at the character level. After initial training on individual characters as above, global word-level discriminative training was performed with a database of three thousand five hundred lower case words. For the SDNN/HMM system, without any dictionary constraints, the error rates dropped from thirty-eight percent and twelve point four percent word and character error to twenty-six percent and eight point two percent respectively after word-level training, that is, a relative drop of thirty-two percent and thirty-four percent.\n```",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394124,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1642,
    "prompt_tokens": 3378,
    "total_tokens": 5020
  }
}