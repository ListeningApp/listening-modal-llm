{
  "id": "chatcmpl-A3UFgLXZzITwPkzSUFCNVaTA9UbRL",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "jie2 | Duration and Prosody Predictors (Table eleven). The duration predictor and prosody predictors are trained together in the second stage of training. There is a shared three-layer bidirectional long short-term memory network between the duration predictor and prosody predictor named text feature encoder, each followed by an adaptive layer normalization. Adaptive layer normalization is similar to adaptive instance normalization where the gain and bias are predicted from the style vector S. However, unlike adaptive instance normalization which normalizes each channel independently, adaptive layer normalization normalizes the entire feature map. The style vector S is also concatenated with the output to every token from each long short-term memory layer as the input\nd0ik | to the next long short-term memory layer. Lastly, we have a final bidirectional long short-term memory network and a linear projection L that maps H prosody into the predicted duration.\n0x0s | The hidden representation H prosody is dotted with the alignment D align and sent to the prosody decoder. The prosody encoder consists of one bidirectional long short-term memory network and two sets of three residual blocks with adaptive instance normalization followed by a linear projection, one for predicting the F zero and another for predicting the energy, respectively.",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394636,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 247,
    "prompt_tokens": 1939,
    "total_tokens": 2186
  }
}