You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document.

Your task is to label each textbox with exactly one of the following labels:
  title: the primary document title, no more than one per document
  heading: the name of the following chapter or section (should never start in the middle of the previous paragraph)
  subheading: a secondary heading, often following another heading (should never start in the middle of the previous paragraph)
  body: main paragraph content: may start or end in the middle of a word, use context to follow paragraphs that are split across textboxes (if a textbox contains both heading and body text, label it "body")
  math: textbox primarily containing math
  imageDescription: standalone callout that only describes an image, chart, table, or similar (typically begins with "Table...", "Figure...", "Fig. ...", "Above...", "Left...", etc.)
  authors: names of contributors to this document
  institutions: list of universities, business, and other institutions affiliated with this document
  publisher: info about the publisher, or provided by the publisher, including copyright info
  pagenum: the page number
  headerOrFooter: boilerplate text page number, or redundant headings at the top/bottom of the page
  toc: the table of contents
  references: bibliographic references and resources
  acknowledgements: thanks and credits to contributors
  appendix: index, appendix, or any other end matter not part of the main thread (including related headings)
  table: tabular data, label, title, or subheading for a grid or list of data
  datum: numeric data or data label from a chart or list
  advertisement: promotional ads and marketing
  layout: non-content related to the layout of the page, e.g. sidebar navigation
  callout: pull quote or long block text that stands apart from the main text
  footnote: footnotes and endnotes near the bottom of the page
  keywords: list of keywords or tags
  url: web address or email
  other: any other text that does not belong to the main thread

Each line of input is prefixed with a textbox ID in the format `id | Text content`. The output must be in the format `id | label`.

Note that body text may be split across multiple textboxes, and textboxes may start or end in the middle of a sentence or word. Because the text was extracted from a web page or document, paragraphs of body text may be interrupted by multiple textboxes of redundant headers, footnotes, page numbers, tables, images, etc. For example, a real heading will never interrupt the middle of a sentence. Use context clues like this to carefully label each textbox.

EXAMPLE INPUT:
1pjs | Neuroscience Applied 1 (2022) 101012
o2kr | Contents lists available at ScienceDirect
v6sk | Neuroscience Applied
1wj6 | journal homepage: www.journals.elsevier.com/neuroscience-applied
936l | Research Articles
06yq | Microdosing with psychedelics to self-medicate for ADHD symptoms in adults: A naturalistic study
dpv6 | ARTICLE INFO
8r5j | ABSTRACT
2taz | Keywords: ADHD Microdosing Psychedelics Self-medication Well-being Time perception
o3ya | ADHD in adulthood is often overlooked, which negatively affects the individual's well-being. First-line phar- macological interventions are effective in many ADHD patients, relieving symptoms rapidly. However, there seems to be a proportion of individuals who discontinue, or fail to respond to these treatments. For these in- dividuals, alternative treatment options should be explored.
r5il | 1. Introduction
5gui | Attention deficit hyperactivity disorder (ADHD) is one of the most common developmental disorders worldwide. Prevalence research indicates that 2.6% of the adult population has persistent ADHD. ADHD in adults is often overlooked because of the high comorbidity rate and lack of knowledge about how ADHD is expressed in adulthood (Kooij et al.,
9d4o | Fig. 1. Flowchart of included participants for each time point.
82qc | 2019). In addition, ADHD is associated with deficits in various domains of cogni- tive functioning. Twenty-five percent of ADHD cases suffered from ADHD symptoms purely because of de- ficiencies in temporal processing (Sonuga-Barke et al., 2010).
ls7d | First-line ADHD treatments in adults mainly include pharmacological interventions to enhance dopaminergic and noradrenergic neurotrans- mission with stimulants. Overall, they have been proven to work effectively in adults with ADHD, inducing fast symptom relief and thereby enhancing the person's quality of life. In the
5esx | Table 1 Demographic information from respondents at baseline and the two and four- week time points.
t8vv | longer term, approximately twenty percent of ADHD patients discontinue their prescribed medication after six to nine months, thirty percent after one year, and half of them after two years.
xrd1 | 2. Material and methods
5746 | 2.1. Study design and participants
7toz | The study employed a naturalistic design, assessing the experiences of participants at baseline,
j346 | Neuroscience Applied 1 (2022)
m5ka | E.C.H.M. Haijen et al.
kx2c | REVIEW
v8uq | before they start MD on their own initiative, and at two and four weeks after MD initiation. The target population included adults diagnosed with ADHD and individuals who experienced ADHD symptoms to the extent that these interfered with their daily lives and who had not been diag- nosed with ADHD before. To be included in the analyses, participants needed to score above a cut-off point on at least one of the subscales of the Conner's Adult ADHD Rating Scale (CAARS-S:SV).
2zmw | Fig. 2. Mean scores of the CAARS-S:SV DSM-IV total symptoms T-scores at baseline (0W) and two (2W) and four weeks (4W) after MD (A) of the whole sample, and (B) per conventional ADHD medication use. Error bars represent mean error.
sdk3 | <LATEX>\lim _ { x ightarrow \infty } rac { 6 x ^ { 2 } + 1 0 0 } { 7 x ^ { 2 } - 1 0 } =</LATEX>
x972 | 2.2. Study procedure
k221 | Mean performance measures of the CAARS-

EXAMPLE OUTPUT:
1pjs | headerOrFooter
o2kr | publisher
v6sk | publisher
1wj6 | publisher
936l | headerOrFooter
06yq | title
dpv6 | other
8r5j | heading
2taz | keywords
o3ya | body
r5il | heading
5gui | body
9d4o | imageDescription
82qc | body
ls7d | body
5esx | imageDescription
t8vv | body
xrd1 | heading
5746 | subheading
7toz | body
j346 | headerOrFooter
m5ka | authors
kx2c | headerOrFooter
v8uq | body
2zmw | imageDescription
sdk3 | math
x972 | heading
k221 | body




km8w | ni 1 j=1 ni log po (x , xi, <j) where 0 parameterizes the Planning LM. (1) Xi
wzno | argmax ( Po (X) == = >
xagm | 3.2 Admissible Action Parsing by Semantic Translation
iwn5 | One issue arises when naively following the above approach to generate action plans: the plan expressed in free-form language often cannot be mapped to unambiguous actionable steps and thus is not executable by a robotic agent. Many reasons can cause such failures: 1) the output does not follow pre-defined mappings of any atomic action (e.g. "I first walk to the bedroom" is not of the format "walk to (PLACE)"), 2) the output may refer to atomic action and objects using words unrecognizable by the environment (e.g. "microwave the chocolate milk" where "microwave" and "chocolate milk" cannot be mapped to precise action and object), or 3) the output contains lexically ambiguous words (e.g. "open TV" should instead be "switch on TV").
uooz | Instead of developing a set of rules to transform the free-form text into admissible action steps, we propose to again leverage world knowledge learned by language models to semantically translate the action. For each admissible environment action <LATEX>a _ { e } ,</LATEX> we calculate its semantic distance to the predicted action phrase <LATEX>\widehat { a }</LATEX> by cosine similarity:
pxbq | <LATEX>C \left( f \left( \widehat { a } \right) , f \left( a _ { e } \right) \right) : = \frac { f \left( \widehat { a } \right) \cdot f \left( a _ { e } \right) } { \| f \left( \widehat { a } \right) \| \| f \left( a _ { e } \right) \| } \mathrm { w h e r e } f \text { is an embedding function. } .</LATEX> (2)
jfsr | To embed the output action phrase and environment actions, we use a BERT-style LM [10, 27] pre-trained with Sentence-BERT [41] objective, to which we refer as Translation LM3. The action embedding is obtained by mean-pooling the last layer hidden states across all tokens in that action phrase. While the set of admissible actions in our environment is discrete and possible to exhaustively enumerate, sampling or projection can be employed in larger discrete or continuous action spaces.
u15r | 3.3 Autoregressive Trajectory Correction
lq35 | Translating each step of the program after the entire program has been synthesized lacks consideration of achievability of individual steps and subjects to compounding errors. In practice, LLMs might output compounded instructions for a single step, even though it cannot be completed using one admissible action in the environment. To this end, we can instead interleave plan generation and action translation to allow for automatic trajectory correction. At each step, we first query Planning LM to generate <LATEX>k</LATEX> samples for a single action <LATEX>\left( \widehat { a _ { 1 } } , \widehat { a _ { 2 } } , \ldots , \widehat { a _ { k } } \right) .</LATEX> For each sample <LATEX>\widehat { a } ,</LATEX> we consider both its semantic soundness and its achievability in the environment. Specifically, we aim to find admissible environment action <LATEX>a _ { e }</LATEX> by modifying the ranking scheme described in Equation 1 as follows:
3g9w | <LATEX>\arg \max _ { a _ { e } } \left[ \max _ { \widehat { a } } C \left( f \left( \widehat { a } \right) , f \left( a _ { e } \right) \right) + \beta \cdot P _ { \theta } \left( \widehat { a } \right) \right] \mathrm { w h e r e } \beta \text { is a weighting coefficient. } .</LATEX> (3)
d09o | Then we append the translated environment action <LATEX>a _ { e }</LATEX> to the unfinished text completion. This way all subsequent steps will be conditioned on admissible actions instead of free-form action phrases generated by Planning LM. Furthermore, we can use Translation LM to detect out-of-distribution actions, those outside the capabilities of a robot, and terminate a program early instead of mapping to a faulty action. This can be achieved by setting a threshold <LATEX>\epsilon</LATEX> such that if <LATEX>\max _ { \widehat { a } , a _ { e } } C \left( f \left( \widehat { a } \right) , f \left( a _ { e } \right) \right) +</LATEX> <LATEX>\beta \cdot P _ { \theta } \left( \widehat { a } \right) < \epsilon</LATEX> at step <LATEX>t</LATEX> t, the program is terminated early. Since we now sample Planning LM for individual steps instead of an entire sequence, another termination condition we consider is when > 50% of current-step samples are 0-length (excluding leading or trailing non-English text tokens).
ylhz | 3.4 Dynamic Example Selection for Improved Knowledge Extraction
a3td | So far in the text, we always give the same example in the prompt for all query tasks. However, consider the task of "ordering pizza". Prompting LLMs with this task may give the assumption that the agent is initialized in front of a computer, and the LLMs may guide the agent to search for a pizza store and click "checkout my cart". Although these are reasonable and feasible in the real world, such assumption cannot always be made as these interactions may not be supported in simulated environments. In fact, the closest series of actions that human experts give in VirtualHome may be "walking to a computer", "switching on the computer", and "typing the keyboard". Without being fine-tuned on these data, LLMs would often fail at these tasks.
ex5k | To provide weak supervision at inference time, we propose to select the most similar task <LATEX>T</LATEX> and its example plan E from the demonstration set to be used as the example in the prompt. Specifically, we re-use the same Translation LM introduced in Section 3.2 and select <LATEX>\left( T ^ { * } , E ^ { * } \right)</LATEX> whose high-level task name <LATEX>T ^ { * }</LATEX> maximizes <LATEX>C \left( f \left( T \right) , f \left( Q \right) \right) ,</LATEX> where <LATEX>Q</LATEX> is the query task. This approach bears resemblance to several recent works [37, 13, 26, 43]. An example is shown in Figure 2 where "Shave" is the most similar to the query task "Apply lotion".
9d4o | FINAL METHOD Combining the various improvement discussed above, we refer to the final method as Translated (LM) , where (LM) is replaced by specific language model used such as GPT-3.
cjq2 | Figure 3: Visualization of VirtualHome programs generated by our approach. The top row shows the execution of the task "Complete Amazon Turk Surveys", and the bottom row shows the task "Get Glass of Milk". We show LLMs not only can generate sensible action plans given only high-level tasks but also contains the actionable knowledge that can be extracted for grounding in embodied environments.
5esx | 4 Results
m5ka | In this section, we first show that language models can generate sensible action plans for many high-level tasks, even without any additional training. Then we highlight its inadequacy when naively applied to embodied environments and demonstrate how this can be improved by again leveraging world knowledge learned by LLMs. Visualization of generated programs is shown in Figure 3.
byu8 | Sampling from LMs Pre-trained LMs are sensitive to sampling parameters and the specific exam- ple given in the prompt. For all evaluated methods, we perform hyperparameter search over various sampling parameters, and for methods using a fixed prompt example, we report metrics averaged across three randomly chosen examples. To select the best run for each method, we rank the runs by the sum of LCS and executability, each normalized by human-expert scores. Further details are in Appendix A.1.
76b0 | Model Choices For Planning LM, we evaluate a representative set of causal language models. For Translation LM, we mainly use Sentence-RoBERTa-355M and provide relevant ablations in Section 5.3. GPT-3 and Codex are accessed using OpenAI API, and the remaining models are accessed through open-source packages, Hugging Face Transformers [55] and SentenceTransformers [41], all without additional training (except for the fine-tuning baseline).
zxz6 | 4.1 Do LLMs contain actionable knowledge for high-level tasks?
xnth | We first investigate whether LLMs can generate sensible action plans expressed in free-form language. We use the approach described in Section 3.1 to query pre-trained LLMs. To evaluate the correctness of generated action plans, we conduct human evaluations. For each model, we ask 10 human annotators to determine - by answering "Yes" or "No" - whether each task can be completed using provided action steps. To provide a reference of how humans might rate the action plans provided by other humans, we also ask annotators to rate the human-written action plans included in the VirtualHome dataset for the same set of tasks. In contrast to the free-form text output by LLMs, humans wrote the plans using a graphical programming interface that enforces strict syntax and a chosen set of atomic action vocabulary, which limit the expressivity and the completeness of their answers4. More details of our human evaluation procedure can be found in Appendix A.2.
vafm | We show the human evaluation results in Figure 1, where the y-axis shows correctness averaged across all tasks and all annotators. Surprisingly, when LLMs are large enough and without imposed syntactic constraints, they can generate highly realistic action plans whose correctness - as deemed by human annotators - even surpasses human-written action plans. We also observe some level of correctness for smaller models such as GPT-2. However, inspection of its produced output indicates
2zmw | Table 1: Human-evaluated correctness and evaluation results in VirtualHome. Although action plans generated by large language models can match or even surpass human-written plans in correctness measure, they are rarely executable. By translating the naive action plans, we show an important step towards grounding LLMs in embodied environments, but we observe room to achieve this without trading executability for correctness. We also observe a failure mode among smaller models that lead to high executability. For correctness measure, standard error of the mean across 10 human annotators is reported in the parenthesis.
bf9k | that it often generates shorter plans by ignoring common-sense actions or by simply rephrasing the given task (e.g. the task "Go to sleep" produces only a single step "Go to bed"). These failure modes sometimes mislead human annotators to mark them correct as the annotators may ignore common-sense actions in their judgment as well, resulting in a higher correctness rate than the quality of the output shows.
otkr | 4.2 How executable are the LLM action plans?
ibgs | We analyze the executability of LLM plans by evaluating them in all 7 household scenes in Virtual- Home. As shown in Table 1, we find action plans generated naively by LLMs are generally not very executable. Although smaller models seem to have higher executability, we find that the majority of these executable plans are produced by ignoring the queried task and repeating the given example of a different task. This is validated by the fact that smaller models have lower LCS than larger models despite having high executability, showing that this failure mode is prevalent among smaller models. In contrast, larger models do not suffer severely from this failure mode. Yet as a result of being more expressive, their generated programs are substantially less executable.
colo | 4.3 Can LLM action plans be made executable by proposed procedure?
d6r4 | We evaluate the effectiveness of our proposed procedure of action translation. We first create a bank of all allowed 47522 action steps in the environment, including all possible combinations of atomic actions and allowed arguments/objects. Then we use an off-the-shelf Sentence-RoBERTa [27, 41] as Translation LM to create embeddings for actions and output text. For better computational efficiency, we pre-compute the embeddings for all allowed actions, leaving minor computation overhead for our procedure over the baseline methods at inference time. As shown in Table 1, executability of generated programs is significantly improved. Furthermore, we also observe improved LCS because the translated action steps precisely follow the program syntax and thus are more similar to the plans produced by human experts. Sample output is shown in Figure 1 and a larger random subset of generated samples can be found in Appendix A.5.
9mrz | To validate their correctness, we again perform human evaluations using the same procedure from Section 4.1. Results are shown in Table 1. We find that despite being more similar to human-written plans as they follow strict syntax, the programs are deemed less correct by humans compared to their vanilla counterparts. By examining the output, we observe two main sources of errors. First, we find Translation LM is poor at mapping compounded instructions to a succinct admissible action, e.g. "brush teeth with toothbrush and toothpaste". Second, we find that the generated programs are sometimes terminated too early. This is partly due to the imperfect expressivity of the environment;
pk06 | 9
7wn9 | certain necessary actions or objects are not implemented to fully achieve some tasks, so Translation LM cannot map to a sufficiently similar action. This is also reflected by our human evaluation results of the programs written by other humans, as only 70% of the programs are considered complete.
wcd0 | 5 Analysis and Discussions
caos | 5.1 Ablation of design decisions
qrvy | We perform ablation studies for the three components of our proposed procedure, described in Section 3.2, 3.3, and 3.4 respectively. As shown in Table 2, leaving out any of the three components would all lead to decreased performance in both executability and LCS. An exception is Translated GPT-3 w/o Trajectory Correction, where we observe a slight improvement in LCS at the expense of a considerable drop in executability. Among the three proposed components, leaving out action transla- tion leads to the most significant executability drop, showing the importance of action translation in extracting executable action plans from LLMs.
pn9j | Table 2: Ablation of three proposed techniques.
1pmc | 5.2 Are the generated action plans grounded in the environment?
5z6q | Since successful execution of correct action plans directly measures grounding, we calculate the percentage of generated action plans that are both correct and executable. We deem an action plan to be correct if 70% or more human annotators decide it is correct. Human-written plans are 100% executable, of which 65.91% are deemed correct. Results for LMs are shown in Figure 4.
yeoh | Although smaller LMs such as GPT-2 can generate highly executable action plans as shown in Table 1, these executable plans mostly are not correct, as they often repeat the given example or do not contain all necessary steps. Increasing model parameters can lead to some improvement in generating plans that are both executable and correct, yet it scales poorly with the parameter count. In the meantime, action translation offers a promising way towards grounding actionable knowledge by producing executable and correct plans, though a large gap remains to be closed to reach human-level performance (65.91%).