You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document. Your task is to faithfully reproduce the text for our text-to-speech engine so that it is easily read aloud.

Note that the text might not start at the beginning and paragraphs may be split acrosss multiple textboxes. Textboxes may start or end in the middle of a word which is acceptable: do not combine text between textboxes and leave broken words at the start and end of a textbox unchanged.

You will receive one textbox per-line in the format `id | Textbox content`. The output must be in the format `id | Clean content`.

RULES:
 • Remove inline citations and references e.g. "(Author, 2021)" or "(https://wikipedia.org/article.html)" or "[ECMOS 35b, 47, 49]".
 • Spell out numbers, dates, and chemical formulas for the TTS engine e.g. "-2.5" -> "negative two point five" or "Jan. 2020" -> "January twenty twenty".
 • Spell out LaTeX formulas for the TTS engine e.g. "<LATEX>p = 1</LATEX>" -> "P equals one".
 • Rejoin hyphenated word fragments within the same textbox e.g. "synth -esize" -> "synthesize".
 • Fix simple typos and OCR errors e.g. "O nce upon a 1ime." -> "Once upon a time.".
 • Delete nonsequiter textboxes that interrupt the middle of a sentence if they obviously do not belong.

Otherwise, the output should exactly match the input text:
 • Do not combine text across lines or attempt to fix words broken across lines.
 • Ensure each ID from the input is included in the output.
 • Make as few changes as possible while respecting the above rules.

EXAMPLE INPUT:
ccpt | stigate the effectiveness of psychedelics for ADHD symp- toms in adults.
0fpw | 2. Materia1 and methods
dqn8 | 2.1. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at 2 and 4 weeks after initiation. The target population included adults with ADHD symptoms who had not been diag- nosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale (CAARS-S:SV). This cut-off was indicative of clinically elevated symptoms (Conners et al., 1999) (see section 2.3).
82ju | 2.2. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics (www.microdo sing.nl). Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took 20 min to complete. If the survey had not been completed after 24 h, a reminder was sent. Each of the surveys at the 2- and 4-week time points took about 15 min to complete. Par- ticipants were able to pause the surveys. Data collection occurred between Nov. 2020 and Jul. 2021. The study was approved by the Ethics Review Committee of Psy- chology and Neuroscience at Maastricht University (ERCPN- 215_05_11_2019_A1).
1piq | 2.3. Measures
7fqw | 2.3.1. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psyche- delics (i.e., ayahuasca, DMT, 5-MeO-DMT, LSD, novel lysergamides (e.g., 1P-LSD, ALD-52), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | 2.3.2. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD (Kooij et al., 2019), or because these diagnoses were reported to be common in people who microdose (Fadiman and Korb, 2019). We 
3j2l | REVIEW ARTICLE Frontiers in Psychiatry | www.frontiersin.org
03k3 | 2
1k9e | constructed a variable Comorbidity alongside ADHD, differenti- ating respondents with and without a comorbid diagnosis alongside ADHD (<LATEX>p < . 0 0 1 =</LATEX> only ADHD or no ADHD diagnosis; <LATEX>p > . 0 1 =</LATEX> ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conven- tiona1 ADHD medication alongside microdosing (<LATEX>0 =</LATEX> only microdosing; <LATEX>1 =</LATEX> conven-

EXAMPLE OUTPUT:
ccpt | stigate the effectiveness of psychedelics for ADHD symptoms in adults.
0fpw | Two. Material and methods
dqn8 | Two point one. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at two and four weeks after initiation. The target population included adults with ADHD symptoms who had not been diagnosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale. This cut-off was indicative of clinically elevated symptoms (see section two point three).
82ju | Two point two. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics. Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took twenty minutes to complete. If the survey had not been completed after twenty-four hours, a reminder was sent. Each of the surveys at the two and four-week time points took about fifteen minutes to complete. Participants were able to pause the surveys. Data collection occurred between November twenty twenty and July twenty twenty-one. The study was approved by the Ethics Review Committee of Psychology and Neuroscience at Maastricht University.
1piq | Two point three. Measures
7fqw | Two point three point one. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psychedelics (i.e., ayahuasca, DMT, five-MeO-DMT, LSD, novel lysergamides (e.g., one-P-LSD, ALD-fifty-two), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | Two point three point two. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD, or because these diagnoses were reported to be common in people who microdose. We
3j2l | REVIEW ARTICLE Frontiers in Psychiatry: www.frontiersin.org
03k3 | Two
1k9e | constructed a variable Comorbidity alongside ADHD, differentiating respondents with and without a comorbid diagnosis alongside ADHD (P is less than point zero zero one equals only ADHD or no ADHD diagnosis; P is greater than point zero one equals ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conventional ADHD medication alongside microdosing (zero equals only microdosing; one equals conven-




w4hq | PGRAPH graph2, PTRANS trans)
ghbe | Returns PGRAPH { // Create new graph PGRAPH ngraph = new_graph ()
1lkf | // Create map between token positions // and nodes of the new graph PNODE map [PNODE, PNODE] = new_empty_map() map [endnode (graph1), endnode(graph2)] = endnode (newgraph)
uobn | // Recursive subroutine for simulating tokens Function simtokens (PNODE node1, PNODE node2) Returns PNODE {
3194 | PNODE currentnode = map[node1, node2] // Check if already visited If (currentnode == nil)
r22o | // Record new configuration currentnode = ngraph->create_node () map [node1, node2] = currentnode // Enumerate the possible non-null // joint token transitions For ARC arc1 in down_arcs (node1) For ARC arc2 in down_arcs (node2) If (trans->check(arc1, arc2)) PNODE newnode = simtokens (down_node (arc1) , down_node (arc2)) trans->fprop(ngraph, currentnode, newnode, arc1, arc2) // Return node in composed graph Return currentnode }
nupw | // Perform token simulation simtokens (startnode(graph1), startnode(graph2)) Delete map Return ngraph }
37xs | trajectory is acceptable (i.e., both tokens simultaneously reach the end nodes of their graphs). The management of null transitions is a straightforward modification of the token simulation function. Before enumerating the possible nonnull joint token transitions, we loop on the possible null transitions of each token, recursively call the token simulation function, and finally call the method fprop. The safest way for identifying acceptable trajectories con- sists of running a preliminary pass for identifying the token configurations from which we can reach the terminal configuration (i.e., both tokens on the end nodes). This
hoi0 | is easily achieved by enumerating the trajectories in the opposite direction. We start on the end nodes and follow the arcs upstream. During the main pass, we only build the nodes that allow the tokens to reach the terminal configuration.
tffb | Graph composition using transducers (i.e., standard trans- duction) is easily and efficiently implemented as a gener- alized transduction. The method check simply tests the equality of the input symbols on the two arcs, and the method fprop creates a single arc whose symbol is the output symbol on the transducer's arc.
ewwt | The composition between pairs of graphs is particularly useful for incorporating linguistic constraints in a handwrit- ing recognizer. Examples of its use are given in the online handwriting recognition system described in Section IX (and in the check reading system described in Section X).
2tj1 | In the rest of the paper, the term composition transformer will denote a GT based on the generalized transductions of multiple graphs. The concept of generalized transduc- tion is a very general one. In fact, many of the GT's described earlier in this paper, such as the segmenter and the recognizer, can be formulated in terms of generalized transduction. In this case, the generalized transduction does not take two input graphs but a single input graph. The method fprop of the transformer may create several arcs or even a complete subgraph for each arc of the initial graph. In fact the pair check, fprop itself can be seen as procedurally defining a transducer.
nbhq | In addition, it can be shown that the generalized trans- duction of a single graph is theoretically equivalent to the standard composition of this graph with a particular transducer graph. However, implementing the operation this way may be very inefficient since the transducer can be very complicated.
w251 | In practice, the graph produced by a generalized transduc- tion is represented procedurally in order to avoid building the whole output graph (which may be huge when for example the interpretation graph is composed with the grammar graph). We only instantiate the nodes which are visited by the search algorithm during recognition (e.g., Viterbi). This strategy propagates the benefits of pruning algorithms (e.g., beam search) in all the GTN's.
1vgx | D. Notes on the Graph Structures
yjnk | Section VI discussed the idea of global training by back- propagating gradient through simple GT's. The bprop method is the basis of the back-propagation algorithm for generic GT's. A generalized composition transformer can be seen as dynamically establishing functional relation- ships between the numerical quantities on the input and output arcs. Once the check function has decided that a relationship should be established, the fprop function im- plements the numerical relationship. The check function establishes the structure of the ephemeral network inside the composition transformer.
9zmh | Since fprop is assumed to be differentiable, gradients can be back propagated through that structure. Most param- eters affect the scores stored on the arcs of the successive
mi3g | graphs of the system. A few threshold parameters may determine whether an arc appears or not in the graph. Since nonexisting arcs are equivalent to arcs with very large penalties, we only consider the case of parameters affecting the penalties.
ntjg | In the kind of systems we have discussed until now (and the application described in Section X), much of the knowledge about the structure of the graph that is produced by a GT is determined by the nature of the GT, but it may also depend on the value of the parameters and on the input. It may also be interesting to consider GT modules which attempt to learn the structure of the output graph. This might be considered a combinatorial problem and not amenable to gradient-based learning, but a solution to this problem is to generate a large graph that contains the graph candidates as subgraphs, and then select the appropriate subgraph.
86at | E. GTN and HMM's
bpd2 | GTN's can be seen as a generalization and an extension of HMM's. On the one hand, the probabilistic interpretation can be either kept (with penalties being log-probabilities), pushed to the final decision stage (with the difference of the constrained forward penalty and the unconstrained for- ward penalty being interpreted as negative log-probabilities of label sequences), or dropped altogether (the network just represents a decision surface for label sequences in input space). On the other hand, GTN's extend HMM's by allowing to combine in a well-principled framework multiple levels of processing, or multiple models (e.g., Pereira et al. have been using the transducer framework for stacking HMM's representing different levels of processing in automatic speech recognition [86]).
hkd8 | Unfolding an HMM in time yields a graph that is very similar to our interpretation graph (at the final stage of processing of the GTN, before Viterbi recognition). It has nodes n(t, i) associated to each time step t and state i in the model. The penalty Ci for an arc from n(t - 1, j) to n(t, i) then corresponds to the negative log-probability of emitting observed data ot at position t and going from state j to state i in the time interval (t- 1,t). With this probabilistic interpretation, the forward penalty is the negative logarithm of the likelihood of whole observed data sequence (given the model).