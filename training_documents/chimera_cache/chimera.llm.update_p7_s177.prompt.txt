You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document. Your task is to faithfully reproduce the text for our text-to-speech engine so that it is easily read aloud.

Note that the text might not start at the beginning and paragraphs may be split acrosss multiple textboxes. Textboxes may start or end in the middle of a word which is acceptable: do not combine text between textboxes and leave broken words at the start and end of a textbox unchanged.

You will receive one textbox per-line in the format `id | Textbox content`. The output must be in the format `id | Clean content`.

RULES:
 • Remove inline citations and references e.g. "(Author, 2021)" or "(https://wikipedia.org/article.html)" or "[ECMOS 35b, 47, 49]".
 • Spell out numbers, dates, and chemical formulas for the TTS engine e.g. "-2.5" -> "negative two point five" or "Jan. 2020" -> "January twenty twenty".
 • Spell out LaTeX formulas for the TTS engine e.g. "<LATEX>p = 1</LATEX>" -> "P equals one".
 • Rejoin hyphenated word fragments within the same textbox e.g. "synth -esize" -> "synthesize".
 • Fix simple typos and OCR errors e.g. "O nce upon a 1ime." -> "Once upon a time.".
 • Delete nonsequiter textboxes that interrupt the middle of a sentence if they obviously do not belong.

Otherwise, the output should exactly match the input text:
 • Do not combine text across lines or attempt to fix words broken across lines.
 • Ensure each ID from the input is included in the output.
 • Make as few changes as possible while respecting the above rules.

EXAMPLE INPUT:
ccpt | stigate the effectiveness of psychedelics for ADHD symp- toms in adults.
0fpw | 2. Materia1 and methods
dqn8 | 2.1. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at 2 and 4 weeks after initiation. The target population included adults with ADHD symptoms who had not been diag- nosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale (CAARS-S:SV). This cut-off was indicative of clinically elevated symptoms (Conners et al., 1999) (see section 2.3).
82ju | 2.2. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics (www.microdo sing.nl). Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took 20 min to complete. If the survey had not been completed after 24 h, a reminder was sent. Each of the surveys at the 2- and 4-week time points took about 15 min to complete. Par- ticipants were able to pause the surveys. Data collection occurred between Nov. 2020 and Jul. 2021. The study was approved by the Ethics Review Committee of Psy- chology and Neuroscience at Maastricht University (ERCPN- 215_05_11_2019_A1).
1piq | 2.3. Measures
7fqw | 2.3.1. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psyche- delics (i.e., ayahuasca, DMT, 5-MeO-DMT, LSD, novel lysergamides (e.g., 1P-LSD, ALD-52), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | 2.3.2. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD (Kooij et al., 2019), or because these diagnoses were reported to be common in people who microdose (Fadiman and Korb, 2019). We 
3j2l | REVIEW ARTICLE Frontiers in Psychiatry | www.frontiersin.org
03k3 | 2
1k9e | constructed a variable Comorbidity alongside ADHD, differenti- ating respondents with and without a comorbid diagnosis alongside ADHD (<LATEX>p < . 0 0 1 =</LATEX> only ADHD or no ADHD diagnosis; <LATEX>p > . 0 1 =</LATEX> ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conven- tiona1 ADHD medication alongside microdosing (<LATEX>0 =</LATEX> only microdosing; <LATEX>1 =</LATEX> conven-

EXAMPLE OUTPUT:
ccpt | stigate the effectiveness of psychedelics for ADHD symptoms in adults.
0fpw | Two. Material and methods
dqn8 | Two point one. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at two and four weeks after initiation. The target population included adults with ADHD symptoms who had not been diagnosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale. This cut-off was indicative of clinically elevated symptoms (see section two point three).
82ju | Two point two. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics. Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took twenty minutes to complete. If the survey had not been completed after twenty-four hours, a reminder was sent. Each of the surveys at the two and four-week time points took about fifteen minutes to complete. Participants were able to pause the surveys. Data collection occurred between November twenty twenty and July twenty twenty-one. The study was approved by the Ethics Review Committee of Psychology and Neuroscience at Maastricht University.
1piq | Two point three. Measures
7fqw | Two point three point one. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psychedelics (i.e., ayahuasca, DMT, five-MeO-DMT, LSD, novel lysergamides (e.g., one-P-LSD, ALD-fifty-two), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | Two point three point two. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD, or because these diagnoses were reported to be common in people who microdose. We
3j2l | REVIEW ARTICLE Frontiers in Psychiatry: www.frontiersin.org
03k3 | Two
1k9e | constructed a variable Comorbidity alongside ADHD, differentiating respondents with and without a comorbid diagnosis alongside ADHD (P is less than point zero zero one equals only ADHD or no ADHD diagnosis; P is greater than point zero one equals ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conventional ADHD medication alongside microdosing (zero equals only microdosing; one equals conven-




8p6h | <LATEX>\left[ \left( D - D / 2 f + 1 \right) M _ { a } \right. ,</LATEX> <LATEX>\left. D * M _ { a } \right]</LATEX> For any <LATEX>f \in F ,</LATEX> Chimera can scale to more micro-batches (i.e., <LATEX>\left. N > D \right)</LATEX> using the methods discussed in Section 3.5. For a given <LATEX>f ,</LATEX> Chimera incurs <LATEX>2 \left( D / f / 2 - 1 \right)</LATEX> bubbles, but has to maintain <LATEX>2 f</LATEX> model replicas and synchronize the gradients of 2f stages on each worker.
pmgl | The larger the value of <LATEX>f ,</LATEX> the less bubbles (and the more balanced activations memory consumption), but also the higher gradient syn- chronization overhead and weights memory consumption. When <LATEX>f = Q ,</LATEX> Chimera degrades to pure data parallelism. Empirical results in Section 4.4 show that <LATEX>f > 1</LATEX> rarely brings more performance bene- fit on the models used for evaluation. Thus, <LATEX>f = 1</LATEX> (i.e., a combination of two pipelines) is the default setting for Chimera in this paper, unless otherwise stated. We expect that <LATEX>f > 1 ,</LATEX> whose features are summarized in Table 3, would further improve the performance for future deep models with deeper pipeline.
90no | 4 EXPERIMENTAL EVALUATION
jt0y | We conduct our experiments mainly on the CSCS Piz Daint super- computer. Each Cray XC50 compute node contains an Intel Xeon E5-2690 CPU, and one NVIDIA P100 GPU with 16 GB global mem- ory. The compute nodes of Piz Daint are connected by Cray Aries interconnect network in a Dragonfly topology.
qb7o | We also evaluate the performance on a small cluster equipped with 32 NVIDIA V100 GPUs. The cluster has four GPU servers connected by Infiniband, and each server has eight V100 GPUS with NVLink. Each V100 GPU has 32 GB global memory.
oae5 | We evaluate the performance of the schemes listed in Table 2, which covers the state-of-the-art. For a fair comparison, all schemes are implemented in PyTorch [41] with GLOO [15] distributed back- end for both the point-to-point <LATEX>\left( p 2 p \right)</LATEX> communication between pipeline stages and gradient synchronization (allreduce) across the stage replicas, and GPU devices are utilized for acceleration. Al- though NCCL [40] backend of PyTorch performs better for allreduce
s0fl | <LATEX>> = 5 1 2</LATEX> across GPU nodes (with GPUDirect RDMA), it does not support p2p communication. Using NCCL for gradient synchronization and GLOO for <LATEX>p 2 p</LATEX> at the same time fails, which is also observed in PipeDream [38]. We use the language models summarized in Ta- ble 4 for evaluation, and the max sequence length of Bert-48 and GPT-2 are set to 128 and 632 respectively, unless otherwise stated. The mini-batch size and sequence length we use are consistent with those in the machine learning community [13, 43, 56, 59]. Since Chimera is a synchronous approach without compromising conver- gence accuracy, we focus on the training throughput comparison.
43ia | 4.1 Memory Consumption
3g2y | 4.2 Parallel Scalability
gc7v | We first find the best configuration for each approach, and compare their best performance in the test of weak scaling.
wqfv | 4.2.1 Performance Optimization Space for the Baselines. Given the mini-batch size B and the number of workers P, the best config- uration of B (micro-batch size), D ( pipeline stages), and W (the number of replicated pipelines) is not obvious a priori because of the trade-offs (i.e., computational efficiency and bubbles, allre- duce and p2p communication overhead). We search the space of the parameters (W, D, and B (for power-of-two)) to find the best performance for each baseline. The results for Bert-48 on 32 GPU nodes are presented in Figure 10.
j30a | For synchronous baselines (such as GPipe and DAPPLE), the value of B affects both computational efficiency and the bubble ra- tio. The planner of DAPPLE [16] gives an answer for how to select the configuration of W and D based on the profiling information, but it is not clear for how to select the best B. From Figure 10 we can see the highest throughput of both DAPPLE and GPipe (with activation recomputation) is achieved by (W=8, D=4, B=4), under which they hit the sweet spot for the trade-off between p2p commu- nication overhead and allreduce communication overhead by (W=8, D=4), and the sweet spot for the trade-off between bubble ratio and computational efficiency by B=4 (and N=16). GEMS prefers a large B for high computational efficiency since a smaller B does not help a lot to reduce the bubble ratio, and therefore its best performance is achieved by (W=8, D=4, B=32).
7bdk | Asynchronous baselines (PipeDream-2BW and PipeDream) al- ways prefer the maximum B fitting in the device memory, since there is no bubble problem for them. Note that PipeDream conducts gradient synchronization across W pipelines after each backward pass on a micro-batch, thus its B is limited by the maximum B. Since the frequent gradient synchronization of PipeDream leads to high allreduce overhead, its best performance is achieved with a deeper pipeline than others, namely by (W=4, D=8, B=48). PipeDream- 2BW scales to large B by accumulating the gradients for more than D micro-batches (i.e., N>=D), and its best performance is achieved by (W=8, D=4, B=16) with activation recomputation.
fim0 | For GPT-2, we present the performance tuning for each baseline by searching the parameter space in Figure 11.
ojro | 4.2.2 Performance Modelling of Chimera. We first evaluate the performance of Chimera with different gradient synchronization strategies discussed in Section 3.2. We use eager-sync to denote
l6t9 | eager synchronization also conducted for the middle stages, and eager-sync-opt to denote eager synchronization not conducted for the middle stages. Results in Figure 12 show that eager-sync-opt achieves higher (e.g., 1.09x on 64 nodes) throughput than eager-sync. These empirical results support our claim in Section 3.2.