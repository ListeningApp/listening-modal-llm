{
  "id": "chatcmpl-A3U7QtAq7IR86nF8Ziv3CKmwiOj1O",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "8gxa | Gradient-Based Learning Applied to Document Recognition\nfsvi | Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of two dimensional shapes, are shown to outperform all other techniques.\n068d | Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called graph transformer networks, allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure.\nysz7 | Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks.\nk5db | A graph transformer network for reading a bank check is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day.\n7jzh | NOMENCLATURE\nvm00 | I. INTRODUCTION\n62qe | Over the last several years, machine learning techniques, particularly when applied to neural networks, have played an increasingly important role in the design of pattern recognition systems. In fact, it could be argued that the availability of learning techniques has been a crucial factor in the recent success of pattern recognition applications such as continuous speech recognition and handwriting recognition.\nypz9 | The main message of this paper is that better pattern recognition systems can be built by relying more on automatic learning and less on hand-designed heuristics. This is made possible by recent progress in machine learning and computer technology. Using character recognition as a case study, we show that hand-crafted feature extraction can be advantageously replaced by carefully designed learning machines that operate directly on pixel images. Using document understanding as a case study, we show that the traditional way of building recognition systems by manually integrating individually designed modules can be replaced by a unified and well-principled design paradigm, called graph transformer networks, which allows training all the modules to optimize a global performance criterion.\nmpml | Since the early days of pattern recognition it has been known that the variability and richness of natural data, be it speech, glyphs, or other types of patterns, make it almost impossible to build an accurate recognition system entirely by hand. Consequently, most pattern recognition systems are built using a combination of automatic learning techniques and hand-crafted algorithms. The usual method\nimnm | of recognizing individual patterns consists in dividing the system into two main modules shown in Figure one. The first module, called the feature extractor, transforms the input patterns so that they can be represented by low-dimensional vectors or short strings of symbols that: one) can be easily matched or compared and two) are relatively invariant with respect to transformations and distortions of the input patterns that do not change their nature. The feature extractor contains most of the prior knowledge and is rather specific to the task. It is also the focus of most of the design effort, because it is often entirely hand crafted. The classifier, on the other hand, is often general purpose and trainable. One of the main problems with this approach is that the recognition accuracy is largely determined by the ability of the designer to come up with an appropriate set of features. This turns out to be a daunting task which, unfortunately, must be redone for each new problem. A large amount of the pattern recognition literature is devoted to describing and comparing the relative merits of different feature sets for particular tasks.\n8na8 | Historically, the need for appropriate feature extractors was due to the fact that the learning techniques used by the classifiers were limited to low-dimensional spaces with easily separable classes. A combination of three factors has changed this vision over the last decade. First, the availability of low-cost machines with fast arithmetic units allows for reliance on more brute-force \"numerical\" methods than on algorithmic refinements. Second, the availability of large databases for problems with a large market and wide interest, such as handwriting recognition, has enabled designers to rely more on real data and less on hand-crafted feature extraction to build recognition systems. The third and very important factor is the availability of powerful machine learning techniques that can handle high-dimensional inputs and can generate intricate decision functions when fed with these large data sets. It can be argued that the recent progress in the accuracy of speech and handwriting recognition systems can be attributed in large part to an increased reliance on learning techniques and large training data sets. As evidence of this fact, a large proportion of modern commercial optical character recognition systems use some form of multilayer neural network trained with back propagation.\nul2a | In this study, we consider the tasks of handwritten\n4eaf | character recognition (Sections one and two) and compare the performance of several learning techniques on a benchmark data set for handwritten digit recognition (Section three). While more automatic learning is beneficial, no learning technique can succeed without a minimal amount of prior knowledge about the task. In the case of multilayer neural networks, a good way to incorporate knowledge is to tailor its architecture to the task. Convolutional neural networks, introduced in Section two, are an example of specialized neural network architectures which incorporate knowledge about the invariances of two-dimensional shapes by using local connection patterns and by imposing constraints on the weights. A comparison of several methods for isolated handwritten digit recognition is presented in Section three. To go from the recognition of individual characters to the recognition of words and sentences in documents, the idea of combining multiple modules trained to reduce the overall error is introduced in Section four. Recognizing variable-length objects such as handwritten words using multimodule systems is best done if the modules manipulate directed graphs. This leads to the concept of trainable graph transformer networks, also introduced in Section four. Section five describes the now classical method of hidden Markov models for recognizing words or other character strings. Discriminative and nondiscriminative gradient-based techniques for training a recognizer at the word level without requiring manual segmentation and labeling are presented in Section six. Section seven presents the promising space-displacement neural network approach that eliminates the need for segmentation heuristics by scanning a recognizer at all possible locations on the input. In Section eight, it is shown that trainable graph transformer networks can be formulated as multiple generalized transductions based on a general graph composition algorithm. The connections between graph transformer networks and hidden Markov models, commonly used in speech recognition, is also treated. Section nine describes a globally trained graph transformer network system for recognizing handwriting entered in a pen computer. This problem is known as \"online\" handwriting recognition since the machine must produce immediate feedback as the user writes. The core of the system is a convolutional neural network. The results clearly demonstrate the advantages of training a recognizer at the word level, rather than training it on presegmented, hand-labeled, isolated characters. Section ten describes a complete graph transformer network-based system for reading handwritten and machine-printed bank checks. The core of the system is the convolutional neural network called LeNet-five, which is described in Section two. This system is in commercial use in the National Cash Register Corporation line of check recognition systems for the banking industry. It is reading millions of checks per month in several banks across the United States.\n4b6k | A. Learning from Data\nhxiu | There are several approaches to automatic machine learning, but one of the most successful approaches, popularized in recent years by the neural network community, can be called \"numerical\" or gradient-based learning. The learning machine computes a function Yp equals F(Zp, W) where Zp is the pth input pattern, and W represents the collection of adjustable parameters in the system. In a pattern recognition setting,",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394124,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1628,
    "prompt_tokens": 3341,
    "total_tokens": 4969
  }
}