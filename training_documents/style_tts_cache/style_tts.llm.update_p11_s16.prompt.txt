You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document. Your task is to faithfully reproduce the text for our text-to-speech engine so that it is easily read aloud.

Note that the text might not start at the beginning and paragraphs may be split acrosss multiple textboxes. Textboxes may start or end in the middle of a word which is acceptable: do not combine text between textboxes and leave broken words at the start and end of a textbox unchanged.

You will receive one textbox per-line in the format `id | Textbox content`. The output must be in the format `id | Clean content`.

RULES:
 • Remove inline citations and references e.g. "(Author, 2021)" or "(https://wikipedia.org/article.html)" or "[ECMOS 35b, 47, 49]".
 • Spell out numbers, dates, and chemical formulas for the TTS engine e.g. "-2.5" -> "negative two point five" or "Jan. 2020" -> "January twenty twenty".
 • Spell out LaTeX formulas for the TTS engine e.g. "<LATEX>p = 1</LATEX>" -> "P equals one".
 • Rejoin hyphenated word fragments within the same textbox e.g. "synth -esize" -> "synthesize".
 • Fix simple typos and OCR errors e.g. "O nce upon a 1ime." -> "Once upon a time.".
 • Delete nonsequiter textboxes that interrupt the middle of a sentence if they obviously do not belong.

Otherwise, the output should exactly match the input text:
 • Do not combine text across lines or attempt to fix words broken across lines.
 • Ensure each ID from the input is included in the output.
 • Make as few changes as possible while respecting the above rules.

EXAMPLE INPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symp- toms in adults.
0fpw | 2. Materia1 and methods
dqn8 | 2.1. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at 2 and 4 weeks after initiation. The target population included adults with ADHD symptoms who had not been diag- nosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale (CAARS-S:SV). This cut-off was indicative of clinically elevated symptoms (Conners et al., 1999) (see section 2.3).
82ju | 2.2. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics (www.microdo sing.nl). Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took 20 min to complete. If the survey had not been completed after 24 h, a reminder was sent. Each of the surveys at the 2- and 4-week time points took about 15 min to complete. Par- ticipants were able to pause the surveys. Data collection occurred between Nov. 2020 and Jul. 2021. The study was approved by the Ethics Review Committee of Psy- chology and Neuroscience at Maastricht University (ERCPN- 215_05_11_2019_A1).
1piq | 2.3. Measures
7fqw | 2.3.1. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psyche- delics (i.e., ayahuasca, DMT, 5-MeO-DMT, LSD, novel lysergamides (e.g., 1P-LSD, ALD-52), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | 2.3.2. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD (Kooij et al., 2019), or because these diagnoses were reported to be common in people who microdose (Fadiman and Korb, 2019). We 
3j2l | REVIEW ARTICLE Frontiers in Psychiatry | www.frontiersin.org
03k3 | 2
1k9e | constructed a variable Comorbidity alongside ADHD, differenti- ating respondents with and without a comorbid diagnosis alongside ADHD (<LATEX>p < . 0 0 1 =</LATEX> only ADHD or no ADHD diagnosis; <LATEX>p > . 0 1 =</LATEX> ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conven- tiona1 ADHD medication alongside microdosing (<LATEX>0 =</LATEX> only microdosing; <LATEX>1 =</LATEX> conven-
```

EXAMPLE OUTPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symptoms in adults.
0fpw | Two. Material and methods
dqn8 | Two point one. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at two and four weeks after initiation. The target population included adults with ADHD symptoms who had not been diagnosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale. This cut-off was indicative of clinically elevated symptoms (see section two point three).
82ju | Two point two. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics. Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took twenty minutes to complete. If the survey had not been completed after twenty-four hours, a reminder was sent. Each of the surveys at the two and four-week time points took about fifteen minutes to complete. Participants were able to pause the surveys. Data collection occurred between November twenty twenty and July twenty twenty-one. The study was approved by the Ethics Review Committee of Psychology and Neuroscience at Maastricht University.
1piq | Two point three. Measures
7fqw | Two point three point one. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psychedelics (i.e., ayahuasca, DMT, five-MeO-DMT, LSD, novel lysergamides (e.g., one-P-LSD, ALD-fifty-two), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | Two point three point two. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD, or because these diagnoses were reported to be common in people who microdose. We
3j2l |
03k3 |
1k9e | constructed a variable Comorbidity alongside ADHD, differentiating respondents with and without a comorbid diagnosis alongside ADHD (P is less than point zero zero one equals only ADHD or no ADHD diagnosis; P is greater than point zero one equals ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conventional ADHD medication alongside microdosing (zero equals only microdosing; one equals conven-
```

INPUT:
```
o7qm | = htext . Wtext + S . Wstyle
d52l | = htext . Wtext + Concat (htext, s)
qlbb | where Wtext and Wstyle are block matrix notation of the corresponding weights for hstyle and s and Concat (htext, S) = s . Wstyle denotes the concatenation operation as a function of input htext and style vector s. This Concat (x, s) function is almost like AdaIN in equation 1 where Lu(s) = Wstyle except we do not have the temporal modulation term La(s). The modulation term is very important in style transfer, and some works argue that modulation alone is enough for diverse style representations [24], [67]. In contrast, concatenation only provides the addition term (Lu) but no modulation term (La). Intuitively, the modulation term can determine the variance of the pitch and energy, for example, and therefore without such a term, correlations for pitch and energy standard deviation are much lower than AdaIN and AdaLN as shown in Table VIII.
nhsg | AdaLN vs. AdaIN. Generative models for speech synthesis learn to generate mel-spectrograms, which is essentially a 1- D feature map with 80 channels. Each channel in the mel- spectrogram represents a single frequency range. When we apply AdaIN, we learn a distribution with a style-specific mean and variance for each channel, compared to AdaLN, where a single mean and variance are learned for the entire feature map. This inherent difference between feature distributions makes AdaIN more expressive in terms of style reflection than AdaLN.
hy0l | C. Pitch Extractor
4jmz | Acoustic methods for pitch estimation sometimes fail because of the presence of non-stationary speech intervals and sensitivity of hyper-parameters as discussed in the original papers that propose these methods [39], [41]. A neural network trained with ground truth from these methods, however, can leverage the problems of failed pitch estimation because the failed pitch estimation can be regarded as noises in the training set, so it does not affect the generalization of the pitch extractor network. Moreover, since the pitch extractor is fine-tuned along with the decoder, there is no ground truth for the pitch beside the sole objective that the decoder needs to use extracted pitch information to reconstruct the speech. This fine-tuning allows better pitch representations beyond the original F0 in Hertz, but it also allows flexible pitch control as we can still recognize the pitch curves and edit them later when needed during inference.
b7cq | In the multi-speaker experiments, we used pre-trained Fast- speech212 , VITS 13 , and HiFiGAN 14 from ESPnet. We used pre-trained VITS from ESPnet instead of the official repository because we need the model to be trained on the LibriTTS dataset; however, the official models were trained on the LJSpeech or VCTK dataset.
0b39 | Similar to the single-talker experiment, we launched 5 batches 15 on AMT when we tested the multi-talker models on the LibriTTS dataset. 48 out of 58 subjects were qualified. We launched 3 batches 16 with batch sizes 33, 33, 34, respectively, when we tested the multi-talker models on the VCTK dataset. 28 out of 30 subjects were qualified.
qecd | Since our text encoder, text aligner, pitch extractor, and de- coder are trained in a speaker-agnostic manner, our decoder can reconstruct speech from any aligned phonemes, pitch, energy, and reference speakers. Therefore, our model can perform any- to-any voice conversion by extracting the alignment, pitch, and energy from an input mel-spectrogram and generating speech using a style vector of reference audio from an arbitrary target speaker. Our voice conversion scheme is transcription-guided, similar to Mellotron [10] and Cotatron [66]. We provide one example in Figure 6 with both source and target speaker unseen from the LJSpeech and VCTK datasets. We refer our readers to our demo page for more examples.
1o7p | In this section, we provide detailed model architectures of StyleTTS, which consists of eight modules. Since we use the same text encoder as in Tacorton 2 [51], very similar architecture to the decoder of Tacotron 2 for text aligner and the
cp13 | same architecture as the JDC network [40] for pitch extractor, we leave the readers to the above references for detailed descriptions of these modules. Here, we only provide detailed architectures for the other five modules. All activation functions used are leaky ReLU (LReLU) with a negative slope of 0.2. We apply spectral normalization [68] to all trainable parameters in style encoder and discriminator and weight normalization [69] to those in decoder because they are shown to be beneficial for adversarial training.
bgre | Decoder (Table IX). Our decoder takes four inputs: the aligned phoneme representation, the pitch F0, the energy, and the style code. It consists of seven 1-D residual blocks (ResBlk) along with three sub-modules for processing the input F0, energy, and residual of the phoneme representation. The normalization consists of both instance normalization (IN) and adaptive instance normalization (AdaIN). We concatenate (Concat) the processed F0, energy, and residual of phonemes with the output from each residual block as the input to the next block for the first three blocks.
57lp | Style Encoder and Discriminator (Table <LATEX>\left. X \right) .</LATEX> Our style encoder and discriminator share the same architecture, which consists of four 2-D residual blocks (ResBlk). The dimension of the style vector is set to 128. We use learned weights for pooling through a dilated convolution (Dilated Conv) layer with a kernel size of <LATEX>3 \times 3 .</LATEX> We apply an adaptive average pooling (AdaAvg) along the time axis of the feature map to make the output independent of the size of the input mel-spectrogram.
ukth | Duration and Prosody Predictors (Table XI). The duration predictor and prosody predictors are trained together in the second stage of training. There is a shared 3-layer bidirectional LSTM (bi-LSTM) <LATEX>s</LATEX> between the duration predictor and prosody predictor named text feature encoder, each followed by an adaptive layer normalization (AdaLN). AdaLN is similar to AdaIN where the gain and bias are predicted from the style vector s. However, unlike AdaIN which normalizes each channel independently, AdaLN normalizes the entire feature map. The style vector <LATEX>s</LATEX> is also concatenated (Concat) with the output to every token from each LSTM layer as the input
kpvt | to the next LSTM layer. Lastly, we have a final bidirectional LSTM and a linear projection L that maps hprosody into the predicted duration.
jie2 | The hidden representation hprosody is dotted with the alignment dalign and sent to the prosody decoder. The prosody encoder consists of one bidirectional LSTM and two sets of three residual blocks (ResBlk) with AdaIN followed by a linear projection, one for predicting the F0 and another for predicting the energy, respectively.
```

OUTPUT:
```
