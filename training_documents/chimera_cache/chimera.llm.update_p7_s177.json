{
  "id": "chatcmpl-A3UD976gRJL4yYslucrEcnGl5P2Y0",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "8p6h | left parenthesis D minus D over two f plus one right parenthesis M sub a comma left parenthesis D times M sub a right parenthesis For any f in F, Chimera can scale to more micro-batches (i.e., N greater than D) using the methods discussed in Section three point five. For a given f, Chimera incurs two times D over f over two minus one bubbles, but has to maintain two f model replicas and synchronize the gradients of two f stages on each worker.\npmgl | The larger the value of f, the less bubbles (and the more balanced activations memory consumption), but also the higher gradient synchronization overhead and weights memory consumption. When f equals Q, Chimera degrades to pure data parallelism. Empirical results in Section four point four show that f greater than one rarely brings more performance benefit on the models used for evaluation. Thus, f equals one (i.e., a combination of two pipelines) is the default setting for Chimera in this paper, unless otherwise stated. We expect that f greater than one, whose features are summarized in Table three, would further improve the performance for future deep models with deeper pipeline.\n90no | Four EXPERIMENTAL EVALUATION\njt0y | We conduct our experiments mainly on the CSCS Piz Daint supercomputer. Each Cray XC fifty compute node contains an Intel Xeon E five twenty-six ninety CPU, and one NVIDIA P one hundred GPU with sixteen gigabytes global memory. The compute nodes of Piz Daint are connected by Cray Aries interconnect network in a Dragonfly topology.\nqb7o | We also evaluate the performance on a small cluster equipped with thirty-two NVIDIA V one hundred GPUs. The cluster has four GPU servers connected by Infiniband, and each server has eight V one hundred GPUS with NVLink. Each V one hundred GPU has thirty-two gigabytes global memory.\noae5 | We evaluate the performance of the schemes listed in Table two, which covers the state-of-the-art. For a fair comparison, all schemes are implemented in PyTorch with GLOO distributed backend for both the point-to-point p two p communication between pipeline stages and gradient synchronization (allreduce) across the stage replicas, and GPU devices are utilized for acceleration. Although NCCL backend of PyTorch performs better for allreduce \ns0fl | greater than five hundred twelve across GPU nodes (with GPUDirect RDMA), it does not support p two p communication. Using NCCL for gradient synchronization and GLOO for p two p at the same time fails, which is also observed in PipeDream. We use the language models summarized in Table four for evaluation, and the max sequence length of Bert minus forty-eight and GPT two are set to one hundred twenty-eight and six hundred thirty-two respectively, unless otherwise stated. The mini-batch size and sequence length we use are consistent with those in the machine learning community. Since Chimera is a synchronous approach without compromising convergence accuracy, we focus on the training throughput comparison.\n43ia | Four point one Memory Consumption\n3g2y | Four point two Parallel Scalability\ngc7v | We first find the best configuration for each approach, and compare their best performance in the test of weak scaling.\nwqfv | Four point two point one Performance Optimization Space for the Baselines. Given the mini-batch size B and the number of workers P, the best configuration of B (micro-batch size), D (pipeline stages), and W (the number of replicated pipelines) is not obvious a priori because of the trade-offs (i.e., computational efficiency and bubbles, allreduce and p two p communication overhead). We search the space of the parameters (W, D, and B (for power-of-two)) to find the best performance for each baseline. The results for Bert forty-eight on thirty-two GPU nodes are presented in Figure ten.\nj30a | For synchronous baselines (such as GPipe and DAPPLE), the value of B affects both computational efficiency and the bubble ratio. The planner of DAPPLE gives an answer for how to select the configuration of W and D based on the profiling information, but it is not clear for how to select the best B. From Figure ten we can see the highest throughput of both DAPPLE and GPipe (with activation recomputation) is achieved by (W equals eight, D equals four, B equals four), under which they hit the sweet spot for the trade-off between p two p communication overhead and allreduce communication overhead by (W equals eight, D equals four), and the sweet spot for the trade-off between bubble ratio and computational efficiency by B equals four (and N equals sixteen). GEMS prefers a large B for high computational efficiency since a smaller B does not help a lot to reduce the bubble ratio, and therefore its best performance is achieved by (W equals eight, D equals four, B equals thirty-two).\n7bdk | Asynchronous baselines (PipeDream-two BW and PipeDream) always prefer the maximum B fitting in the device memory, since there is no bubble problem for them. Note that PipeDream conducts gradient synchronization across W pipelines after each backward pass on a micro-batch, thus its B is limited by the maximum B. Since the frequent gradient synchronization of PipeDream leads to high allreduce overhead, its best performance is achieved with a deeper pipeline than others, namely by (W equals four, D equals eight, B equals forty-eight). PipeDream-two BW scales to large B by accumulating the gradients for more than D micro-batches (i.e., N greater than or equal to D), and its best performance is achieved by (W equals eight, D equals four, B equals sixteen) with activation recomputation.\nfim0 | For GPT two, we present the performance tuning for each baseline by searching the parameter space in Figure eleven.\nojro | Four point two point two Performance Modelling of Chimera. We first evaluate the performance of Chimera with different gradient synchronization strategies discussed in Section three point two. We use eager-sync to denote\nl6t9 | eager synchronization also conducted for the middle stages, and eager-sync-opt to denote eager synchronization not conducted for the middle stages. Results in Figure twelve show that eager-sync-opt achieves higher (e.g., one point zero nine times on sixty-four nodes) throughput than eager-sync. These empirical results support our claim in Section three point two.",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394479,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1309,
    "prompt_tokens": 3198,
    "total_tokens": 4507
  }
}