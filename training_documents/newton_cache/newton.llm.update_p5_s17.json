{
  "id": "chatcmpl-A3UEK9kmZJBLfSnkQR6j9ZBbWFYoN",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "53tr | <LATEX>\\mathcal{A} \\left( x _ { k } , \\delta _ { k } \\right) \\text { and } \\mathcal{I} \\left( x _ { k } , \\delta _ { k } \\right) \\text { as in } \\left( 2 \\right) .</LATEX> Four: if (seven) is satisfied then\n3zd1 | Five: Terminate.\n3shq | <LATEX>\\mathrm { p } _ { k } : \\left\\{ \\begin{array}{} \\mathrm { p } _ { k } ^ { \\mathcal{A} } \\leftarrow - \\mathrm { g } _ { k } ^ { \\mathcal{M} } , \\\\ \\\\ \\left( \\mathrm { p } _ { k } ^ { \\mathcal{I} } , \\mathrm { D } _ { \\mathrm { t y p e } } \\right) \\leftarrow \\mathrm { M I N R E S } \\left( \\mathrm { H } _ { k } ^ { \\mathcal{I} } , \\mathrm { g } _ { k } ^ { \\mathcal{I} } , \\eta , \\bar { \\varsigma } \\right) \\end{array} \\right.</LATEX> Eight: if <LATEX>\\mathrm { D } _ { \\mathrm { t y p e } } = \\mathrm { S O I }</LATEX> then\nr3r5 | <LATEX>\\alpha _ { k } \\leftarrow \\text { Algorithm } Five \\text { with } \\alpha _ { 0 } = One \\text { and } \\left( 1 1 \\right) .</LATEX> Ten: else if <LATEX>\\mathrm { D } _ { \\mathrm { t y p e } } = \\mathrm { N P C }</LATEX> then\npgo2 | <LATEX>\\alpha _ { k } \\leftarrow \\mathrm { A l g o r i t h m } Six \\mathrm { w i t h } \\alpha _ { 0 } = One \\mathrm { a n d } \\left( 1 1 \\right) .</LATEX> Twelve: end if\nv6zz | Thirteen:\n7zt5 | <LATEX>\\mathrm { x } _ { k + One } = \\mathcal{P} \\left( \\mathrm { x } _ { k } + \\alpha _ { k } \\mathrm { p } _ { k } \\right)</LATEX> Fourteen: end for\n77ir | In Liu & Roosta, it was shown that when MINRES algorithm the returns an NPC step, the line search for <LATEX>\\alpha</LATEX> could run in a forward tracking mode (cf. Algorithm Six). In numerical experiments, it was demonstrated that the forward tracking line search was beneficial because it allowed for very large steps to be taken, particularly in flat regions where progress would otherwise be slow. Our theoretical analysis in Appendix B demonstrates that a forward tracking line search can also be used in Algorithm One for NPC type steps.\nwbov | To analyse the global complexity of Algorithm One, we only require typical assumptions on Lipschitz continuity of the gradient and lower-boundedness of the objective.\n4bll | Assumption Three point One. There exists <LATEX>Zero \\leq L _ { g } < \\infty</LATEX> such that for all <LATEX>x ,</LATEX> <LATEX>\\mathrm { y } \\in \\mathbb{R} _ { + } ^ { d } ,</LATEX> <LATEX>\\| \\mathrm { g } \\left( \\mathrm { x } \\right) - \\mathrm { g } \\left( \\mathrm { y } \\right) \\| \\leq L _ { g } \\| \\mathrm { x } - \\mathrm { y } \\| .</LATEX> Assumption Three point Two. We have\nfl9r | <LATEX>- \\infty < f _ { * } \\leq f \\left( \\mathrm { x } \\right) ,</LATEX> <LATEX>\\forall \\mathrm { x } \\in \\mathbb{R} _ { + } ^ { d } .</LATEX> With these minimal assumptions we can provide a guarantee of convergence of Algorithm One in Theorem Three point Three, the proof of which we deferred to Appendix B.\nc297 | Theorem Three point Three (Global Complexity of Algorithm One). Let <LATEX>\\epsilon _ { g } \\in \\left( Zero , One \\right)</LATEX> and <LATEX>\\varsigma > Zero .</LATEX> Under Assumptions Three point One and Three point Two, if we choose <LATEX>\\delta _ { k } = \\epsilon _ { k } = \\epsilon _ { g } ^ { One half }</LATEX> and <LATEX>\\bar { \\varsigma } = \\left( d + One \\right) \\varsigma ,</LATEX> Algorithm One produces an <LATEX>\\epsilon _ { g } - F O</LATEX> point in at most <LATEX>\\mathcal{O} \\left( \\epsilon _ { g } ^ { - Two } \\right)</LATEX> iterations.\nvo3u | Remark Three point Four. The \"big-O\" rate obtained in Theorem Three point Three hides a dependence on the problem constants and algorithm parameters <LATEX>\\rho ,</LATEX> <LATEX>\\varsigma</LATEX> s, <LATEX>L _ { g } ,</LATEX> <LATEX>\\eta ,</LATEX> which are, in particular, independent of d. However, the proof of Theorem Three point Three (and, indeed, Theorem Three point Eight) implies that the worst case constant hidden by the\ngxrz | Inexact Newton-type Methods for Optimisation with Nonnegativity Constraints\nhkkk | big-O notation could have an unfortunate dependence on the problem constants (e.g., <LATEX>L _ { g } ^ { Three } .</LATEX> This could suggest poor practical performance despite the desirable dependence on <LATEX>\\epsilon _ { g } .</LATEX> However, as we show numerically in Section Four, such worst case analyses are rarely indicative of typical performance in practice.\nzmxa | Three point Three. Global Convergence: Improved Rate",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394552,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1373,
    "prompt_tokens": 3098,
    "total_tokens": 4471
  }
}