You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document.

Your task is to label each textbox with exactly one of the following labels:
  title: the primary document title, no more than one per document
  heading: the name of the following chapter or section (should never start in the middle of the previous paragraph)
  subheading: a secondary heading, often following another heading (should never start in the middle of the previous paragraph)
  body: main paragraph content: may start or end in the middle of a word, use context to follow paragraphs that are split across textboxes (if a textbox contains both heading and body text, label it "body")
  math: textbox primarily containing math
  imageDescription: standalone callout that only describes an image, chart, table, or similar (typically begins with "Table...", "Figure...", "Fig. ...", "Above...", "Left...", etc.)
  authors: names of contributors to this document
  institutions: list of universities, business, and other institutions affiliated with this document
  publisher: info about the publisher, or provided by the publisher, including copyright info
  pagenum: the page number
  headerOrFooter: boilerplate text page number, or redundant headings at the top/bottom of the page
  toc: the table of contents
  references: bibliographic references and resources
  acknowledgements: thanks and credits to contributors
  appendix: index, appendix, or any other end matter not part of the main thread (including related headings)
  table: tabular data, label, title, or subheading for a grid or list of data
  datum: numeric data or data label from a chart or list
  advertisement: promotional ads and marketing
  layout: non-content related to the layout of the page, e.g. sidebar navigation
  callout: pull quote or long block text that stands apart from the main text
  footnote: footnotes and endnotes near the bottom of the page
  keywords: list of keywords or tags
  url: web address or email
  other: any other text that does not belong to the main thread

Each line of input is prefixed with a textbox ID in the format `id | Text content`. The output must be in the format `id | label`.

Note that body text may be split across multiple textboxes, and textboxes may start or end in the middle of a sentence or word. Because the text was extracted from a web page or document, paragraphs of body text may be interrupted by multiple textboxes of redundant headers, footnotes, page numbers, tables, images, etc. For example, a real heading will never interrupt the middle of a sentence. Use context clues like this to carefully label each textbox.

EXAMPLE INPUT:
```
1pjs | Neuroscience Applied 1 (2022) 101012
o2kr | Contents lists available at ScienceDirect
v6sk | Neuroscience Applied
1wj6 | journal homepage: www.journals.elsevier.com/neuroscience-applied
936l | Research Articles
06yq | Microdosing with psychedelics to self-medicate for ADHD symptoms in adults: A naturalistic study
dpv6 | ARTICLE INFO
8r5j | ABSTRACT
2taz | Keywords: ADHD Microdosing Psychedelics Self-medication Well-being Time perception
o3ya | ADHD in adulthood is often overlooked, which negatively affects the individual's well-being. First-line phar- macological interventions are effective in many ADHD patients, relieving symptoms rapidly. However, there seems to be a proportion of individuals who discontinue, or fail to respond to these treatments. For these in- dividuals, alternative treatment options should be explored.
r5il | 1. Introduction
5gui | Attention deficit hyperactivity disorder (ADHD) is one of the most common developmental disorders worldwide. Prevalence research indicates that 2.6% of the adult population has persistent ADHD. ADHD in adults is often overlooked because of the high comorbidity rate and lack of knowledge about how ADHD is expressed in adulthood (Kooij et al.,
9d4o | Fig. 1. Flowchart of included participants for each time point.
82qc | 2019). In addition, ADHD is associated with deficits in various domains of cogni- tive functioning. Twenty-five percent of ADHD cases suffered from ADHD symptoms purely because of de- ficiencies in temporal processing (Sonuga-Barke et al., 2010).
ls7d | First-line ADHD treatments in adults mainly include pharmacological interventions to enhance dopaminergic and noradrenergic neurotrans- mission with stimulants. Overall, they have been proven to work effectively in adults with ADHD, inducing fast symptom relief and thereby enhancing the person's quality of life. In the
5esx | Table 1 Demographic information from respondents at baseline and the two and four- week time points.
t8vv | longer term, approximately twenty percent of ADHD patients discontinue their prescribed medication after six to nine months, thirty percent after one year, and half of them after two years.
xrd1 | 2. Material and methods
5746 | 2.1. Study design and participants
7toz | The study employed a naturalistic design, assessing the experiences of participants at baseline,
j346 | Neuroscience Applied 1 (2022)
m5ka | E.C.H.M. Haijen et al.
kx2c | REVIEW
v8uq | before they start MD on their own initiative, and at two and four weeks after MD initiation. The target population included adults diagnosed with ADHD and individuals who experienced ADHD symptoms to the extent that these interfered with their daily lives and who had not been diag- nosed with ADHD before. To be included in the analyses, participants needed to score above a cut-off point on at least one of the subscales of the Conner's Adult ADHD Rating Scale (CAARS-S:SV).
2zmw | Fig. 2. Mean scores of the CAARS-S:SV DSM-IV total symptoms T-scores at baseline (0W) and two (2W) and four weeks (4W) after MD (A) of the whole sample, and (B) per conventional ADHD medication use. Error bars represent mean error.
sdk3 | <LATEX>\lim _ { x ightarrow \infty } rac { 6 x ^ { 2 } + 1 0 0 } { 7 x ^ { 2 } - 1 0 } =</LATEX>
x972 | 2.2. Study procedure
k221 | Mean performance measures of the CAARS-
```

EXAMPLE OUTPUT:
```
1pjs | headerOrFooter
o2kr | publisher
v6sk | publisher
1wj6 | publisher
936l | headerOrFooter
06yq | title
dpv6 | other
8r5j | heading
2taz | keywords
o3ya | body
r5il | heading
5gui | body
9d4o | imageDescription
82qc | body
ls7d | body
5esx | imageDescription
t8vv | body
xrd1 | heading
5746 | subheading
7toz | body
j346 | headerOrFooter
m5ka | authors
kx2c | headerOrFooter
v8uq | body
2zmw | imageDescription
sdk3 | math
x972 | heading
k221 | body
```

INPUT:
```
wcd0 | A more interpretable metric for fit is Mean Absolute Deviance (MAD) -- the average of the absolute values of the differences between observed values and predicted values. We do not use it as a heuristic because it leads to over fitting. <LATEX>\mathrm { W } e</LATEX> include it as a measure of the improvement in the model fit.
caos | Figure 4 illustrates <LATEX>A ^ { * }</LATEX> search with AIC as the heuristic. The original model is evaluated and <LATEX>\mathrm { A I C }</LATEX> is computed. The model is then split into a few new models by incorporating the factors. AICs are computed from each of the new model. A* selects the best one (the shaded node with value 5301) for the next model generation. <LATEX>A ^ { * }</LATEX> does not always go down. It may go up to select a model (the shaded node with value 5312) to expand if all the new models have worse heuristic scores than a previous model has. After several expansions, it finds a best node with the lowest AIC value.
qrvy | 170
pn9j | H. Cen, K. Koedinger, and B. Junker
1pmc | Fig. 3. Using A* algorithm search through the model space
5z6q | 5 Experiments and Results
yeoh | 5.1 Experiment 1
b8hf | This experiment addresses the question -- How can we describe learning behavior in terms of an existing cognitive model? Specifically, we want to find out the learning rate and initial difficulty level of each rule, and the initial performance of students, given the data. The question is answered by fitting the logistic regression model in equation 2 and getting the coefficients. The coefficient estimates for the skills and students, and the overall model statistics are summarized in table 4.
hntf | Table 4. Statistics for a partial list of the skills, students and the overall model. Intercept for skill is the initial difficulty level for each skill. Slope is the learning rate. Avg Practice Opportunties is the average amount of practice per skill across all students. Initial Probabltiy is the estimated probability of getting a problem correct in the first opportunity to use a skill accross all students. Avg Probability and Final Probability are the success probability to use a skill at the average amount of opportunities and the last opportunity, respectively.
99fo | The higher the intercept of the each skill, the lower the initial difficulty the skill has. The higher the slope of the each skill, the faster students learned the skill. Pentagon-area is the hardest skill with the intercept of -2.16. Parallelogram-area is the easiest skill with the intercept of 2.14. Three skills have small slopes close to
y5r7 | Learning Factors Analysis - A General Method for Cognitive Model Evaluation
lrry | 171
hvhm | zero -- Compose-by-addition ( -. 04) and Parallelogram-area ( -. 01), Triangle-area (.03). Parallelogram-area was already mastered with an initial success probability .95. It appears that more practice on those skills does not lead to much learning gain. Interestingly, although PENTAGON-AREA is the hardest skill among all, it has the highest learning rate .45, leading to bigger improvement with more practice.
863b | The coefficients for students measure each student's overall performance. The higher the number, the better the student performed. The AIC, BIC and MAD statistics provide a baseline for evaluating alternative models discussed below.
fj24 | 5.2 Experiment 2
uz3c | This experiment addresses the question -- How can we improve a cognitive model? The question is answered by running LFA on the data including the factors, and searching through the model space. The improved models by LFA with BIC are summarized in table 5. The improved models by LFA with AIC is summarized in the interpretation.
d5bi | Table 5. Top three improved models found by LFA with BIC as the heuristic. The table shows the history of splits and model statistics.
ba4l | LFA suggests better models, which make finer distinctions on some skills in the original model and identify which difficulty factors the subject experts thought would turn out to be psychologically important. All the better models found by AIC and BIC have better (i.e. lower) statistical scores than those of the original. For the best BIC model, its BIC is reduced by 37, and AIC by 62. The fit of the new model, as measured by MAD, is reduced by .012. The best AIC model reduces AIC by an even larger amount of 83, and increases BIC by 18. Its MAD is reduced by .02.
ffx8 | The improved skills common to most of the better models are Compose-by- multiplication, Compose-by-addition, Circle-area, and Triangle-area. We will discuss a few examples here.
s6su | All the new models suggest splitting Compose-by-multiplication into two skills - Cmarea and CMsegment, making a distinction of the geometric quantity being
y219 | H. Cen, K. Koedinger, and B. Junker
06ht | 172
v3r2 | multiplied. By examining the positions of these problems in the curriculum, CMarea at the 43rd step and CMsegement at the 90th. As seen in table 6, although the final probability of CMarea is high .96, the initial probability of CMsegment is low .32. This sudden drop in the success probability at later steps corresponds to a significant blip in the learning curve as illustrated in figure 2. The distinction between different geometric quantities suggests treating the original skill differently. LFA successfully identified the blip without the need of visually inspecting learning curves.
nv42 | Table 6. Success probabilities of CMarea and CMsegment
xags | The subject experts thought embedding a shape into another shape would increase the difficulty of a skill and identified a factor "Embed", hoping LFA could make a distinction on it. LFA split these two skills by Embed in all the top AIC models. The three probabilities of CAalone and CAembed are shown in table 7. Does Embed make find the circle area harder? Note that problems with CAembed are introduced later in the curriculum after students have had significant practice with CAalone, about the time CAalone has reached the average probability of .81. At this point, CAembed has an initial probability of .71, indicating an increase in difficulty.
jc47 | Table 7. Success probabilities of CAalone and CAembed
ko3c | 5.3 Experiment 3
xek3 | In experiment 2, LFA improved the original model by splitting skills. Experiment 3 addresses model improvement even further -- Will some skills be better merged than if they are separate skills? Can LFA recover some elements of truth if we search from a merged model, given difficulty factors?
bbpr | We merged some skills in the original model to remove some of the distinctions, which are represented as the difficulty factors. Circle-area and Circle-radius are merged into one skill Circle; Circle-circumference and Circle-diameter into Circle- CD; Parallelogram-area and Parallelogram-side into Parallelogram; Pentagon-area, and Pentagon-side into Pentagon; Trapezoid-area, Trapezoid-base, Trapezoid-height into Trapezoid. The new merged model has 8 skills -- Circle, Crcle-CD, Compose-by- addition, Compose-by-multiplication, Parallelogram, Pentagon, Trapezoid, Triangle.
5zyf | Then we substituted the original skill names with the new skill name in the data, ran LFA including the factors, and had the A* algorithm search through the model space. The improved models by LFA with BIC are summarized in table 8. The improved models by LFA with AIC are summarized in the interpretation.
9own | Learning Factors Analysis - A General Method for Cognitive Model Evaluation
bqfb | 173
wwdt | Table 8. Top three improved models found by LFA with BIC as the heuristic
mn1r | LFA fully recovered three skills (Circle, Parallelogram, Triangle), suggesting the distinctions made in the original model are necessary. LFA partially recovered two skills (Triangle, Trapezoid), suggesting the some original distinctions are necessary and some are not. LFA did not recover one skill (Circle-CD), suggesting that the original distinctions might not be necessary. LFA recovered one skill (Pentagon) in a different way, suggesting the original distinction may not be as significant as the distinction caused by another factor. We discuss a few examples here.
5vqw | In BIC model 1, Circle is split into Circle*area, and Circle*radius. The other two BIC models and all the AIC models split it into Circle*backward, and Circle*forward, which are equivalent to Circle-AR *area, and Circle-AR*radius because of the one-to- one relationship between forward and area and between backward and radius. Thus, LFA fully recovers the Circle skills.
meyw | None of the models recovered Circle-CD. This suggests that it may not be necessary to have two separate skills for Circle-circumference and Circle-Diameter. It appears that once students learn the formula circumference = n*diameter, they can fairly easily apply it in the forward or backward direction.
2e62 | In one of the top AIC models, Pentagon is split into Pentagon*initial and Pentagon*repeat, instead of Pentagon*area and Pentagon*side. This suggests that the distinction between the first use of a Pentagon skill in a problem and later uses of that skill in the same problem may be more significant than the distinction between the area and the side. Usually repeated use of a skill in the same problem is easier than the original use. For instance, once a student makes the initial relatively difficult determination that the Pentagon formula is relevant to a problem and recalls it, he need only use it again and perform easier arithmetic in repeated opportunities in that same problem.
75y3 | 174
s2g2 | H. Cen, K. Koedinger, and B. Junker
q1q2 | 5.4 Combining the Results from Experiment 1, 2, 3
cb7r | By combining the results from the three experiments, we can address question 3 -- How can we use LFA to improve the tutor and the curriculum by identifying over- taught or under-taught rules, and adjusting their contribution to curriculum length without compromising student performance?
68xu | Parallelogram-side has a high intercept (2.06) and a low slope ( -. 01). Its initial success probability is .94 and the average number of practices per student is 14.9. Much practice spent on an easy skill is not a good use of student time. Reducing the amount of practice for this skill should save student time without compromising their performance. Trapezoid-height has a low intercept (-1.55), and a positive slope (.27). Its initial success probability is .29 and the average number of practices per student is 4.2. The final success probability is .69, far away from the level of mastery. More practice on this skill is needed for students to reach mastery.
hd35 | The advantage of LFA goes even further. An original rule may have two split rules, each of which need decidedly different amounts of practice, because they have different initial difficulty and learning rates. However, students who have appeared to master the original rule in the curriculum before even reading the second split rule might not get enough practice on the second split rule. Compose-by-multiplication is such a case, as seen in table 9.
2zpk | With final probability .92 students seem to have mastered Compose-by- multimplication. However, the decomposition of the skill shows a different picture. CMarea does well with final probability .96. But CMsegment has final probability only .60 and an average amount of practice less than 2. The knowledge-tracing algorithm in the tutor may let the student go after he reaches the mastery on Compose-by-addition in the original model. But with the model found by LFA, the knowledge-tracing algorithm will be able to catch the weakness of students in acquiring CMsegment.
epu7 | 6 Conclusions and Future Work
7od1 | Learning Factors Analysis is a way to combine statistics, human expertise and combinatorial search to evaluate and improve a cognitive model. The system we have developed is implemented in Java and is able to evaluate a model in seconds and conduct a search evaluating hundreds of models in 4-5 hours. The statistics for each model are meaningful, and the new improved models have better statistical scores and are interpretable. We are planning to use the method for datasets from other tutors to discover its potential for model and tutor improvement.
0bqy | Learning Factors Analysis - A General Method for Cognitive Model Evaluation
b780 | 175
ccmb | Acknowledgements
ma93 | References
```

OUTPUT:
```
