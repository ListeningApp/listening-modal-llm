You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document. Your task is to faithfully reproduce the text for our text-to-speech engine so that it is easily read aloud.

Note that the text might not start at the beginning and paragraphs may be split acrosss multiple textboxes. Textboxes may start or end in the middle of a word which is acceptable: do not combine text between textboxes and leave broken words at the start and end of a textbox unchanged.

You will receive one textbox per-line in the format `id | Textbox content`. The output must be in the format `id | Clean content`.

RULES:
 • Remove inline citations and references e.g. "(Author, 2021)" or "(https://wikipedia.org/article.html)" or "[ECMOS 35b, 47, 49]".
 • Spell out numbers, dates, and chemical formulas for the TTS engine e.g. "-2.5" -> "negative two point five" or "Jan. 2020" -> "January twenty twenty".
 • Spell out LaTeX formulas for the TTS engine e.g. "<LATEX>p = 1</LATEX>" -> "P equals one".
 • Rejoin hyphenated word fragments within the same textbox e.g. "synth -esize" -> "synthesize".
 • Fix simple typos and OCR errors e.g. "O nce upon a 1ime." -> "Once upon a time.".
 • Delete nonsequiter textboxes that interrupt the middle of a sentence if they obviously do not belong.

Otherwise, the output should exactly match the input text:
 • Do not combine text across lines or attempt to fix words broken across lines.
 • Ensure each ID from the input is included in the output.
 • Make as few changes as possible while respecting the above rules.

EXAMPLE INPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symp- toms in adults.
0fpw | 2. Materia1 and methods
dqn8 | 2.1. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at 2 and 4 weeks after initiation. The target population included adults with ADHD symptoms who had not been diag- nosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale (CAARS-S:SV). This cut-off was indicative of clinically elevated symptoms (Conners et al., 1999) (see section 2.3).
82ju | 2.2. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics (www.microdo sing.nl). Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took 20 min to complete. If the survey had not been completed after 24 h, a reminder was sent. Each of the surveys at the 2- and 4-week time points took about 15 min to complete. Par- ticipants were able to pause the surveys. Data collection occurred between Nov. 2020 and Jul. 2021. The study was approved by the Ethics Review Committee of Psy- chology and Neuroscience at Maastricht University (ERCPN- 215_05_11_2019_A1).
1piq | 2.3. Measures
7fqw | 2.3.1. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psyche- delics (i.e., ayahuasca, DMT, 5-MeO-DMT, LSD, novel lysergamides (e.g., 1P-LSD, ALD-52), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | 2.3.2. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD (Kooij et al., 2019), or because these diagnoses were reported to be common in people who microdose (Fadiman and Korb, 2019). We 
3j2l | REVIEW ARTICLE Frontiers in Psychiatry | www.frontiersin.org
03k3 | 2
1k9e | constructed a variable Comorbidity alongside ADHD, differenti- ating respondents with and without a comorbid diagnosis alongside ADHD (<LATEX>p < . 0 0 1 =</LATEX> only ADHD or no ADHD diagnosis; <LATEX>p > . 0 1 =</LATEX> ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conven- tiona1 ADHD medication alongside microdosing (<LATEX>0 =</LATEX> only microdosing; <LATEX>1 =</LATEX> conven-
```

EXAMPLE OUTPUT:
```
ccpt | stigate the effectiveness of psychedelics for ADHD symptoms in adults.
0fpw | Two. Material and methods
dqn8 | Two point one. Study design and participants
cop0 | The study employed a naturalistic design, assessing the experiences of participants at bas-,
lhkq | eline before they start, and at two and four weeks after initiation. The target population included adults with ADHD symptoms who had not been diagnosed with ADHD before. To be included, participants needed to score on Conner's Adult ADHD Rating Scale. This cut-off was indicative of clinically elevated symptoms (see section two point three).
82ju | Two point two. Study procedure
y2qo | The online advertisement was placed on a website providing information about psychedelics. Interested participants were redirected to information explaining the study rationale and procedure. The baseline survey took twenty minutes to complete. If the survey had not been completed after twenty-four hours, a reminder was sent. Each of the surveys at the two and four-week time points took about fifteen minutes to complete. Participants were able to pause the surveys. Data collection occurred between November twenty twenty and July twenty twenty-one. The study was approved by the Ethics Review Committee of Psychology and Neuroscience at Maastricht University.
1piq | Two point three. Measures
7fqw | Two point three point one. Demographic information and history of substance use
rhaz | At baseline, demographic information was collected. History of substance use assessed experience with psychedelics (i.e., ayahuasca, DMT, five-MeO-DMT, LSD, novel lysergamides (e.g., one-P-LSD, ALD-fifty-two), psilocybin, salvia divinorum, ibogaine, and mescaline) in both full (psychedelic) doses and microdoses.
wak1 | Two point three point two. Psychiatric and physiological diagnoses
wtfz | Participants were asked whether they had a current diagnosis of a disorder. These answer options were chosen because most of the listed diagnoses are often reported to co-occur with ADHD, or because these diagnoses were reported to be common in people who microdose. We
3j2l |
03k3 |
1k9e | constructed a variable Comorbidity alongside ADHD, differentiating respondents with and without a comorbid diagnosis alongside ADHD (P is less than point zero zero one equals only ADHD or no ADHD diagnosis; P is greater than point zero one equals ADHD and at least one other diagnosis). We constructed a variable Medication use alongside microdosing, differentiating respondents who were and were not using conventional ADHD medication alongside microdosing (zero equals only microdosing; one equals conven-
```

INPUT:
```
j0m4 | The principle of maximum entropy is widely used outside physics, though still con- troversial. But I think we should use it to figure out some basic properties of a gas-like its energy or entropy per molecule, as a function of pressure and temperature.
sc0s | To do this, we should generalize Shannon entropy to 'Gibbs entropy', replacing the sum by an integral. Or else we should 'discretize' the gas, assuming each molecule has a finite set of states. It sort of depends on whether you prefer calculus or programming. Either approach is okay if we study our gas using classical statistical mechanics.
pnsc | Quantum statistical mechanics gives a more accurate answer. It uses a more general
p1qs | definition of entropy-but the principle of maximum entropy still applies!
k5kg | I won't dive into any calculations just yet. Before doing a gas, we should do some simpler examples-like the die whose average roll is 5. But I can't resisting mentioning one philosophical point. In the box above I was hinting that maximum entropy works when your 'prior' is uniform:
e002 | Suppose there are n possible outcomes. At first you have no reason to think any is more probable than any other.
9klo | This is an important assumption: when it's not true, the principle of maximum entropy as we've stated it does not apply. But what if our set of events is something like a line? There's no obvious best probability measure on the line! And even good old Lebesgue measure dx depends on our choice of coordinates. To handle this, we need a generalization of the principle of maximum entropy, called the principle of maximum relative entropy.
pbpw | In short, a deeper treatment of the principle of maximum entropy pays more atten- tion to our choice of 'prior': what we believe before we learn new facts. And it brings in the concept of 'relative entropy': entropy relative to that prior. But we won't get into this here, because we will always be using a very bland prior, like assuming that each of finitely many outcomes is equally likely.
6tr9 | ADMITTING YOUR IGNORANCE
06s5 | Suppose you describe your knowledge of a system with n states using a probability distribution p1, . . . , Pn. Then the Shannon information
f3g2 | H = - pi log pi i=1 measures your ignorance of the system's state.
zlrt | So, choosing the maximum-entropy probability distribution consistent with the facts you know amounts to not pretending to know more than you do.
8szg | Remember: if we describe our knowledge using a probability distribution, its Shan- non entropy says how much we expect to learn when we find out what's really going on. We can roughly say it measures our 'ignorance'-though ordinary language can be misleading here.
hh47 | At first you think this ordinary 6-sided die is fair. But then you learn that no, the average of the numbers that come up is 5. What are the probabilities p1, ... , Pn for the different faces to come up?
adpv | This is tricky: you can imagine different answers!
sy8a | You could guess the die lands with 5 up every time. In other words, p5 = 1. This indeed gives the correct average. But the entropy of this probability distribution is 0. So you're claiming to have no ignorance at all of what happens when you roll the die!
11zj | Next you might guess that it lands with 4 up half the time and 6 up half the time. In other words, p4 = P6 = 2. This probability distribution has 1 bit of entropy. Now you are admitting more ignorance. But how can you be so sure that 5 never comes up?
dza1 | Next you might guess that p4 = P6 = 4 and p5 = 2. We can compute the entropy of this probability distribution. It's higher: 1.5 bits. Good, you're being more honest now! But how can you be sure that 1, 2, or 3 never come up? You are still pretending to know stuff!
5gil | Keep improving your guess, finding probability distributions with mean 5 with big- ger and bigger entropy. The bigger the entropy gets, the more you're admitting your ignorance! If you do it right, your guess will converge to the unique maximum-entropy solution.
n91l | But there's a more systematic way to solve this problem.
iknb | THE BOLTZMANN DISTRIBUTION
3ohm | Suppose you want to maximize the Shannon entropy
enn6 | - pi log pi i=1
voir | of a probability distribution p1, ... , Pn, subject to the constraint that the expected value of some quantity A¿ is some number c:
bxm5 | piAi = C (*) i=1 n
6cnd | Then try the Boltzmann distribution:
z41z | n exp(-₿Ai) Pi
k1hn | Lexp(-BAi)
853d | If you can find ß that makes (*) hold, this is the answer you seek!
px3f | How do you actually use the principle of maximum entropy?
28wa | If you know the expected value of some quantity and want to maximize entropy given this, there's a great formula for the probability distribution that usually does the job! It's called the 'Boltzmann distribution'. In physics it also goes by the names 'Gibbs distribution' or 'canonical ensemble', and in statistics it's called an 'exponential family'.
1jce | In the Boltzmann distribution, the probability pi is proportional to exp(-BA;) where A is the quantity whose expected value you know. Since probabilities must sum to one, we must have
jfbn | n exp(-ßAi) i=1 Lexp(-BAi)
cn1a | Pi =
0j5u | It is then easy to find the expected value of A as a function of the number ß: just plug these probabilities into the formula
u6dp | (A) = AiPi i=1 n
hnb4 | The hard part is inverting this process and finding { if you know what you want (A) to be.
a0sw | When and why does the Boltzmann distribution actually work? That's a bit of a long story, so I'll explain it later. First, let's use the Boltzmann distribution to solve the puzzle I mentioned last time:
aak4 | At first you think this ordinary 6-sided die is fair. But then you learn that no, the average of the numbers that come up is 5. What are the probabilities P1, ... , Pn for the different faces to come up? You can use the Boltzmann distribution to solve this puzzle!
7l7y | To do it, take 1 ≤ i ≤ 6 and Ai = i. Stick the Boltzmann distribution pi into the formula Ci Aipi = 5 and get a polynomial equation for exp(-3). You can solve this with a computer and get exp(-) ~ 1.877.
p1kn | So, the probability of rolling the die and getting the number 1 ~ ~ ~ 6 is pro- portional to exp(-Bi) ~ 1.877'. You can figure out the constant of proportionality by demanding that the probabilities sum to 1-or just look at the formula for the Boltzmann distribution. You should get these probabilities:
49ym | You can compute the entropy of this probability distribution, and you get roughly 1.97 bits. You'll remember that last time we got entropies up to 1.5 bits just by making some rather silly guesses.
abvj | So, using the Boltzmann distribution, you can find the maximum-entropy die that rolls 5 on average. Later, we'll see how the same math lets us find the maximum-entropy state of a box of gas that has some expected value of energy!
k4xq | MAXIMIZATION SUBJECT TO A CONSTRAINT
ok5a | To maximize a smooth function f of several variables subject to a constraint on some smooth function g, look for a point where
2ngm | for some number X.
```

OUTPUT:
```
