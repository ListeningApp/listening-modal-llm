{
  "id": "chatcmpl-A3UPYGks9ys5ZJu1K4biOZuThOT6R",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "ti7f | regression error. Wang et al. extend the student task by regressing a feature pyramid rather than a single output of a pre-trained network. Bergmann and Sattlegger adapt the student-teacher concept to point clouds. Local geometric descriptors are learned in a self-supervised manner to train the teacher. Xiao et al. let teachers learn to classify applied image transformations. The anomaly score is a weighted sum of the regression error and the class score entropy of an ensemble of students. By contrast, our method requires only one student and the regression error as the only criterion to detect anomalies. All of the existing work is based on identical and conventional (non-injective) networks for student and teacher, which causes undesired generalization of the student as explained in Section one.\noksu | Two point two. Density Estimation\nwtow | Anomaly detection can be viewed from a statistical perspective: By estimating the density of normal samples, anomalies are identified through a low likelihood. The concept of density estimation for anomaly detection can be simply realized by assuming a multivariate normal distribution. For example, the Mahalanobis distance of pre-extracted features can be applied as an anomaly score which is equivalent to computing the negative log likelihood of a multivariate Gaussian. However, this method is very inflexible to the training distributions, since the assumption of a Gaussian distribution is a strong simplification.\no22k | To this end, many works try to estimate the density more flexibly with a Normalizing Flow. Normalizing Flows are a family of generative models that map bijectively by construction as opposed to conventional neural networks. This property enables exact density estimation in contrast to other generative models like GANs or VAEs. Rudolph et al. make use of this concept by modeling the density of multi-scale feature vectors obtained by pre-trained networks. Subsequently, they extend this to multi-scale feature maps instead of vectors to avoid information loss caused by averaging. To handle differently sized feature maps so-called cross-convolutions are integrated. A similar approach by Gudovskiy et al. computes a density on feature maps with a conditional normalizing flow, where likelihoods are estimated on the level of local positions which act as a condition for the Normalizing Flow.\nnwfz | A common problem of normalizing flows is unstable training, which has a tradeoff on the flexibility of density estimation. However, even the ground truth density estimation does not provide perfect anomaly detection, since the density strongly depends on the parameterization.\nnvfy | Two point three. Other Approaches\nmror | Generative Models\nzlxc | Many approaches try to tackle anomaly detection based on\nk0bw | other generative models than normalizing flows as autoencoders or GANs. This is motivated by the inability of these models to generate anomalous data. Usually, the reconstruction error is used for anomaly scoring. Since the magnitude of this error depends highly on the size and structure of the anomaly, these methods underperform in the industrial inspection setting. The disadvantage of these methods is that the synthetic anomalies cannot imitate many real anomalies.\naq5a | Anomaly Synthesization\nsc5y | Some work reformulates semi-supervised anomaly detection as a supervised problem by synthetically generating anomalies. Either parts of training images or random images are patched into normal images. Synthetic masks are created to train a supervised segmentation. Traditional Approaches\n0yab | In addition to deep-learning-based approaches, there are also classical approaches for anomaly detection. The one-class SVM is a max-margin method optimizing a function that assigns a higher value to high-density regions than to low-density regions. Isolation forests are based on decision trees, where a sample is considered anomalous if it can be separated from the rest of the data by a few constraints. Local Outlier Factor compares the density of a point with that of its neighbors. A comparatively low density of a point identifies anomalies. Traditional approaches usually fail in visual anomaly detection due to the high dimensionality and complexity of the data. This can be circumvented by combining them with other techniques: For example, the distance to the nearest neighbor, as first proposed by Amer and Goldstein, is used as an anomaly score after features are extracted by a pre-trained network. Alternatively point cloud features or density-based clustering can be used to characterize a points neighborhood and label it accordingly. However, the runtime is linearly related to the dataset size.\nw95z | Three. Method\n0i1k | Our goal is to train two models, a student model F sub S and a teacher model F sub T, such that the student learns to regress the teacher outputs on defect-free image data only. The training process is divided into two phases: First, the teacher model is optimized to transform the training distribution P sub X to a normal distribution N zero, one bijectively with a normalizing flow. Second, the student is optimized to match the teacher outputs by minimizing the distance between F sub S X and F sub T X of training samples X in set X. We apply the distance for anomaly scoring at test-time, which is further described in Section three point two.\ndqlg | We follow and use extracted features obtained by a pre-trained network on ImageNet instead of RGB images as direct input for our models. Such networks have been shown to be universal feature extractors whose outputs\np6pq | carry relevant semantics for industrial anomaly detection.\nzse6 | In addition to RGB data, our approach is easily extendable to multimodal inputs including three-D data. If three-D data is available, we concatenate depth maps to these features along the channels. Since the feature maps are reduced in height and width compared to the depth map resolution by a factor D, we apply pixel-unshuffling by grouping a depth image patch of D by D pixels as one pixel with D squared channels to match the dimensions of the feature maps.",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725395248,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1194,
    "prompt_tokens": 3091,
    "total_tokens": 4285
  }
}