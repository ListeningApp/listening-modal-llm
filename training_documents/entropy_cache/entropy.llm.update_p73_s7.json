{
  "id": "chatcmpl-A3UG3CRWy4Rhnh1t7LLwdm4vy3LVk",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "po9y | Here's how you can compute the expected energy (E) and the entropy S of any system starting from its partition function Z of Beta as a function of the coolness Beta. I'll show you why these formulas are true, and then we'll test them out on the harmonic oscillator, where we have already computed the expected energy and entropy by other methods.\nw5lk | THE PARTITION FUNCTION KNOWS THE EXPECTED ENERGY\npb48 | If a system has partition function Z of six equals E to the power of negative Beta E of x d x then\nnriw | d over d Beta ln Z equals negative one over Z d over d Beta Z d beta Jx equals negative one over Z d over d Beta E to the power of negative Beta E of x d x equals E of x E to the power of negative Beta E of x d x over Z Jx\nh7kb | Jx E of x E to the power of negative Beta E of x d x\n2mrs | Jx E to the power of negative Beta E of x d x\nf7it | equals E\no9jm | In short, the expected energy is E equals negative d over d Beta d ln Z\ngz4c | The partition function is all-powerful! For starters, if you know the partition function of a physical system, you can figure out its expected energy. The expected energy E is minus the derivative of ln Z with respect to the coolness Beta equals one over k T.\nu30w | How do we show this? Easy: just look at the calculation above! We get a fraction, which is the expected value of E with respect to the Gibbs distribution.\nee2o | By the way, this trick of taking the derivative of the logarithm of a function is famous: it's called a 'logarithmic derivative'. Notice that\np87c | f prime of x\nreyp | f of x\n9vu6 | Thus the logarithmic derivative says how fast a function is growing compared to the value of the function itself-like the interest rate in compound interest.\nli13 | THE PARTITION FUNCTION KNOWS THE ENTROPY\nyb5z | If a system has Boltzmann distribution\nl7da | p of x equals E to the power of negative Beta E of x over Z where Z equals the integral of E to the power of negative Beta E of x d x\n24j5 | then its entropy in thermal equilibrium is\nsyjc | S equals negative k integral of p of x ln p of x d x equals negative k integral of p of x ln E to the power of negative Beta E of x over Z d x\nijx9 | equals k integral of p of x ln Z plus Beta E of x d x\nsosd | equals k ln Z plus Beta E\nzxxx | But since E equals minus ln Z, this gives\ne6pm | S equals k ln Z minus Beta ln Z over d Beta\nml6c | The entropy is a bit more complicated. But don't be scared! The Boltzmann distribution p of x is a fraction, so the log of this fraction breaks into two parts:\nujdt | ln p of x equals ln E to the power of negative Beta E of x over Z equals negative ln Z plus Beta E of x.\numn7 | Thus our integral for entropy breaks into two parts:\nt2yx | S equals negative k integral of p of x ln p of x d x equals k integral of p of x ln Z d x plus k Beta integral of p of x E of x d x.\n70qq | The first part is just k ln Z since the integral of p of x is one. The second part is k Beta E. If we use what we just learned about E:\n2421 | E equals negative d over d Beta ln Z\nlvcg | we get this formula for entropy in terms of the partition function:\nf9cy | This formula seems hard to understand at first. To extract its inner meaning, we need a new concept: 'free energy'.\n3vhx | THE PARTITION FUNCTION KNOWS THE FREE ENERGY\n1lk7 | To maximize entropy while holding expected energy constant, you can just minimize the free energy\nrkgd | F equals E minus T S We've seen\njbj0 | E equals negative d over d Beta ln Z and S equals k ln Z minus Beta ln Z over d Beta\nf7b0 | so with Beta equals one over k T a little algebra shows\n9bdp | F equals negative ln Z\nb1jn | Three\nf02j | We can understand the relation between entropy, energy and the partition function if we bring in a concept I haven't mentioned yet: the free energy\nuc93 | F equals E minus T S.\n24jr | Since we know formulas for E and S in terms of the partition function, we can work out a formula for F. And it's really simple! Much simpler than S, for example. It's just\nweol | F equals negative ln Z.\nzo3w | But what's the meaning of free energy? Remember: to maximize the Shannon entropy H subject to a constraint on expected energy, we introduced the Lagrange multiplier Beta equals one over k T and maximized the quantity H minus Beta E. But if you multiply this quantity by negative k T, you get free energy:\nbqsc | negative k T times H minus Beta E equals E minus T S equals F.\nc2j4 | So, as long as T is greater than zero, maximizing entropy subject to a constraint on expected energy is equivalent to minimizing free energy!\nk611 | Thus, free energy turns a problem of maximizing entropy subject to a constraint into a minimization problem without a constraint. The point is not that we've turned maximization into minimization: that's just an arbitrary business with signs. The point is that free energy lets us stop thinking about the constraint.\n6s1a | There's a huge amount to say about the free energy, which is also called the 'Helmholtz free energy', since there are other kinds. You can think of T S as the amount of energy in useless random form, since it comes from entropy. Since E is the total expected energy, F equals E minus T S is the amount of 'useful' energy. More precisely, the free energy is the maximum amount of work obtainable from a system at a constant temperature. But showing this would take us out of our way.\nxwwb | THE PARTITION FUNCTION KNOWS ALL: REVISITED\notfh | If Z of three is the partition function of a system, in thermal equilibrium at coolness Beta its expected energy is E equals negative d over d Beta ln Z\n6dzi | and its free energy is\nnk46 | F equals negative ln Z\nsbg4 | We can compute its entropy from these using\n0vsm | F equals E minus T S and we get\nrrsc | S equals k ln Z minus Beta ln Z over d Beta\nxjfg | Now we can tell a simpler story, which is easier to remember. Free energy, being the energy in useful form, is the expected energy minus the useless energy, which is temperature times entropy. Thus\niw9o | F equals E minus T S\nenxg | so\nvmnz | S equals E minus F over T\n82g8 | equals k Beta times negative F plus E\nl3g2 | and using our formulas for F and E in terms of the partition function Z, we get\n5ah7 | S equals k ln Z minus Beta ln Z\ncq8x | The story here is more of a mnemonic than a true explanation, because I'm not saying much what it means for energy to be 'useful' or 'useless'. I've only given this hint: when a system is in thermal equilibrium, its free energy is minimized. For more on the meaning of free energy, try a good book on thermodynamics, like this:\ndxup | Right now I'd rather say a bit about the meaning of the partition function.\n0xhz | THE MEANING OF THE PARTITION FUNCTION\nthwq | Say X is a set where each point i has an 'energy' E sub i; E R. Its partition function is\nnmx1 | Z equals the sum of E to the power of negative Beta E sub i for i in X\nng95 | where Beta E R is the coolness.\nldw4 | The partition function counts the points of X-but it counts points with large energy less, since they're less likely to be 'occupied'.\ngynb | If Beta equals one over k T, points with energy E sub i much greater than k T count for very little.\nyp2i | But as T approaches plus infinity, all points get fully counted and Z approaches the absolute value of X. In physics we call Z the number of accessible states.\ngm15 | Say we have a system with some countable set of states X. In thermal equilibrium at temperature T, the probability that the system is in its i-th state is proportional to the exponential of negative Beta E sub i, where E sub i is the energy of that state and Beta is the coolness. Thus, physicists say the partition function\nuwgf | Z equals the sum of E to the power of negative Beta E sub i for i in X\nai15 | is the number of accessible states: roughly, the number of states the system can easily be in at temperature T, where Beta equals one over k T.",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394659,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1973,
    "prompt_tokens": 3558,
    "total_tokens": 5531
  }
}