{
  "id": "chatcmpl-A3UFU3ClL9vZ72LFWNKWm6vPzutAt",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "a7ao | Thirteen GLM two: Comparing means adjusted for other predictors (analysis of covariance)\n29a3 | Thirteen point one. What will this chapter tell me?\nsb1e | My road to rock stardom had taken a bit of a knock with my unexpected entry to an all-boys' grammar school (rock bands and grammar schools really didn't go together). I needed to be inspired and I turned to the masters: Iron Maiden. I first heard Iron Maiden at the age of eleven when a friend lent me Piece of Mind on a cassette and told me to listen to 'The Trooper'. It was, to put it mildly, an epiphany. I became their smallest (I was eleven) biggest fan and obsessed about them in the unhealthiest of ways. I bombarded the man who ran their fan club (a guy called Keith) with letters, and, bless him, he replied to them all. Eventually my stalking paid off and Keith arranged for me to go backstage when they played what was then (and to me always will be) the Hammersmith Odeon in London on fifth November nineteen eighty-six. Not only was it the first time I had seen them live, but I got to meet them too. It is difficult to convey how exciting and anxiety-provoking that night was. It was all quite overwhelming. I was so utterly awe-struck that I managed to say precisely nothing to any of the band (but I do have some good photos where my speechlessness is tangible; see Figure thirteen point one). Soon to become a theme in my life, a social situation had provoked me to make an utter fool of myself. When it was over I was in no doubt that this was the best day of my life. In fact, I thought, I should just kill myself there and then because nothing would ever be as good. This may be true, but I have subsequently had other very nice experiences, so who is to say that they were not better? I could compare experiences to see which one is the best, but there is an important confound: my age. At the age of thirteen, meeting Iron Maiden was bowel-weakeningly exciting, but adulthood (sadly) dulls your capacity for this kind of unqualified excitement. To really see which experience was best, I would have to take account of the variance in enjoyment that is attributable to my age at the time. Doing so will give me a purer measure of how much variance in my enjoyment is attributable to the event itself.\nw2yn | This chapter extends the previous one to look at situations in which you want to compare groups' means, but also adjust those means for another variable (or variables) that you expect to affect the outcome. This involves a linear model in which an outcome is predicted from dummy variables representing group membership but one or more other predictors (usually continuous variables) are included. These additional predictors are sometimes labelled covariates, and this configuration of the linear model is sometimes known as analysis of covariance.\nap6l | Thirteen point two. What is ANCOVA?\niest | In the previous chapter we saw how we can compare multiple group means with the linear model by using dummy variables to code group membership. In addition, in Chapter nine we saw how the linear model can incorporate several continuous predictor variables. It should, therefore, be no surprise that the linear model to compare means can be extended to include one or more continuous variables that predict the outcome (or dependent variable). When the main focus of the model is to compare means (perhaps from different experimental groups) then these additional predictors in the model are sometimes referred to as covariates. Also, this form of the linear model is sometimes referred to as analysis of covariance (or ANCOVA for short).\ncox8 | As we've discussed before, these labels for special cases of the linear model (such as one-way independent ANOVA in the previous chapter, and ANCOVA here) reflect historical divisions in methods. They are unhelpful because they create the impression that we're using distinct statistical models when we're not. I want you to focus on the general linear model that underpins these special cases, but I can't really avoid using the ANOVA/ANCOVA labels now and again so that when your supervisor tells you to do ANOVA/ANCOVA you can find the relevant part of the book!\nppqi | In the previous chapter, we used an example about the effects of puppy therapy\noxou | on happiness. Let's think about things other than puppy therapy that might influence happiness. Well, the obvious one is how much you like dogs (a dog phobic is going to be about as happy after puppy therapy as I would be after tarantula therapy), but there are other things too such as individual differences in temperament. If these variables (the covariates) are measured, then it is possible to adjust for the influence they have on the outcome variable by including them in the linear model. From what we know of hierarchical regression it should be clear that if we enter the covariate into the model first, and then enter the dummy variables representing the group means (e.g., the experimental manipulation), we can see what effect a predictor variable has, adjusting for the effect of the covariate. In essence, rather than predicting the outcome from group means, we predict it from group means that have been adjusted for the effect of covariate(s). There are two main reasons to include covariates in ANOVA:\n495n | To reduce within-group error variance: When we predict an outcome from group means (e.g., when these represent the effect of an experiment), we compute an F-statistic by comparing the amount of variability in the outcome that the experiment can explain against the variability that it cannot explain. If we can attribute some of this 'unexplained' variance to other measured variables (covariates), then we reduce the error variance, allowing us to assess more sensitively the difference between group means.\nawri | Elimination of confounds: In any experiment, there may be unmeasured variables that confound the results (i.e., variables other than the experimental manipulation that affect the outcome variable). If any variables are known to influence the outcome variable being measured, then including them as covariates can remove these variables as potential explanations for the effect of interest.\nbl28 | Thirteen point three. ANCOVA and the general linear model\nd5bz | The researchers who conducted the puppy therapy study in the previous chapter suddenly realized that a participant's love of dogs would affect whether puppy therapy would affect happiness. Therefore, they repeated the study on different participants, but included a self-report measure of love of puppies from zero (I am a weird person who hates puppies, please be deeply suspicious of me) to seven (puppies are the best thing ever, one day I might marry one). The data are in Table thirteen point one and in the file Puppy Love dot sav, which contains the variables Dose (one equals control, two equals fifteen minutes, three equals thirty minutes), Happiness (the person's happiness\nap5o | The summary of the model resulting from the self-test (Output thirteen point one) shows us the goodness of fit of the model first when only the covariate is used in the model, and second when both the covariate and the dummy variables are used. The difference between the values of R squared zero point two eight eight minus zero point zero six one equals zero point two two seven represents the individual contribution of puppy therapy to predicting happiness. Puppy therapy accounted for twenty-two point seven percent of the variation in happiness, whereas love of puppies",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394624,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1552,
    "prompt_tokens": 3332,
    "total_tokens": 4884
  }
}