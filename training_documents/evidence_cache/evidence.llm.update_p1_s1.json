{
  "id": "chatcmpl-A0ZTlNIsR1FfhRDMfdSkuq4T3bwXN",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "```\n9own | Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence\nbqfb | We examine the productivity effects of a generative artificial intelligence technology-the assistive chatbot ChatGPT-in the context of mid-level professional writing tasks. In a preregistered online experiment, we assign occupation-specific, incentivized writing tasks to four hundred forty-four college-educated professionals, and randomly expose half of them to ChatGPT. Our results show that ChatGPT substantially raises average productivity: time taken decreases by zero point eight SDs and output quality rises by zero point four SDs. Inequality between workers decreases, as ChatGPT compresses the productivity distribution by benefiting low-ability workers more. ChatGPT mostly substitutes for worker effort rather than complementing worker skills, and restructures tasks towards idea-generation and editing and away from rough-drafting. Exposure to ChatGPT increases job satisfaction and self-efficacy and heightens both concern and excitement about automation technologies.\nwwdt | One Introduction\nmn1r | Recent advances in generative artificial intelligence may have widespread implications for production and labor markets. New generative AI systems like ChatGPT or DALL-E, which can be prompted to create novel text or visual outputs from large amounts of training data, are qualitatively unlike most historical examples of automation technologies. Previous waves of automation predominantly impacted \"routine\" tasks consisting of explicit sequences of steps that could be easily codified and programmed into a computer. Creative, difficult-to-codify tasks (such as writing and image generation) largely avoided automation-a pattern that scholars noted might change with the advent of the deep learning techniques that now underpin generative AI systems.\n5vqw | The emergence of powerful generative AI technologies reintroduces a host of classic questions in a new context. Automation technologies-by definition-perform specific tasks in place of humans. But, more broadly, they may either displace humans completely from certain occupations or complement existing human workers and increase their productivity. Insofar as automation technologies mostly displace human workers, they can increase unemployment, while their impacts on aggregate productivity may be small or nonexistent to the degree that they mainly serve to redistribute income from workers to owners of capital. Insofar as automation complements existing workers, it can simultaneously benefit workers, capital owners, and consumers by raising productivity and wages and lowering prices.\nmeyw | For example, a potent generative writing tool like ChatGPT might entirely replace certain kinds of writers, such as grant writers or marketers, by letting companies directly automate the creation of grant applications and press releases with minimal human oversight. This might not increase the quality of the resulting written output, but would let companies save on wage costs by eliminating human labor. Alternatively, a tool like ChatGPT could substantially raise the productivity of grant writers and marketers, for example by automating relatively routine, time-consuming subcomponents of their writing tasks, such as translating ideas into an initial rough draft. In this case, demand for these services could expand, resulting in higher employment and wages as well as greater productivity for companies and cheaper products for consumers. Inequalities between workers could also be affected: inequality could decrease if lower-ability workers are helped more by ChatGPT, or increase if higher-ability workers have the skills necessary to take advantage of the new technology.\n2e62 | Which of these eventualities will generative AI systems bring about? The answer depends on a host of questions: how do generative AI systems affect workers' productivity in existing tasks? Do they affect productivity largely by substituting for worker effort or complementing worker skills? Do they differentially affect low- or high-ability workers, or workers with\n75y3 | different skill profiles? Do they affect workers' enjoyment of their work?\ns2g2 | This paper takes the first step towards answering these questions. In an online experiment, we recruit four hundred forty-four experienced, college-educated professionals and assign each to complete two occupation-specific, incentivized writing tasks. The occupations we draw on are marketers, grant writers, consultants, data analysts, human resource professionals, and managers. The tasks, which include writing press releases, short reports, analysis plans, and delicate emails, comprise twenty-to thirty-minute assignments designed to resemble real tasks performed in these occupations; indeed, most of our participants report completing similar tasks before and rate the assigned tasks as realistic representations of their everyday work. Participants face high-powered incentives, in the form of large bonus payments, to produce high-quality work. Quality is assessed by blinded experienced professionals working in the same occupations. Evaluators are asked to treat the output as if encountered in a work setting and are incentivized to grade outputs carefully. Evaluators assign an overall grade as well as separate grades for writing quality, content quality, and originality. Each piece of output is seen by three evaluators, with an average within-essay cross-evaluator correlation of zero point four four.\nq1q2 | A randomly-selected fifty percent of our participants-the treatment group-are instructed to sign up for ChatGPT between the first and second task, are walked through how to use it, and are told they are permitted to use it on the second task if they find it useful. The control group is instead instructed to sign up for the LaTeX editor Overleaf. This design allows us to estimate the causal effects of ChatGPT using a combination of within-person and between-person variation, and performance on the first task serves as a measure of baseline ability that enables our inequality analyses.\ncb7r | We collect participants' output and elicit total time taken, time taken on various subcomponents of the task, job satisfaction, self-efficacy, and beliefs about automation. We also take a snapshot of each participant's output each minute while they perform the task, to construct an objective measure of time active on the task and to detect ChatGPT usage in the control group and on the pre-treatment task.\n68xu | A complete description of our experimental design, a copy of relevant survey questionnaires, and additional figures validating our central measures and extending our main results are included in the Online Appendix. Descriptive statistics about the sample, as well as balance and selective attrition tests, are available in Table One. The attrition rate is five percent in the control group and ten percent in the treatment group. Balance tests indicate that across thirteen pre-treatment characteristics, the treatment and control group exhibit a small significant difference only for only two characteristic (employment status and being an HR professional). Our partly within-person design, which controls for performance on the pre-treatment task, should\nhd35 | eliminate any influence of selective attrition on our results; in the Online Appendix, we also report Lee bounds on our main results and versions of our results controlling for employment status and occupation, which confirm that our results are highly robust to selective attrition.\n2zpk | Two Results\nepu7 | Two point one Takeup of ChatGPT\n7od1 | In the treatment group, ninety-two percent of treated participants successfully sign up for ChatGPT, and eighty-one percent choose to use it on the second task, giving it an average self-assessed usefulness score of four point four out of five.\n0bqy | Prior to treatment, about seventy percent of our participants had heard of ChatGPT and thirty percent had used it before. Self-reported and objective measures indicate only ten to twenty percent of the control group use ChatGPT on the tasks, meaning there is at least a sixty percentage point experimentally-induced gap in usage between our treatment and control groups on the second task. The fact that some control participants are using the tool means our estimates provide lower bounds on the effects of ChatGPT usage on productivity.\nb780 | Two point two Productivity\n```",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1724699745,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_3aa7262c27",
  "usage": {
    "completion_tokens": 1556,
    "prompt_tokens": 3369,
    "total_tokens": 4925
  }
}