{
  "id": "chatcmpl-A3U7PJtDhJ5PfiQTmsOC7h8NMRqd1",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "16py | In the third set of experiments, we measured the improvements obtained with the joint training of the NN and the postprocessor with the word-level criterion, in comparison to training based only on the errors performed at the character level. After initial training on individual characters as above, global word-level discriminative training was performed with a database of three thousand five hundred lower case words. For the SDNN/HMM system, without any dictionary constraints, the error rates dropped from thirty-eight percent and twelve point four percent word and character error to twenty-six percent and eight point two percent respectively after word-level training, i.e., a relative drop of thirty-two percent and thirty-four percent.\nm4ov | For the HOS system and a slightly improved architecture, without any dictionary constraints, the error rates dropped from twenty-two point five percent and eight point five percent word and character error to seventeen percent and six point three percent respectively, i.e., a relative drop of twenty-four point four percent and twenty-five point six percent. With a twenty-five thousand four hundred sixty-one-word dictionary, errors dropped from four point six percent and two point zero percent word and character errors to three point two percent and one point four percent, respectively, after word-level training, i.e., a relative drop of thirty point four percent and thirty percent. Even lower error rates can be obtained by drastically reducing the size of the dictionary to three hundred fifty words, yielding one point six percent and zero point ninety-four percent word and character errors.\n9uqd | These results clearly demonstrate the usefulness of globally trained NN/HMM hybrids for handwriting recognition. This confirms similar results obtained earlier in speech recognition.\n8szx | Ten. A CHECK READING SYSTEM\niwdc | This section describes a GTN-based check reading system, intended for immediate industrial deployment. It also shows how the use of gradient-based learning and GTN's make this deployment fast and cost-effective while yielding an accurate and reliable solution.\n4vks | The verification of the amount on a check is a task that is extremely time and money consuming for banks. As a consequence, there is a very high interest in automating the process as much as possible. Even a partial automation would result in considerable cost reductions. The threshold of economic viability for automatic check readers, as set by the bank, is when fifty percent of the checks are read with less than one percent error. The other fifty percent of the check being rejected and sent to human operators. In such a case, we describe the performance of the system as fifty percent correct/forty-nine percent reject/one percent error. The system presented here was one of the first to cross that threshold on representative mixtures of business and personal checks.\nuyaf | Checks contain at least two versions of the amount. The courtesy amount is written with numerals, while the legal amount is written with letters. On business checks, which are generally machine-printed, these amounts are relatively easy to read but quite difficult to find due to the lack of standard for business check layout. On the other hand, these amounts on personal checks are easy to find but much harder to read.\nd1qh | For simplicity (and speed requirements), our initial task is to read the courtesy amount only. This task consists of two main steps.\nnyqt | One) The system has to find, among all the fields (lines of text), the candidates that are the most likely to contain the courtesy amount. This is obvious for many personal checks, where the position of the amount is standardized. However, as already noted, finding the amount can be rather difficult in business checks, even for the human eye. There are many strings of digits, such as the check number, the date, or even \"not to exceed\" amounts, that can be confused with the actual amount. In many cases, it is very difficult to decide which candidate is the courtesy amount before performing a full recognition.\n7odd | Two) In order to read (and choose) some courtesy amount candidates, the system has to segment the fields into characters, read and score the candidate characters, and finally find the best interpretation of the amount using contextual knowledge represented by a stochastic grammar for check amounts.\n0le2 | The GTN methodology was used to build a check amount reading system that handles both personal checks and business checks.\n5dw0 | A. A GTN for Check Amount Recognition\ni4yq | We now describe the successive graph transformations that allow this network to read the check amount. Each GT produces a graph whose paths encode and score the current hypotheses considered at this stage of the system.\nfj3g | The input to the system is a trivial graph with a single arc that carries the image of the whole check.\nzuua | One) The Field Location Transformer: Tfield first performs classical image analysis (including connected component analysis, ink density histograms, layout analysis, etc.) and heuristically extracts rectangular zones that may contain the check amount. Tfield produces an output graph, called the field graph, such that each candidate zone is associated with one arc that links the start node to the end node. Each arc contains the image of the zone and a penalty term computed from simple features extracted from the zone (absolute position, size, aspect ratio, etc.). The penalty term is close to zero if the features suggest that the field is a likely candidate and is large if the field is deemed less likely to be an amount. The penalty function is differentiable, therefore its parameters are globally tunable.\nelwn | An arc may represent separate dollar and cent amounts as a sequence of fields. In fact, in handwritten checks, the cent amount may be written over a fractional bar and not aligned at all with the dollar amount. In the worst case, one may find several cent amount candidates (above and below the fraction bar) for the same dollar amount.\njnqv | Two) The Segmentation Transformer: Tseg, similar to the one described in Section Eight, examines each zone contained in the field graph and cuts each image into pieces of ink using heuristic image processing techniques. Each piece of ink may be a whole character or a piece of character. Each arc in the field graph is replaced by its corresponding segmentation graph that represents all possible groupings of pieces of ink. Each field segmentation graph is appended to an arc that contains the penalty of the field in the field graph. Each arc carries the segment image, together with a penalty that provides a first evaluation of the likelihood that the segment actually contains a character. This penalty is obtained with a differentiable function that combines a few simple features such as the space between the pieces of ink or the compliance of the segment image with a global baseline, and a few tunable parameters. The segmentation graph represents all the possible segmentations of all the field images. We can compute the penalty for one segmented field by adding the arc penalties along the corresponding path. As before, using a differentiable function for computing the penalties will ensure that the parameters can be optimized globally.\nunp3 | The segmenter uses a variety of heuristics to find candidate cut. One of the most important ones is called \"hit and deflect.\" The idea is to cast lines downward from the top of the field image. When a line hits a black pixel, it is deflected so as to follow the contour of the object. When a line hits a local minimum of the upper profile, i.e., when it cannot continue downward without crossing a black pixel, it is just propagated vertically downward through the ink. When two such lines meet each other, they are merged into a single cut. The procedure can be repeated from the bottom up. This strategy allows the separation of touching characters such as double zeros.",
        "role": "assistant",
        "function_call": null,
        "tool_calls": null,
        "refusal": null
      }
    }
  ],
  "created": 1725394123,
  "model": "gpt-4o-2024-05-13",
  "object": "chat.completion",
  "system_fingerprint": "fp_fde2829a40",
  "usage": {
    "completion_tokens": 1558,
    "prompt_tokens": 3302,
    "total_tokens": 4860
  }
}