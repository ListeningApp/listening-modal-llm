You will receive raw text from an OCR scan of a document or web page. Each line of input represents one textbox from the document.

Your task is to label each textbox with exactly one of the following labels:
  title: the primary document title, no more than one per document
  heading: the name of the following chapter or section (should never start in the middle of the previous paragraph)
  subheading: a secondary heading, often following another heading (should never start in the middle of the previous paragraph)
  body: main paragraph content: may start or end in the middle of a word, use context to follow paragraphs that are split across textboxes (if a textbox contains both heading and body text, label it "body")
  math: textbox primarily containing math
  imageDescription: standalone callout that only describes an image, chart, table, or similar (typically begins with "Table...", "Figure...", "Fig. ...", "Above...", "Left...", etc.)
  authors: names of contributors to this document
  institutions: list of universities, business, and other institutions affiliated with this document
  publisher: info about the publisher, or provided by the publisher, including copyright info
  pagenum: the page number
  headerOrFooter: boilerplate text page number, or redundant headings at the top/bottom of the page
  toc: the table of contents
  references: bibliographic references and resources
  acknowledgements: thanks and credits to contributors
  appendix: index, appendix, or any other end matter not part of the main thread (including related headings)
  table: tabular data, label, title, or subheading for a grid or list of data
  datum: numeric data or data label from a chart or list
  advertisement: promotional ads and marketing
  layout: non-content related to the layout of the page, e.g. sidebar navigation
  callout: pull quote or long block text that stands apart from the main text
  footnote: footnotes and endnotes near the bottom of the page
  keywords: list of keywords or tags
  url: web address or email
  other: any other text that does not belong to the main thread

Each line of input is prefixed with a textbox ID in the format `id | Text content`. The output must be in the format `id | label`.

Note that body text may be split across multiple textboxes, and textboxes may start or end in the middle of a sentence or word. Because the text was extracted from a web page or document, paragraphs of body text may be interrupted by multiple textboxes of redundant headers, footnotes, page numbers, tables, images, etc. For example, a real heading will never interrupt the middle of a sentence. Use context clues like this to carefully label each textbox.

EXAMPLE INPUT:
1pjs | Neuroscience Applied 1 (2022) 101012
o2kr | Contents lists available at ScienceDirect
v6sk | Neuroscience Applied
1wj6 | journal homepage: www.journals.elsevier.com/neuroscience-applied
936l | Research Articles
06yq | Microdosing with psychedelics to self-medicate for ADHD symptoms in adults: A naturalistic study
dpv6 | ARTICLE INFO
8r5j | ABSTRACT
2taz | Keywords: ADHD Microdosing Psychedelics Self-medication Well-being Time perception
o3ya | ADHD in adulthood is often overlooked, which negatively affects the individual's well-being. First-line phar- macological interventions are effective in many ADHD patients, relieving symptoms rapidly. However, there seems to be a proportion of individuals who discontinue, or fail to respond to these treatments. For these in- dividuals, alternative treatment options should be explored.
r5il | 1. Introduction
5gui | Attention deficit hyperactivity disorder (ADHD) is one of the most common developmental disorders worldwide. Prevalence research indicates that 2.6% of the adult population has persistent ADHD. ADHD in adults is often overlooked because of the high comorbidity rate and lack of knowledge about how ADHD is expressed in adulthood (Kooij et al.,
9d4o | Fig. 1. Flowchart of included participants for each time point.
82qc | 2019). In addition, ADHD is associated with deficits in various domains of cogni- tive functioning. Twenty-five percent of ADHD cases suffered from ADHD symptoms purely because of de- ficiencies in temporal processing (Sonuga-Barke et al., 2010).
ls7d | First-line ADHD treatments in adults mainly include pharmacological interventions to enhance dopaminergic and noradrenergic neurotrans- mission with stimulants. Overall, they have been proven to work effectively in adults with ADHD, inducing fast symptom relief and thereby enhancing the person's quality of life. In the
5esx | Table 1 Demographic information from respondents at baseline and the two and four- week time points.
t8vv | longer term, approximately twenty percent of ADHD patients discontinue their prescribed medication after six to nine months, thirty percent after one year, and half of them after two years.
xrd1 | 2. Material and methods
5746 | 2.1. Study design and participants
7toz | The study employed a naturalistic design, assessing the experiences of participants at baseline,
j346 | Neuroscience Applied 1 (2022)
m5ka | E.C.H.M. Haijen et al.
kx2c | REVIEW
v8uq | before they start MD on their own initiative, and at two and four weeks after MD initiation. The target population included adults diagnosed with ADHD and individuals who experienced ADHD symptoms to the extent that these interfered with their daily lives and who had not been diag- nosed with ADHD before. To be included in the analyses, participants needed to score above a cut-off point on at least one of the subscales of the Conner's Adult ADHD Rating Scale (CAARS-S:SV).
2zmw | Fig. 2. Mean scores of the CAARS-S:SV DSM-IV total symptoms T-scores at baseline (0W) and two (2W) and four weeks (4W) after MD (A) of the whole sample, and (B) per conventional ADHD medication use. Error bars represent mean error.
sdk3 | <LATEX>\lim _ { x ightarrow \infty } rac { 6 x ^ { 2 } + 1 0 0 } { 7 x ^ { 2 } - 1 0 } =</LATEX>
x972 | 2.2. Study procedure
k221 | Mean performance measures of the CAARS-

EXAMPLE OUTPUT:
1pjs | headerOrFooter
o2kr | publisher
v6sk | publisher
1wj6 | publisher
936l | headerOrFooter
06yq | title
dpv6 | other
8r5j | heading
2taz | keywords
o3ya | body
r5il | heading
5gui | body
9d4o | imageDescription
82qc | body
ls7d | body
5esx | imageDescription
t8vv | body
xrd1 | heading
5746 | subheading
7toz | body
j346 | headerOrFooter
m5ka | authors
kx2c | headerOrFooter
v8uq | body
2zmw | imageDescription
sdk3 | math
x972 | heading
k221 | body




1pjs | Working Memory Capacity of ChatGPT: An Empirical Study
o2kr | Abstract
v6sk | 1 Working memory is a critical aspect of both human intelligence and artificial intelligence, serving as a workspace for the temporary storage and manipulation of information. In this paper, we systematically assess the working memory capacity of ChatGPT (GPT-3.5), a large language model developed by OpenAI, by examining its performance in verbal and spatial n-back tasks under various
1wj6 | 123 45 6 7 8 9 10 1 2 3 5
936l | 6 conditions. Our experiments reveal that ChatGPT experiences significant declines 7 in performance as n increases (which necessitates more information to be stored in 8 working memory), suggesting a limit to the working memory capacity strikingly 9 similar to that of humans. Furthermore, we investigate the impact of different instruction strategies on ChatGPT's performance and observe that the fundamental
06yq | 11 patterns of a capacity limit persist. From our empirical findings, we propose that
dpv6 | 12 n-back tasks may serve as tools for benchmarking the working memory capacity
8r5j | 13 of large language models and hold potential for informing future efforts aimed
2taz | 14 at enhancing AI working memory and deepening our understanding of human 15 working memory through AI models.
o3ya | 16 1 Introduction
r5il | 17 The advent of large language models (LLMs) like ChatGPT and GPT-4 [31] has propelled the
5gui | 18 pursuit of artificial general intelligence [5] and unveiled human-level abilities that warrant further
82qc | 19 exploration [39, 22]. Among these abilities is the capacity to retain contextual information while
ls7d | 20 engaging in multi-turn conversations, suggesting the presence of working memory in these LLMs.
tzt3 | 21 In cognitive sciences, working memory is usually defined as the ability to temporarily store and 22 manipulate information in mind [1]. It is widely regarded as a critical element of human intelligence, as it underlies various higher-order cognitive processes such as reasoning, problem-solving, and
t8vv | 24 language comprehension [9].
qvnu | 25 Studies on human participants have revealed a fundamental capacity limit in working memory [10].
kggw | 26 However, there has not been a consensus on why and how working memory capacity is limited [30, 41].
xrd1 | 27 Among many theories, the executive attention hypothesis [16, 15] suggests that working memory
5746 | 28 requires using attention to maintain or suppress information, and the constraint on working memory
7toz | 29 capacity is not really about memory storage per se, but about the capacity for controlled, sustained
j346 | 30 attention in the face of interference.
v8uq | 31 Supporting evidence of the executive attention hypothesis includes results from the n-back task,
x972 | 32 which is arguably the current gold standard measure of working memory capacity in the cognitive
cwrw | 33 neuroscience literature (for a review, see [20]). The n-back task, initially developed by Kirchner [21],
4i0e | 34 requires participants to monitor a continuous stream of stimuli, and to decide for each stimulus
h2l3 | 35 whether it matches the one n steps back in the stream (see Figure 1 for illustrations of basic verbal and
dfzb | <LATEX>m</LATEX> Figure 1: Illustrations of verbal (top row) and spatial (bottom row) n-back tasks with <LATEX>n = 1 , 2 , 3 .</LATEX> Participants are instructed to give a response ("m") when the current stimulus (e.g., a letter or a spatial location) is the same as the stimulus <LATEX>n</LATEX> trials ago), and not respond <LATEX>\left( ^ { \prime \prime } - ^ { \prime \prime } \right)</LATEX> on nonmatch trials.
u6ty | 36 spatial n-back tasks). The participants in this task must, therefore, continuously update their mental
awvu | 37 representation of the target items while also dropping now irrelevant items from consideration. So,
on9b | 38 some executive attention processes are required in addition to storage. Typical human performance
a8ge | 39 (measured by accuracy) as a function of <LATEX>n</LATEX> is shown in Figure 2, where we used the data presented in 40 [19].
h27a | 41 In humans, working memory capacity has proved to be closely
pdjh | 42 related with fluid intelligence (Gf) or general intelligence (g) [7,
xmgs | 43 34], placing working memory at the core of human intelligence.
bd9h | 44 However, in artificial intelligence, there has not been a consensus as 45 to which metrics should be accepted as an intelligence index when 46 evaluating and comparing cognitive abilities of LLMs. In the current
m047 | 47 study, we define working memory of LLMs as an emergent ability
gy8c | 48 to selectively maintain and manipulate information for ongoing
y4mj | 49 cognitive processes, echoing the executive attention hypothesis in
vpgq | 50 cognitive sciences. We propose that the performance of LLMs
ousl | 51 on n-back tasks can be a reliable metric for assessing their working
m4ju | 52 memory capacity, which in turn might reflect the general intelligence
a0mb | 53 of reasoning and problem solving emerged from these models.
ki8m | Figure 2: Typical human per- formance to the n-back tasks for <LATEX>n = 1 , 2 , 3 .</LATEX> We plot the mean ± standard deviation of the data collected in [19].
km8w | 54 To demonstrate this, we used ChatGPT (GPT-3.5) as a representative
wzno | 55 of LLMs, and designed two categories of the n-back task to eval-
xagm | 56 uate its working memory capacity. Our results revealed strikingly
iwn5 | 57 consistent patterns of a capacity limit across multiple experimental
uooz | 58 conditions, hinting at possibly similar mechanisms of working mem-
pxbq | 59 ory in humans and LLMs. We believe this finding is important for both cognitive scientists and LLM
jfsr | 60 researchers, and hope that this could guide future endeavors of better understanding why human
u15r | 61 working memory capacity is limited and building more intelligent LLMs with better working memory 62 capacity.
lq35 | 63 2 Related Works
3g9w | 64 Working memory has long been a subject of study in human and animal cognition [11]. Unlike 65 long-term memory, which is stored in long-term synaptic weights in the neural system, working
d09o | 66 memory is believed to be maintained by sustained activations of neurons in prefrontal cortex [26].
ylhz | 67 This working mechanism bears striking resemblance to the in-context learning ability found in LLMs.
a3td | 68 However, the investigation of working memory in LLMs remains largely unexplored. Therefore,
ex5k | 69 exploring the working memory capacity of LLMs holds great interest and significance, as it can 70 contribute to the development of more powerful models [17, 18, 42, 23].
9d4o | 71 Large language models have played a crucial role in achieving impressive performance across a wide
cjq2 | 72 range of downstream tasks. While fine-tuning has emerged as a popular approach for transferring to
5esx | 73 new tasks [13, 38, 2], it can be impractical to apply this method to extremely large models and/or
m5ka | 74 scarce data. As an alternative, a method called in-context learning was proposed in a study by [4] ,
byu8 | 2
76b0 | Figure 3: Illustrations of the different variants of verbal* n-back tasks (we use <LATEX>n = 2</LATEX> in the figure) considered in this paper. (a): base case identical to the case presented in Figure 1; (b): stimulus on each trial now contains 3-6 random noise characters (chosen from "#$%&@ ~~ ") in addition to a single alphabetical letter that the LLM should compare across trials. The LLM is instructed to ignore these noise characters, and the alphabetical letter may appear in any position in the noise-corrupted stimulus; (c): alongside the input for every trial, the <LATEX>L L M</LATEX> is also provided with the feedback on whether it has performed the previous trial correctly; (d): the LLM is prompted with a reasoning- eliciting instruction to output the final answer <LATEX>\left( { } ^ { \prime \prime } \mathrm { m } ^ { \prime \prime } \right.</LATEX> or "-") and the rationale. Refer to Table 1 for the detailed instructions the LLM is prompted with in each of the task variants.
zxz6 | "Note that both verbal and spatial tasks are compatible with these variants; we illustrate using verbal tasks without loss of generality.
xnth | 75 showcasing the remarkable few-shot learning capabilities of large language models without requiring
vafm | 76 weight updates through gradient descent. Since its introduction, research on in-context learning in
2zmw | 77 language models has garnered significant attention from both academia and industry. Previous studies
bf9k | 78 have presented various approaches to leverage the in-context learning ability of language models,
otkr | 79 including selecting labeled examples for demonstrations [33, 25, 24], meta-training with an explicit
ibgs | 80 in-context learning objective [6, 27], and exploring the variant of in-context learning that involves
colo | 81 learning to follow instructions [40, 38, 14, 28, 29]
d6r4 | 82 However, relatively less work has been done to calibrate the working memory capacity of LLMs and understand the limitation of in-context learning ability. To the best of our knowledge, this paper is 83
9mrz | 84 the first that provides an empirical analysis from the neuroscience view that investigates the working 85 memory ability of LLMs.
pk06 | 86 3 Methods
7wn9 | 87 We devised two categories of n-back tasks involving verbal and spatial working memory [36] respec-
wcd0 | 88 tively, and prompted ChatGPT (using the OpenAI API, <LATEX>= ^ { \prime \prime } g p t - 3 . 5 - t u r b o ^ { \prime \prime }</LATEX> to complete the
caos | 89 tasks in a trial-by-trial manner. For both categories, we have a base version task, and several variants 90 derived from the base version to further test the model's performance under different conditions.
qrvy | 91 3.1 Verbal <LATEX>n</LATEX> n-back experiments
pn9j | 92 In the base version of the verbal n-back task, for <LATEX>n = 1 , 2 , 3 ,</LATEX> respectively, we generated 50 blocks of 93 letter sequences using an alphabet commonly found in the literature ("bcdfghjklnpqrstvwxyz').
1pmc | 94 Each block contained a sequence of 24 letters, which are presented one at a time as user input to the
5z6q | 95 API. We included 8 match trials and 16 nonmatch trials in each block. The LLM was instructed to
yeoh | 3
b8hf | Table 1: Prompts used for different verbal task variants. Blue texts are to be selected as appropriate depending on the value of <LATEX>n</LATEX> in the n-back tasks. Other colored texts are inserted as appropriate, depending on the task variant.
hntf | 96 respond with <LATEX>m ^ { \prime \prime }</LATEX> on match trials and "-" on nonmatch trials. Apart from the above base version, we
99fo | 97 further explored the behavioural performance of ChatGPT with the following modifications of the 98 task presented in Figure 3:
y5r7 | 99 . We added <LATEX>3 \quad - \quad 6</LATEX> noise symbols to the input on every trial to examine the LLM's behaviour when to make it impossible to get the correct answer by simply doing string match between stimulus inputs.
lrry | 102 · In human behavioural studies, a common strategy to improve participants' performance is to 103 provide feedback after each trial [35]. Here in the task, after the LLM provided a response 104 for the previous trial, we added feedback on whether its response was correct or wrong 105 alongside the stimulus input of the current trial.
hvhm | 106 · Chain-of-thought (CoT) prompting has proved helpful in eliciting reasoning in LLMs [40]. Here we instructed the LLM to think step by step when giving a response.
863b | 108 3.2 Spatial n-back experiments
fj24 | 109 Although in its very nature, LLMs are text-based, but at least one study has demonstrated that they 110 have spatial reasoning abilities [5]. To build on this promising trail and further examine the spatial working memory of ChatGPT. In the base version of the spatial n-back task, we constructed <LATEX>\mathrm { a } 3 \times 3</LATEX> 111
uz3c | 112 grid using ASCII characters (see Table 2 for detailed prompts). For <LATEX>n = 1 , 2 , 3</LATEX> respectively, we
d5bi | 113 generated 50 blocks of grid sequences each featuring a letter <LATEX>\mathrm { X }</LATEX> in one of the nine positions. Note that
ba4l | 114 the letter <LATEX>\mathrm { X }</LATEX> here was arbitrarily chosen to represent an occupied spatial location textually and could 115 be substituted by any other letter or symbol. Each block contains 24 grids, including 8 match trials
ffx8 | 116 and 16 nonmatch trials. Like in the verbal n-back tasks, the LLM was instructed to respond with
s6su | <LATEX>X</LATEX> Figure 4: Illustrations of the different variants of spatial n-back tasks (we use <LATEX>n = 2</LATEX> in the figure) considered in this paper in addition to the variants presented in Figure 3, which are applicable to both the spatial and the verbal tasks. (a): base case identical to the case presented in Figure 1 (bottom row); (b): spatial tasks with larger grid sizes <LATEX>\left( 4 \times 4 \right.</LATEX> shown for illustration; we considered <LATEX>4 \times 4</LATEX> 4, <LATEX>5 \times 5</LATEX> and <LATEX>7 \times 7</LATEX> (c) and (d): two types of spatial reasoning tasks that additionally require abstract reasoning: in (c), a match is expected whenever the x mark occurs the same row and/or column at the same location n-back ago; in (d) a match is expected when x appears in the same row or column at the location n-back ago, but not both. Refer to Table 2 on the detailed instructions the LLM is prompted with for each of the variant.
y219 | 117 on match trials and "-" on nonmatch trials. We further explored the spatial working memory capacity
06ht | 118 of ChatGPT with the following modifications of the task (3:
v3r2 | 119 · As in the variants of verbal <LATEX>n</LATEX> n-back tasks, we also have "spatial-with-noise", "spatial-with- feedback", and "spatial-with-CoT-reasoning" versions of the task. The prompts for the 121 the with-feedback and with-reasoning versions were basically the same as those for the
nv42 | 122 corresponding verbal tasks (see Table 1). For the spatial-with-noise version, we added a noise character (chosen from "#$%&@ ~~ ") to 1 to 3 unoccupied locations in the <LATEX>3 \times 3</LATEX> grid
xags | 124 on every trial. This is a first step to examine the LLM's spatial working memory when it 125 was not able to get the correct answer by simply doing string match.
jc47 | 126 . To further confirm that the LLM can really reason in a spatial way rather than trivially 127 performing some kind of string match under the hood, we further introduced two variants 128 that specifically require abstract spatial reasoning; an model that would otherwise simply 129 match strings would have failed. To achieve so, in these two tasks, a match is defined as 130 when the location of the letter <LATEX>\mathrm { X }</LATEX> is in the same row or column as the <LATEX>\mathrm { X }</LATEX> n trials ago. The 131 difference is whether identical locations also count as a match. We expect the version 132 excluding identical locations to be harder for the LLM to perform.